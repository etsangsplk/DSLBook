\section{Semantics and Execution}
\label{semantics}

Semantics can be partitioned into static semantics and execution semantics.
Static semantics are implemented by the constraints and type system rules
(and,if you will, the language structure). Execution semantics denote the
observable behaviour of a program $p$ as it is executed. In this section we
focus on execution semantics unless stated otherwise.

Using a function $OB$ that defines this observable behaviour we can define the
semantics of a program $p_{L_D}$ by mapping it to a program $q$ in a language
for $D_{-1}$ that has the same observable behavior:
$$semantics( p_{L_D} ) := q_{L_{D-1}}\;\;\;where\;OB(p_{L_D}) ==
OB(q_{L_{D-1}})$$
\marginnote{There are also a number of approaches for formally defining
semantics independent of operational mappings to target languages. However, they
don't play an important role in real-world DSL design, so we don't address them
in this book.} 
\noindent Equality of the two observable behaviors can be
established with a sufficient number of tests, or with model checking and proof in rare cases. This definition of semantics reflects the hierarchy of domains and works both for
languages that describe only structure, as well as for those that include behavioural
aspects. 

The technical implementation of the mapping to $D_{-1}$ can be
provided in two different ways: a DSL program can literally be transformed into
a program, or a $L_{D-1}$ an interpreter can be written in $L_{D-1}$ or
$L_{D_0}$ to execute the program. Before we spend the rest of this section
looking at these two options in detail, we first briefly look at static
semantics.


\subsection{Static Semantics/Validation}

Before establishing the execution semantics by transforming or interpreting the
program, its static semantics has to be validated. Constraints and type systems
are used to this end and we describe their implementation in the DSL
Implementation section of this book \todo{cite}. Here is a short overview.

\marginnote[1cm]{Sometimes constraints are used instead of grammar rules. For
example, instead of using a $1..n$ multiplicity in the grammar, I often use $0..n$ together with a
constraint that checks that there is at least one element. The reason for using
this approach is that if the grammar mechanism is used, a possible error message
comes from the parser. That error message may read something like
\emph{expecting SUCH\_AND\_SUCH, found SOMETHING\_ELSE}. This is not very
useful. If a more tolerant ($0..n$) grammar is used, the constraint error message can be
made to express a real domain constraint (e.g. \emph{at least one
SUCH\_AND\_SUCH is required, because \ldots}).}

\paragraph{Constraints} are simply boolean expressions that
establish some property of a model. For example, one might verify that the names
of a set of attributes of some entity are unique. For a model to be statically
correct, all constraints have to evaluate to true. Constraint checking should
only be performed for a model that is structurally/syntactically correct.

\embc{One driver in selecting the linguistic abstractions that go into a 
DSL is the ability to easily implement meaningful constraints. For example, in
the state machine extension to C it is trivial to find states that have no
outgoing transitions (dead end). In a functional language, such a constraint
could be written as \emph{Statemachine:
states.select(s|!s.isInstanceOf(StopState)).select(s|s.transitions.size == 0)}.}

When defining languages and transformations, developers often have certain
constraints in their mind which they consider obvious. They assume that no one
would ever use the language in a particular way. However, DSL users may be
creative and actually use the language in that way, leading the transformation
to crash or create non-compilable code. Make sure that all constraints are
actually implemented. This can sometimes be hard. Only extensive (automated)
testing can prevent these problems from occurring.

In many cases, a multi-stage transformations is used where a model expressed in
$L_1$ is transformed into a model expressed in $L_2$, which is then in turn
transformed into a program expressed in $L_3$\footnote{Note how this also
applies to the classical case where $L_1$ is your DSL and $L_2$ is a GPL which
is then compiled!}. Make sure that \emph{every} program in $L_1$ leads to a
valid program in $L_2$. If the processing of $L_2$ fails with an error message
using abstractions from $L_2$ (e.g. compiler errors), users of $L_1$ will not be
able to act on these; they may have never seen the programs generated in $L_2$.
Again, automated testing is the way to address this issue.


\paragraph{Type Systems} are a special kind of constraints. Consider the example of 
\emph{var int x = 2 * someFunction(sqrt(2));}. The type system constraint may
check that the type of the variable is the same or a supertype of the type of the
initialization expression. However, establishing the type of the evaluation
expression is non-trivial, since it can be an arbitrarily complex expression. A
type system defines the rules to establish the types of arbitrary expressions,
as well as type checking constraints. We cover the implementation of type
systems in the DSL implementation part of the book \todo{ref}.

\newthought{When designing constraints and type system} in a language, a
decision has to be made between one of two approaches:  (a) declaration of
intent and checking for conformance and (b) deriving characteristics and
checking for consistency. Consider the following examples.

\embc{Variables have to be defined in the way shown above, where a type has to
be specified explicitly. A type specification expresses the intent that this
variable be of type \emph{int}. Alternatively, a type system could be built to
automatically derive the type of the variable declaration, an approach called
type inference. This would allow the following code to be written: \emph{var x =
2 * someFunction(sqrt(2));}. Since no type is explicitly specified, the
validator will infer the type of \emph{x} to be the type calculated for the init
expression.}

\embc{State machines that are supposed to be verified by the model checker have
to be marked as \emph{verified}. In that case, additional constraints kick in
that report certain ways of writing actions as invalid, because they cannot be
handled by the model checker. An alternative approach could check a state
machine whether these "unverifiable" ways of writing actions are used, and if
so, mark the state machine as not verifiable.}

\pension{Pension plans can inherit from other plans (called the base plan). If a
pension calculation rule overrides a rule in the base plan, then the overriding
rule has to marked as \emph{overrides}. This way, if the rule in the base plan
is removed or renamed, validatio of the sub plan will report an error. An
alternative design would simply derive the fact that a rule overrides
another one if they have the same name and signature.}

Note how in all three cases the constraint checking is based on two steps. First
we declare an intent (variable is intended to be int, this state machine is
intended to be verifiable, a rule is intended to override another one). We
can then check if the program conforms to this intention. The alternative
approach would derive the fact from the program (the variable's type is whatever
the expression's type evaluates to, state machines are verifiable if the
"forbidden" features aren't used, rules override another one if they have the
same name and signature) without any explicitly specified intent. 

When designing constraints and type systems, a decision has to be made regarding
when to use which approach. Here are some trade-offs. The
specification/conformance approach requires a bit more code to be written,
but results in more meaningful and specific error messages. The message can express
that fact that one part of a program does not conform to a specification made by
another part of the program. It also anchors the constraint checker, because a
fixed fact about the program is explicitly given instead of having it derived
from a (possibly large) part of the the program. The derivation/consistency
approach is less effort to write and can hence be seen to be more convenient,
but it requires more effort in constraint checking, and error messages may be
harder to understand because of the missing, explicit "hard fact" about the
program.



\subsection{Transformation} 

The transformation case is easy to see: a transformation recreates those
patterns and idioms in $L_{D-1}$ for which $L_D$ provides linguistic
abstraction. The result may be transformed further, until a level is reached for
which a  language with an execution infrastructure exists --- often $D_0$. Code
generation from a DSL is thus a special case where $L_{D_0}$ code is generated.

\embc{The semantics of state machines are defined by their mapping back to C
switch-case statements. This is repeated for higher D languages.
The semantics of the robot control DSL is defined by its mapping to state
machines and tasks. To explain the semantics to the users, prose documentation is 
available as well.}

\comparch{The component architecture DSL only described interfaces, components
and systems. This is all structure-only. Many constraints about structural
integrity are provided, and a mapping to OSGi is implemented. The formal
definition of the semantics are implied by the mapping to OSGi}


Formally, defining semantics happens by mapping the DSL concepts to $D_{-1}$
concepts for which the semantics is known. For DSLs used by developers, and for
domains that are defined bottom-up, this works well. For domain expert DSLs, and
for domains define top-down this approach is not necessarily good enough, since
the $D_{-1}$ concepts has no inherent meaning to the users and/or the domain. An
additional way of defining the meaning of the DSL is required. Useful approaches
include prose documentation as well as test cases or simulators. These can be
written in (another part of the) DSL itself; this way, domain users can play
with the DSL and write down their expectations in the testing aspect.

\cooling{This DSL has a separate viewpoint for defining test cases where
domain experts can codify their expectations regarding the behaviour of cooling
programs. An interpreter is available to simulate the programs, observe their
progress and stimulate them to see how they react.}

\pension{This DSL supports an Excel-like tabular notation for expressing test
cases for pension calculation rules. The calculations are functional, and the
calculation tree can be extended as a way of debugging the rules.}

\paragraph{Multi-staged Transformation} For languages where the semantic gap
between the DSL and the target language is significant, it makes sense to
introduce intermediate languages so the transformation can be modularized.
Optimizations can be performed on each level, exploiting the properties of that
particular abstraction level. Modern compilers with multiple intermediate
representations are a good example for this approach.\marginnote{ MPS comes with
a transformation engine that makes such transformation chains easy to
implement.} Reusing lower $D$ languages and their subsequent transformations
includes reuse of non-trivial analyses or optimizations. This makes this case
much more useful than what the pure reuse of languages and transformations
suggests. \marginnote{ This is the reason why we usually generate GPL source
code from DSLs, and not machine code: we want to reuse existing transformations
and optimizations provided by the GPL compiler and/or runtime.} Splitting a
transformation into a chain of smaller ones also makes each of them easier to
understand and maintain.

\embc{The extensions to C are all transformed back to C idioms during
transformation. Higher-level DSLs, for example, a simple DSL for robot control,
are reduced to C plus some extensions such as state machines and tasks.}

We can learn something else from compilers: they can be retargetted relatively
easily by exchanging the backends (machine code generation phases) or the
frontend (programming language parsers and analyzers). For example, GCC can
generate code for many different processor architectures (exchangeable
backends), and it can generate backend code for several programming languages,
among them C, C++ and Ada (exchangeable frontends). The same is possible for
DSLs. The same high $D$ models can be executed differently by exchanging the
lower $D$ intermediate languages and transformations. Or the same lower $D$ languages
and transformations can be used for different higher $D$ languages, by mapping
these different languages to the same intermediate language.

\embc{The embedded C language (and some of its higher D extensions) have
various translation options, for several different target platforms (Win32 and
Osek), an example of backend reuse.}

A special case of a multi-staged transformation is as a preprocessor to a code
generator. Here, a transformation is used to reduce the set of used language
concepts in a fragment to a minimal core, and only the minimal core is supported
in the code generator. 

\embc{Consider the case of a state machine where you want to be able to add an
"emergency stop" feature, i.e. a new transition from each existing state to a
new STOP state. Don't handle this in the generator templates. Rather, write a
model transformation script that preprocesses the state machine model and adds
all the new transitions and the new STOP state. Once done, you can run the
existing generator unchanged. You have effectively modularized the emergency
stop concern into the transformation.}

\comparch{The DSL describes hierarchical component architectures (where
components are assembled from interconnected instances of other components).
Most component runtime platforms don't support such hierarchical components, so
you need to "flatten" the structure for execution. Instead of trying to do this
in the code generator, you should consider an M2M step to do it, and then write
a simpler generator that works with a flattened, non-hierarchical model.}


\paragraph{Care about generated code} Ideally, generated code is a throw-away
artifact, a bit like object files in a C compiler. However, that's not quite
true. When integrating with generated code, you will have to read the generated
code, understand it (to some extent), and you will also have to debug it at some
point. Hence, generated code should be documented, use good names for
identifiers, and be indented correctly. All of this is relatively easy to
achieve, as you have all the information you need when writing the code
generator! Making generated code adhere to the same standards as manually
written code also helps to diffuse some of the skepticism against code
generation that is still widespread in some organizations.\marginnote{Note that
in complete languages with full coverage (i.e. where 100\% of the $D_{-1}$ code
is generated), the generated code is never seen by a DSL user. In this case the
statements made here don't apply.}


\paragraph{Platform} Code generators can become complex. The complexity can
be reduced by splitting the overall transformation into several steps ---
see above. Another approach is to work with a manually implemented, rich domain
specific platform. It typically consists of middleware, frameworks, drivers,
libraries and utilities that are taken advantage of by the generated code.
\begin{marginfigure}
  \includegraphics[width=4cm]{figures/platform.png}
  \caption[labelInTOC]{Typical layering structure of an application created
  using DSLs.}
  \label{platform}  
\end{marginfigure}
Where the generated code and the platform meet depends on the complexity of the
generator, requirements regarding code size and performance, the expressiveness
of the target language and the potential availability of libraries and
frameworks that can be used for the task.
\begin{marginfigure}
  \includegraphics[width=5cm]{figures/cave.png}
  \caption[labelInTOC]{Stalagmites and stalactites in limestone caves as a
  metaphor for a generator and a platform.}
  \label{cave} 
\end{marginfigure}

In the extreme case, the generator just generates code to populate/configure the
frameworks (which might already exist, or which you have to grow together with
the generator) or provides statically typed facades around otherwise dynamic
data structures. Don't go too far towards this end, however: in cases where you
need to consider resource or timing constraints, or when the target platform is
predetermined and perhaps limited, code generation does open up a new set of
options and it is often a very good approach (after all, it's basically the same
as compilation, and that's a proven and important technique).

\embc{For most aspects, we use only a very shallow platform. This is mostly for
performance reasons and for the fact that the subset of C that is often used
for embedded systems does not provide good means of abstraction. For example,
state machines are translated to switch/case statements. If we would generate
Java code in an enteprise system, we may populate a state machine framework
instead. In contrast, when we translate the component definitions to the
AUTOSAR target environment, a relatively powerful platform is used --- namely
the AUTOSAR APIs, conventions and generators.}

\subsection{Interpretation} 

For interpretation, the same approach could be used, i.e. an interpreter for
$L_D$ can be implemented in $L_{D-1}$. However, in practice we see interpreters
written in $L_{D_0}$. They may be extensible, so new interpreter code can be
added in case specialized languages define new language concepts. We have not come
across real-world DSLs where interpreters are stacked along the domain hierarchy
in the same way as transformations, with interpreters for $L_{D_n}$ written in
$L_{D_{n-1}}$ for $n>1$.

\cooling{The DSL also supports the definition of unit tests for the
asynchronous, reactive cooling algorithm. These tests are executed with an
in-IDE interpreter. A simulation environment allows the interpreter to be used
interactively. Users can "play" with a cooling program, stepping through it in
single steps, watching values change.}

\pension{The pension DSL supports the in-IDE execution of rule unit tests by an
interpreter. In addition, the rules can be debugged. The rule language is
functional, so the debugger "expands" the calculation tree, and users can
inspect all intermediate results.}



\subsection{Transformation vs. Interpretation} 

A primary concern in semantics is the decision between transformation (code
generation) and interpretation. Here are a couple of criteria to help with this
decision.

\begin{description}
	\item[Code Inspection] When using code generation, the resulting code can
	be inspected to check whether it resembles code that had previously been written
	manually in the DSL's domain. Writing the transformation rules can be guided by
	the established patterns and idioms in D-1. Interpreters are meta programs and
	as such harder to relate to the existing code patterns.
	\item[Debugging] Debugging generated code is straight forward if the code
	is well structured (which is up to the transformation). Debugging interpreters
	is harder, because setting breakpoints in the DSL program requires the use of
	conditional breakpoints, which are typically cumbersome to use.
	\item[Performance and Optimization] The code generator can include
	optimizations that result in small and tight generated code. The compiler for
	the generated code may come with its own optimizations which are used
	automatically if source code is generated. Generally, performance is better in
	generated environments, since interpreters always imply an additional layer of
	indirection.
	\item[Platform Conformance] Generated code can be tailored to any target
	platform. The code can look exactly as manually written code, no support
	libraries are required. This is important for systems where the source code
	(and not the DSL code) is the basis for a contractual obligation or for review
	and/or certification. Also if artifacts need to be generated for the platform
	that are not directly executable (descriptors, meta data), code generation is
	more suitable.
	\item[Turnaround Time] Turnaround time for interpretation is better than
	for generation: no generation, compilation and packaging step is required.
	Especially for target languages with slow compilers, large amounts of generated
	code can be a problem.
	\item[Runtime Change] In interpreted environments, the DSL program can be
	changed as the target system runs; the editor can be integrated into the
	executing system. The term data-driven system is often used in this case.
\end{description}



\subsection{Sufficiency}

A fragment is \emph{sufficient for transformation T} if the fragment itself
contains all the data for the transformation to be executed. It is
\emph{insufficient} if it is not. While dependent fragments are by definition
not sufficient without the transitive closure of fragments they depend on, an
independent fragment may be sufficient for one transformation, and insufficient
for another.

\cooling{The hardware structure is sufficient for a transformation that
generates an HTML doc that describes the hardware. It is insufficient regarding
the C code generator, since the behavior fragment is required as well.}

\embc{The MED code is sufficient regarding the MED-to-C generator. It is not
sufficient regarding the MED-to-Osek generator, since a so-called \emph{system
specification} fragment is required to define how the mapping to Osek should
look like.}


\subsection{Synchronizing Multiple Mappings} 

The approach suggested so far works well if we have only one mapping of a DSL
for execution. The semantics implied by the mapping to $L_{D-1}$ can be
\emph{defined} to be correct. However, as soon as we transform the program to
several different targets in $D_{-1}$ using several transformations, we have to
ensure that the semantics of all resulting programs are identical. In practice,
this often happens when an interpreter is used in the IDE for "experimenting"
with the models, and a code generator creates efficient code for execution in
the target environment. In this case, we recommend providing a set of test cases
that are executed both the interpreted and generated versions, expecting them to
succeed in both. If the coverage of these test cases is high enough to cover all
of the observable behavior, then it can be assumed with reasonable certainty
that the semantics are the same.

\pension{The unit tests in the pension plans DSL are executed by an interpreter
in the IDE. However, as Java code is generated from the pension plan
specifications, the same unit tests are also executed by the generated Java
code, expecting the same results as in the interpreted version.}

\subsection{Choosing between Several Mappings} 

Sometimes there are several \emph{alternative} ways how a program in $L_D$ can
be translated to a single $L_{D-1}$, for example to realize different non-functional
requirements (optimizations, target platform, tracing or logging). There are
several ways how one alternative may be selected.

\begin{itemize}
  \item Heuristics, based on patterns and idioms used in the program, can be
  used to determine the applicable translation from the program. Codifying these
  rules and heuristics can be hard.
  \item In analogy to compiler switches, the decision can be controlled by
  additional, external data, for example by adding an annotation model. An
  annotation model contains data used by the transformation to decide how to
  translate the core program. The transformation uses the $L_D$ program and the
  annotation model as its input. There can
  be several different annotation models for the same core model.
  \item Alternatively, $L_D$ can be extended to contain additional data 
  to guide decision. This is only useful if the DSL user can
  actually decide which alternative to choose, and if only one alternative
  should be chose for each program.
\end{itemize}

\noindent
As we have suggested above in the case of multiple transformations of the same
$L_D$ program, here too extensive testing must be used to make sure that all
translations exhibit the same semantics (except for the non-functional
characteristics that are expected to be different).


\subsection{Reduced Expressiveness} 

It may be beneficial to limit the expressiveness of a language. Limited
expressiveness often results in more sophisticated analyzability. For example,
while state machines are not very expressive, sophisticated model checking
algorithms are available (e.g. using the SPIN model checker from
\url{http://spinroot.com/}). The same is true for first-order logic, where
satisfiability (SAT) solvers \cite{Mitchell05} can be used to check programs for
consistency. If these kinds of analysis are useful for the model purpose, then
limiting the expressiveness to the respective formalism may be a good idea, even
if it makes expressing certain programs in $D$ more cumbersome. 


However, the language may have to be reduced to the point where domain experts
are not able to use the language because the connection to the domain is too
loose. An alternative approach is to use a language with limited expressiveness
at $D_{-1}$. For analysis and verification, the $L_D$ concepts are translated
down into the verifiable $L_{D-1}$ language. Verification is performed on
$L_{D-1}$, mapping the results back to $L_D$. Transforming to a verifiable
formalism also works if the formalism is not at $D_{-1}$, as long as a mapping
exists. The problem with this appraoch is the interpretation of analysis results
in the context of the DSL. Domain users may not be able to interpret the results
of model checkers or solvers, so they have to be translated back to the DSL.
This may be a lot of work, or even impossible.

\embc{The state machines expressed in the statemachine extension can be verified
with a model checker. To make this possible, state machine cannot use arbitrary
C code in its actions. Instead, an action can only change the values of
variables local to the state machine and set output events. These output events
can then be mapped to C functions or component runnables whose implementation
is outside the scope of the verification. The key here is that the state
machine is completely self-contained regarding verification: adapting the state
machine to its surrounding C program is a separate concern and irrelevant to
the model checker.}

\cooling{For the cooling algorithm, we are working on a mapping to SPIN/Promela
formalism to perform model checking on the pumping algorithms. This will be used
to proof that invariants expressed in the pumping program will hold in all
cases, or to show counter examples if they do not.}
 
