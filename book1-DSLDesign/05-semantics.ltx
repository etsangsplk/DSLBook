\section{Semantics and Execution}
\label{semantics}

Semantics can be partitioned into static semantics and execution semantics.
Static semantics represent the constraints and type system rules. Execution
semantics denote the observable behaviour of a program $p$ as it is executed. In
this section we focus on execution semantics. Using a function $OB$
that defines this observable behaviour we can define the semantics of a
program $p_{L_D}$ by mapping it to a program $q$ in a language for $D_{-1}$
that has the same observable behavior:
\vspace{-0.6\baselineskip}

$$semantics( p_{L_D} ) := q_{L_{D-1}}\;\;\;where\;OB(p_{L_D}) ==
OB(q_{L_{D-1}})$$

\noindent Equality of the two observable behaviors can be established with a
sufficient number of tests, or with model checking and proof in rare cases. This
definition of semantics reflects the hierarchy of domains and works both for
languages that describe only structure, as well as for those that include behavioural
definitions. The technical implementation of the mapping to $D_{-1}$ can be
provided in two different ways: a DSL program can literally be transformed into
a program, or a $L_{D-1}$ an interpreter can be written in $L_{D-1}$ or
$L_{D_0}$ to execute the program. 



\subsection{Transformation} 

The transformation case is easy to see: a transformation recreates those
patterns and idioms in $L_{D-1}$ for which $L_D$ provides linguistic
abstraction. The result may be transformed further, until a level is reached for
which a  language with an execution infrastructure exists --- often $D_0$. Code
generation from a DSL is thus a special case where $L_{D_0}$ code is generated.

\embc{The semantics of state machines are defined by their mapping back to C
switch-case statements. This is repeated for higher D languages.
The semantics of the robot control DSL is defined by its mapping to state
machines and tasks. To explain the semantics to the users, prose documentation is 
available as well.}

\comparch{The component architecture DSL only described interfaces, components
and systems. This is all structure-only. Many constraints about structural
integrity are provided, and a mapping to OSGi is implemented. The formal
definition of the semantics are implied by the mapping to OSGi}


Formally, defining semantics happens by mapping the DSL concepts to $D_{-1}$
concepts for which the semantics is known. For DSLs used by developers, and for
domains that are defined bottom-up, this works well. For domain expert DSLs, and
for domains define top-down this approach is not necessarily good enough, since
the $D_{-1}$ concepts has no inherent meaning to the users and/or the domain. An
additional way of defining the meaning of the DSL is required. Useful approaches
include prose documentation as well as test cases or simulators. These can be
written in (another part of the) DSL itself; this way, domain users can play
with the DSL and write down their expectations in the testing aspect.

\fountain{This DSL has a separate viewpoint for defining test cases where
domain experts can codify their expectations regarding the behaviour of cooling
programs. An interpreter is available to simulate the programs, observe their
progress and stimulate them to see how they react.}

\pension{This DSL supports an Excel-like tabular notation for expressing test
cases for pension calculation rules. The calculations are functional, and the
calculation tree can be extended as a way of debugging the rules.}

\paragraph{Multi-staged Transformation} For languages where the semantic gap
between the DSL and the target language is significant, it makes sense to
introduce intermediate languages so the transformation can be modularized.
Optimizations can be performed on each level, exploiting the properties of that
particular abstraction level. Modern compilers with multiple intermediate
representations are a good example for this approach.\marginnote{ MPS comes with
a transformation engine that makes such transformation chains easy to
implement.} Reusing lower $D$ languages and their subsequent transformations
includes reuse of non-trivial analyses or optimizations. This makes this case
much more useful than what the pure reuse of languages and transformations
suggests. \marginnote{ This is the reason why we usually generate GPL source
code from DSLs, and not machine code: we want to reuse existing transformations
and optimizations provided by the GPL compiler and/or runtime.} Splitting a
transformation into a chain of smaller ones also makes each of them easier to
understand and maintain.

\embc{The extensions to C are all transformed back to C idioms during
transformation. Higher-level DSLs, for example, a simple DSL for robot control,
are reduced to C plus some extensions such as state machines and tasks.}

We can learn something else from compilers: they can be retargetted relatively
easily by exchanging the backends (machine code generation phases) or the
frontend (programming language parsers and analyzers). For example, GCC can
generate code for many different processor architectures (exchangeable
backends), and it can generate backend code for several programming languages,
among them C, C++ and Ada (exchangeable frontends). The same is possible for
DSLs. The same high $D$ models can be executed differently by exchanging the
lower $D$ intermediate languages and transformations. Or the same lower $D$ languages
and transformations can be used for different higher $D$ languages, by mapping
these different languages to the same intermediate language.

\embc{The embedded C language (and some of its higher D extensions) have
various translation options, for several different target platforms (Win32 and
Osek), an example of backend reuse.}

A special case of a multi-staged transformation is as a preprocessor to a code
generator. Here, a transformation is used to reduce the set of used language
concepts in a fragment to a minimal core, and only the minimal core is supported
in the code generator. 

\embc{Consider the case of a state machine where you want ´to be able to add an
“emergency stop” feature, i.e. a new transition from each existing state to a
new STOP state. Don’t handle this in the generator templates. Rather, write a
model transformation script that preprocesses the state machine model and adds
all the new transitions and the new STOP state. Once done, you can run the
existing generator unchanged. You have effectively modularized the emergency
stop concern into the transformation.}

\comparch{The DSL describes hierarchical component architectures (where
components are assembled from interconnected instances of other components).
Most component runtime platforms don’t support such hierarchical components, so
you need to “flatten” the structure for execution. Instead of trying to do this
in the code generator, you should consider an M2M step to do it, and then write
a simpler generator that works with a flattened, non-hierarchical model.}


\paragraph{Care about generated code} Ideally, generated code is a throw-away
artifact, a bit like object files in a C compiler. However, that's not quite
true. When integrating with generated code, you will have to read the generated
code, understand it (to some extent), and you will also have to debug it at some
point. Hence, generated code should be documented, use good names for
identifiers, and be indented correctly. All of this is relatively easy to
achieve, as you have all the information you need when writing the code
generator! Making generated code adhere to the same standards as manually
written code also helps to diffuse some of the skepticism against code
generation that is still widespread in some organizations.\marginnote{Note that
in complete languages with full coverage (i.e. where 100\% of the $D_{-1}$ code
is generated), the generated code is never seen by a DSL user. In this case the
statements made here don't apply.}


\paragraph{Platform} Code generators can become complex. The complexity can
be reduced by splitting the overall transformation into several steps ---
see above. Another approach is to work with a manually implemented, rich domain
specific platform. It typically consists of middleware, frameworks, drivers,
libraries and utilities that are taken advantage of by the generated code.
\begin{marginfigure}
  \includegraphics[width=4cm]{figures/platform.png}
  \caption[labelInTOC]{Typical layering structure of an application created
  using DSLs.}
  \label{platform}  
\end{marginfigure}
Where the generated code and the platform meet depends on the complexity of the
generator, requirements regarding code size and performance, the expressiveness
of the target language and the potential availability of libraries and
frameworks that can be used for the task.
\begin{marginfigure}
  \includegraphics[width=5cm]{figures/cave.png}
  \caption[labelInTOC]{Stalagmites and stalactites in limestone caves as a
  metaphor for a generator and a platform.}
  \label{cave} 
\end{marginfigure}

In the extreme case, the generator just generates code to populate/configure the
frameworks (which might already exist, or which you have to grow together with
the generator) or provides statically typed facades around otherwise dynamic
data structures. Don't go too far towards this end, however: in cases where you
need to consider resource or timing constraints, or when the target platform is
predetermined and perhaps limited, code generation does open up a new set of
options and it is often a very good approach (after all, it's basically the same
as compilation, and that's a proven and important technique).

\embc{For most aspects, we use only a very shallow platform. This is mostly for
performance reasons and for the fact that the subset of C that is often used
for embedded systems does not provide good means of abstraction. For example,
state machines are translated to switch/case statements. If we would generate
Java code in an enteprise system, we may populate a state machine framework
instead. In contrast, when we translate the component definitions to the
AUTOSAR target environment, a relatively powerful platform is used --- namely
the AUTOSAR APIs, conventions and generators.}

\subsection{Interpretation} 

For interpretation, the same approach could be used, i.e. an interpreter for
$L_D$ can be implemented in $L_{D-1}$. However, in practice we see interpreters
written in $L_{D_0}$. They may be extensible, so new interpreter code can be
added in case specialized languages define new language concepts. We have not come
across real-world DSLs where interpreters are stacked along the domain hierarchy
in the same way as transformations, with interpreters for $L_{D_n}$ written in
$L_{D_{n-1}}$ for $n>1$.

\fountain{The DSL also supports the definition of unit tests for the
asynchronous, reactive pumping algorithm. These tests are executed with an
in-IDE interpreter. A simulation environment allows the interpreter to be used
interactively. Users can "play" with a pumping program, stepping through it in
single steps, watching values change.}

\pension{The pension DSL supports the in-IDE execution of rule unit tests by an
interpreter. In addition, the rules can be debugged. The rule language is
functional, so the debugger "expands" the calculation tree, and users can
inspect all intermediate results.}



\subsection{Transformation vs. Interpretation} 

A primary concern in semantics is the decision between transformation (code
generation) and interpretation. Here are a couple of criteria to help with this
decision.

\begin{description}
	\item[Code Inspection] When using code generation, the resulting code can
	be inspected to check whether it resembles code that had previously been written
	manually in the DSL's domain. Writing the transformation rules can be guided by
	the established patterns and idioms in D-1. Interpreters are meta programs and
	as such harder to relate to the existing code patterns.
	\item[Debugging] Debugging generated code is straight forward if the code
	is well structured (which is up to the transformation). Debugging interpreters
	is harder, because setting breakpoints in the DSL program requires the use of
	conditional breakpoints, which are typically cumbersome to use.
	\item[Performance and Optimization] The code generator can include
	optimizations that result in small and tight generated code. The compiler for
	the generated code may come with its own optimizations which are used
	automatically if source code is generated. Generally, performance is better in
	generated environments, since interpreters always imply an additional layer of
	indirection.
	\item[Platform Conformance] Generated code can be tailored to any target
	platform. The code can look exactly as manually written code, no support
	libraries are required. This is important for systems where the source code
	(and not the DSL code) is the basis for a contractual obligation or for review
	and/or certification. Also if artifacts need to be generated for the platform
	that are not directly executable (descriptors, meta data), code generation is
	more suitable.
	\item[Turnaround Time] Turnaround time for interpretation is better than
	for generation: no generation, compilation and packaging step is required.
	Especially for target languages with slow compilers, large amounts of generated
	code can be a problem.
	\item[Runtime Change] In interpreted environments, the DSL program can be
	changed as the target system runs; the editor can be integrated into the
	executing system. The term data-driven system is often used in this case.
\end{description}



\subsection{Sufficiency}

A fragment is \emph{sufficient for transformation T} if the fragment itself
contains all the data for the transformation to be executed. It is
\emph{insufficient} if it is not. While dependent fragments are by definition
not sufficient without the transitive closure of fragments they depend on, an
independent fragment may be sufficient for one transformation, and insufficient
for another.

\fountain{The hardware structure is sufficient for a transformation that
generates an HTML doc that describes the hardware. It is insufficient regarding
the C code generator, since the behavior fragment is required as well.}

\embc{The MED code is sufficient regarding the MED-to-C generator. It is not
sufficient regarding the MED-to-Osek generator, since a so-called \emph{system
specification} fragment is required to define how the mapping to Osek should
look like.}


\subsection{Synchronizing Multiple Mappings} 

The approach suggested so far works well if we have only one mapping of a DSL
for execution. The semantics implied by the mapping to $L_{D-1}$ can be
\emph{defined} to be correct. However, as soon as we transform the program to
several different targets in $D_{-1}$ using several transformations, we have to
ensure that the semantics of all resulting programs are identical. In practice,
this often happens when an interpreter is used in the IDE for "experimenting"
with the models, and a code generator creates efficient code for execution in
the target environment. In this case, we recommend providing a set of test cases
that are executed both the interpreted and generated versions, expecting them to
succeed in both. If the coverage of these test cases is high enough to cover all
of the observable behavior, then it can be assumed with reasonable certainty
that the semantics are the same.

\pension{The unit tests in the pension plans DSL are executed by an interpreter
in the IDE. However, as Java code is generated from the pension plan
specifications, the same unit tests are also executed by the generated Java
code, expecting the same results as in the interpreted version.}

\subsection{Choosing between Several Mappings} 

Sometimes there are several \emph{alternative} ways how a program in $L_D$ can
be translated to a single $L_{D-1}$, for example to realize different non-functional
requirements (optimizations, target platform, tracing or logging). There are
several ways how one alternative may be selected.

\begin{itemize}
  \item Heuristics, based on patterns and idioms used in the program, can be
  used to determine the applicable translation from the program. Codifying these
  rules and heuristics can be hard.
  \item In analogy to compiler switches, the decision can be controlled by
  additional, external data, for example by adding an annotation model. An
  annotation model contains data used by the transformation to decide how to
  translate the core program. The transformation uses the $L_D$ program and the
  annotation model as its input. There can
  be several different annotation models for the same core model.
  \item Alternatively, $L_D$ can be extended to contain additional data 
  to guide decision. This is only useful if the DSL user can
  actually decide which alternative to choose, and if only one alternative
  should be chose for each program.
\end{itemize}

\noindent
As we have suggested above in the case of multiple transformations of the same
$L_D$ program, here too extensive testing must be used to make sure that all
translations exhibit the same semantics (except for the non-functional
characteristics that are expected to be different).


\subsection{Reduced Expressiveness} 

It may be beneficial to limit the expressiveness of a language. Limited
expressiveness often results in more sophisticated analyzability. For example,
while state machines are not very expressive, sophisticated model checking
algorithms are available (e.g. using the SPIN model checker from
\url{http://spinroot.com/}). The same is true for first-order logic, where
satisfiability (SAT) solvers \cite{Mitchell05} can be used to check programs for
consistency. If these kinds of analysis are useful for the model purpose, then
limiting the expressiveness to the respective formalism may be a good idea, even
if it makes expressing certain programs in $D$ more cumbersome. 


However, the language may have to be reduced to the point where domain experts
are not able to use the language because the connection to the domain is too
loose. An alternative approach is to use a language with limited expressiveness
at $D_{-1}$. For analysis and verification, the $L_D$ concepts are translated
down into the verifiable $L_{D-1}$ language. Verification is performed on
$L_{D-1}$, mapping the results back to $L_D$. Transforming to a verifiable
formalism also works if the formalism is not at $D_{-1}$, as long as a mapping
exists. The problem with this appraoch is the interpretation of analysis results
in the context of the DSL. Domain users may not be able to interpret the results
of model checkers or solvers, so they have to be translated back to the DSL.
This may be a lot of work, or even impossible.

\todo{add an embc example}

\fountain{For the pumping algorithm, we are working on a mapping to SPIN/Promela
formalism to perform model checking on the pumping algorithms. This will be used
to proof that invariants expressed in the pumping program will hold in all
cases, or to show counter examples if they do not.}
 
