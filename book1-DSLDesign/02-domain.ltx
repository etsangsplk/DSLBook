\FloatBarrier

\section{Programs, Languages, Domains}
\label{hierarchical}

Domain-specific languages live in the realm of \emph{programs},
\emph{languages}, and \emph{domains}. We are primarily interested in
\emph{computation}. So, let's first consider the relation between programs and
languages. Let's define $P$ to be the set of all programs. A \emph{program} $p$
in $P$ is the Platonic representation of some \emph{effective computation} that
runs on a universal computer. That is, we assume that $P$ represents the
canonical semantic model of all programs and includes all possible hardware on
which programs may run. A \emph{language} $L$ defines a structure and notation
for \emph{expressing} or \emph{encoding} programs. Thus, a program $p$ in $P$
may have an expression in $L$, which we will denote $p_L$. Note that $p_{L_1}$
and $p_{L_2}$ are representations of a single semantic (platonic) program in the
languages $L_1$ and $L_2$. There may be multiple ways to express the same
program in a language~$L$. A language is a \emph{finitely generated} set of
program encodings. That is, there must be a finite description that generates
all program expressions in the language. As a result, it may not be possible to
define all programs in some language~$L$. We denote as $P_L$ the subset of $P$
that can be expressed in $L$. A translation $T$ between languages $L_1$ and
$L_2$ maps programs from their $L_1$ encoding to their $L_2$ encoding, i.e.
$T(p_{L_1}) = p_{L_2}$.

\pension{The pension language can be used to effectively represent
pension calculations, but cannot be used to express general purpose
enterprise software}  


\begin{marginfigure}
  \includegraphics[width=5cm]{figures-design/domain.png}
  \caption{Programs, Languages, Domains}
  \label{fig:programs}
\end{marginfigure}


\parhead{Domains} What are domains? There are essentially two approaches to
characterize domains. First, domains are often considered as a body of knowledge
in the real world, i.e. outside the realm of software. From this
\emph{deductive} or \emph{top-down} perspective, a domain $D$ is a body of
knowledge for which we want to provide some form of software support. We define
$P_D$ the subset of programs in $P$ that implement computations in $D$, e.g.
'this program implements a fountain algorithm'.

\pension{The pensions domain has been defined this way. The customer had been
working in the field of old age pansions for decades and had a very detailed
understanding of what the pension domain entails. That knowledge was mainly
contained in the heads of pension experts, in pension plan requirements
documents, and, to some extent, encoded in the source of existing software.}

In the \emph{inductive} or \emph{bottom-up} approach we define a domain in terms
of existing software. That is, a domain $D$ is identified as a subset $P_D$ of
$P$, i.e. a set of programs with common characteristics or similar purpose.
Often, such domains do not exist outside the realm of software. A special
case of the inductive approach is where we define a domain as a subset of
programs of a specific $P_L$ instead of the more general set $P$. In this
special case we can often clearly identify the commonality between programs in
the domain, in the form of their consistent use of a set of domain-specific
patterns or idioms.

\embc{The extensions to the C programming language are defined bottom-up. Based
on idioms commonly used when using C for a given class of problems, linguistic
abstractions have been defined that provide a "shorthand" for those idioms.
These linguistic abstractions form the basis of the language extensions.}

The above example can be considered relatively general --- the domain of
embedded software development is relatively broad. In contrast, a domain may
also be very specific.

\cooling{The cooling DSL is tailored specifically to expressing refrigerator
cooling programs for a very specific organization. No claim is made for
widespread usefulness of the DSL. However, it perfectly fits into the way
cooling algorithms are described and implemented in that particular
organization.}

Whether we take the deductive or inductive route, we can ultimately identify a
domain $D$ by a set of programs $P_D$. There can be multiple languages
in which we can express $P_D$ programs. Possibly, $P_D$ can only be partially
expressed in a language $L$ (Figure~\ref{fig:programs}). A \emph{domain-specific
language} $L_D$ for $D$ is a language that is \emph{specialized} to encoding
$P_D$~programs. That is, $L_D$ is more efficient in some respect in representing
$P_D$~programs. Typically, such a language is \emph{smaller} in the sense that
$P_{L_D}$ is a strict subset of $P_L$ for a less specialized language~$L$.


\begin{marginfigure}[2cm]
\begin{center}
  \includegraphics[width=5cm]{figures-design/domainApprox.png}
  \caption{Languages L1 and L2 under-approximate and over-approximate domain D.}
  \label{fig:approximation}
\end{center}
\end{marginfigure}

The crucial difference between languages and domains is that the
former are finitely generated, but that the latter are arbitrary sets of programs the
membership of which is determined by a human oracle. This difference defines the
difficulty of DSL design: finding regularity in a non-regular domain and
capturing it in a language. The resulting DSL represents an explanation or
interpretation of the domain, and often requires trade-offs by under- or
over-approximation (Figure~\ref{fig:approximation}).

\subsection{Programs as Trees of Elements}

\marginnote{Users use the concrete syntax as they write or change programs. The
abstract syntax is a data structure that contains all the data expressed with
the concrete syntax, but without the notational details. The abstract syntax is
used for analysis and downstream processing of programs.} Programs are
represented in two ways: concrete syntax and abstract syntax. A language
definition includes the concrete and the abstract syntax, as well as rules for
mapping one to the other. \emph{Parser-based} systems map the concrete syntax to
the abstract syntax. Users interact with a stream of characters, and a parser
derives the abstract syntax by using a grammar and mapping rules.
\emph{Projectional} editors go the other way round. User editing gestures
directly change the abstract syntax, the concrete syntax being a mere projection
that looks and feels like text if a textual projection is used. SDF and Xtext
are parser-based, MPS is projectional.

\marginnote{While concrete syntax modularization and composition can be a
challenge (as discussed in \sect{challenges}), we will illustrate most language
design concerns based on the abstract syntax.} The abstract syntax of programs
are primarily trees of program \emph{elements}. Every element (except the root)
is contained by exactly one parent element. Syntactic nesting of the concrete
syntax corresponds to a parent-child relationship in the abstract syntax. There
may also be any number of non-containing cross-references between elements,
established either directly during editing (in projectional systems) or by a
name resolution (or \emph{linking}) phase that follows parsing and tree
construction.

A program may be composed from several program \emph{fragments}. A fragment is a
standalone tree, a partial program\footnote{Conversely, a program is then a
set of fragments.}. $E_f$ is the set of program elements in a fragment $f$.

A language $l$ defines a set of language concepts $C_l$ and their
relationships\footnote{We use the term concept to refer to concrete syntax,
abstract syntax plus the associated type system rules and constraints as well as some
definition of its semantics.}. In a fragment, each element $e$ is an
instance of a concept $c$ defined in some language $l$. 

\embc{In C, the statement \ic{int x = 3;} is an instance of the
\lcr{LocalVariableDeclaration}. \ic{int} is an instance of \lcr{IntType}, and
the 3 is an instance of
\lcr{NumberLiteral}.}

We define the \emph{concept-of} function $co$ to return the concept of which a
program element is an instance: $co \Rightarrow \mathit{element} \to
\mathit{concept}$. Similarly we define the \emph{language-of} function $lo$ to
return the language in which a given concept is defined: $lo \Rightarrow
\mathit{concept} \to \mathit{language}$. Finally, we define a \emph{fragment-of}
function $fo$ that returns the fragment that contains a given program element:
$fo \Rightarrow \mathit{element} \to \mathit{fragment}$.

We also define the following sets of relations between program elements.
$\mathit{Cdn_f}$ is the set of parent-child relationships in a fragment $f$.
Each $c \in C$ has the properties $parent$ and $child$. 

\embc{In \ic{int x = 3;} the local variable declaration is the parent of the
type and the init expression 3. The concept \lcr{LocalVariableDeclaration}
defines the containment relationships \lcr{type} and \lcr{init},
respectively.}

$\mathit{Refs_f}$ is the set of non-containing cross-references between program
elements in a fragment $f$. Each reference $r$ in $\mathit{Refs_f}$ has the
properties $from$ and $to$, which refer to the two ends of the reference
relationship.

\embc{For example, in the \ic{x = 10;} assignment, \ic{x} is a reference to
a variable of that name, for example, the one declared in the previous example
paragraph. The concept \lcr{LocalVariabedRef} has a non-containing reference
relationsip \lcr{var} that points to the respective variable.}

Finally, we define an inheritance relationship that applies the
Liskov Substitution Principle to language concepts. A concept $c_sub$ that
extends another concept $c_super$ can be used in places where an instance of
$c_super$ is expected. $\mathit{Inh_l}$ is the set of inheritance relationships
for a language $l$. Each $i \in \mathit{Inh_l}$ has the properties $super$ and
$sub$.

\embc{The \lcr{LocalVariableDeclaration} introduced above extends the concept
\lcr{Statement}. This way, a local variable declaration can be used wherever a
statement is expected, for example, in the body of a function, which contains a
list of statements.}

An important concept in \lmrc\ is the notion of independence. An
\emph{independent language} does not depend on other languages. An independent
language $l$ can be defined as a language for which the following hold:
\begin{align}
\forall r \in \mathit{Refs_l} &\mid \mathit{lo(r.to)} = 
	\mathit{lo(r.from)} = l
\\ 
\forall s \in \mathit{Inh_l} &\mid \mathit{lo(s.super)} = 
	\mathit{lo(s.sub)} = l
\\ 
\forall c \in \mathit{Cdn_l} &\mid \mathit{lo(c.parent)} = 
     \mathit{lo(c.child)} = l
\end{align}
An \emph{independent fragment} is one where all non-containing cross-references
stay within the fragment (1.4). By definition, an independent fragment has to 
be expressed with an independent language (1.5). 
\begin{align}
\forall r \in \mathit{Refs_f} &\mid \mathit{fo(r.to)} 
	= \mathit{fo(r.from)} = f
\\ 
\forall e \in E_f &\mid \mathit{lo(co(e))} = l 
\end{align}

We can now further refine our definition of \emph{program}: a program is a set
of fragments; for each dependent fragment, the transitive closure of
dependencies must be included in this set.


\begin{marginfigure}
  \includegraphics[width=6cm]{figures-design/cooling/dependent.png} 
  \caption{A \lcr{BuildingBlockRef} references a hardware element from within a
  cooling algorithm fragment.}
  \label{dependent}
\end{marginfigure}
\cooling{The hardware definition language is independent, as are fragments that
use this language. In contrast, the cooling algorithm language is dependent.
The \lcr{BuildingBlockRef} concept declares a reference to the
\lcr{BuildingBlock} concept defined in the hardware language (\fig{dependent}).
Consequently, if a cooling program refers to a hardware setup using an instance of
\lcr{BuildingBlockRef}, the fragment becomes dependent on the hardware
definition fragment that contains the referenced building block.}


We also distinguish \emph{homogeneous} and \emph{heterogeneous} fragments. A
homogeneous fragment is one where all elements are expressed with the same
language:
\begin{align}
\forall e \in E_f &\mid \mathit{lo(e)} = l \\
\forall c \in \mathit{Cdn_f} &\mid \mathit{lo(c.parent)} = 
	\mathit{lo(c.child)} = l
\end{align}

\embc{A program written in plain C is homogeneous. All program elements are
instances of the C language. Using the statemachine language extension allows
us to embed state machines in C programs. This makes the respective fragment
heterogeneous (see \fig{heterogeneous}).}

\begin{figure}[h] 
  \rule{1\textwidth}{0.7pt}
  \vspace{-0.5cm}
  \includegraphics[width=14cm]{figures-design/embc/heterogeneous.png}
  \caption[][0.3cm]{An example of a heterogeneous fragment. This
  module contains global variables (from the \emph{core} language), a state machine
  (from the \emph{statemachines} language) and a test case (from the
  \emph{unittest} language). Note how concepts defined in the
  \emph{statemachine} language (\lcr{trigger}, \lcr{isInState}) are used inside
  a \lcr{TestCase}.}
  \label{heterogeneous} 
  \rule{1\textwidth}{0.7pt}
\end{figure}

\subsection{Domain Hierarchy} 
\label{domhier}



The subsetting of domains naturally gives rise to a hierarchy of domains
(\fig{hierarchicalDomains}). At the bottom we find the most general domain
$D_0$. It is the domain of all possible programs $P$. Domains $D_n$, with $n >
0$, represent progressively more specialized domains, where the set of possible
programs is a subset of those in $D_{n-1}$ (abbreviated as $D_{-1}$). We call
$\D{+1}$ a subdomain of D. For example, $\D{1.1}$ could be the domain of
embedded software, and $\D{1.2}$ could be the domain of enterprise software. The
progressive specialization can be continued ad-infinitum in principle. For
example, $\D{2.1.1}$ and $\D{2.1.2}$ are further subdomains of $\D{1.1}$:
$\D{2.1.1}$ could be automotive embedded software and $\D{2.1.2}$ could be
avionics software. At the top of the hierarchy we find singleton domains that
consist of a single program (a non-interesting boundary case). Languages are
typically designed for a particular $D$. Languages for $\D{0}$ are called
general-purpose languages. Languages for $D_n$ with $n > 0$ become more
domain-specific for growing $n$.


\begin{figure}[h]
  \includegraphics[scale=0.7]{figures-design/hierarchicalDomains.png}
  \caption{Domain hierarchy. Domains with higher index are
  called subdomains of domains with a lower index ($D_1$ is a subdomain of
  $D_0$). We use just $D$ to refer to the current domain, and $\D{+1}$ and $\D{-1}$ to
  refer to the relatively more specific and more general ones.}
  \label{hierarchicalDomains} 
\end{figure}

\embc{The C base language is defined for $D_0$. Extensions for tasks, state
machines or components can argued to be specific to embedded systems, making
those sit in $D_{1.1}$. Progressive specialization is possible; for example, a
language for controlling small lego robots sits on top of state machines and
tasks. It could be allocated to $D_{2.1.1}$.}


\subsection{Model Purpose} We have said earlier that there can be several
languages for the same domain. Deciding which concepts should go into a
particular language for D, and at which level of abstraction or detail, is not
always obvious. The basis for the decision is to consider the \emph{model
purpose}. Models, and hence the languages to express them, are intended for a
specific purpose. Examples of model purpose include automatic derivation of a
$D_{-1}$ program, formal analysis and model checking, platform independent
specification of functionality or generation of
documentation\footnote{Generation of documentation is typically
not the main or sole model purpose, but may be an important secondary concern.
In general, we consider models that only serve communication among humans
outside the scope of this book, because they don't have to be formally defined
to achieve their purpose.}.\updateSlides{}  The same domain concepts can often
be abstracted in different ways, for different purposes. When defining a DSL, we have to identify
the different purposes required, and then decide whether we can create one DSL
that fits all purposes, or create a DSL for each purpose.

\embc{The model purpose is the generation of an efficient low-level C
implementation of the system, while at the same time providing software
developers with meaningful abstractions. Since \emph{efficient} C code has to
be generated, certain abstractions, such as dynamically growing lists or
runtime polymorphic dispatch are not supported. The state machines in the
statemachines language have an additional model purpose: model checking, i.e.
proofing certain properties about the state machines (e.g. proofing that a
certain state is definitely going to be reached after some event occurs). To
enable this, actions used in the state machines are further limited.}

\cooling{The model purpose is the generation of efficient implementation code
for various different target platforms. A secondary purpose is enabling domain
experts to express the algorithms and experiment with them using simulations and
tests. The DSL is not expected to be used to visualize the actual
refrigerator device or for sales or marketing purposes.}

\pension{The model purpose of the pension DSL is to enable insurance
mathematicians and pension plan developers (who are not programmers) to define
complete pension plans, and to allow them to check their own work for
correctness using various forms of tests. A secondary purpose is the generation
of the complete calculation engine for the computing center and the website.}




\subsection{Parsing vs. Projection}

There are two main approaches for implementing external DSLs. The traditional
approach is parser-based. A grammar specifies the sequence of tokens and words
that make up a structurally valid program. A parser is generated from this
grammar. A parser is a program that recognizes valid programs in their textual
form and creates an abstract syntax tree or graph. Analysis tools or generators
work with this abstract syntax tree. Users enter programs using the concrete
syntax (i.e. character sequences) and programs are also stored in this way.
Example tools in this category include Spoofax and Xtext.

Projectional editors (also known as structured editors) work without parsers.
Editing actions directly modify the abstract syntax tree.
Projection rules then render a textual (or other) representation of the program.
Users read and write programs through this projected notation. Programs are
stored as abstract syntax trees, usually as XML. As in parser-based systems,
backend tools operate on the abstract syntax tree. Projectional editing is well
known from graphical editors, virtually all of them use this approach. 
However, they can also be used for textual syntax. \marginnote{While in the past
projectional text editors have gotten a bad reputation, as of 2011, the tools
have become good enough, and computers have become fast enough to make this
approach feasible, productive and convenient to use.} Example tools in this
category include the Intentional Domain Workbench (\url{http://intentsoft.com})
and JetBrains MPS.

In this section, we do not discuss the relative advantages and drawbacks of
parser-based vs. projectional editors in any detail (we do discuss the tradeoffs
in the chapter on language implementation \todo{ref}). However, we will point
out if and when there are different DSL design options depending on which of the
two approaches is used.


\subsection{Design Dimensions}

There are typically many differnet languages suitable for expressing a
particular program. In DSL design we are looking for the \emph{optimal} language
for expressing programs in a particular domain. There are multiple dimensions in
which we can optimize language designs. Often it is not possible to maximize
along all dimensions; we have to find a trade-off between properties. We have
identified the following technical dimensions of DSL design:
\emph{expressivity}, \emph{coverage}, \emph{semantics and execution},
\emph{separation of concerns}, \emph{completeness}, \emph{structuring programs},
\emph{language modularity}, and \emph{concrete syntax}. In the following
sections we will examine each of these dimensions in detail.




