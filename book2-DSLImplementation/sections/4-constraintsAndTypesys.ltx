\chapter{Constraints}

Constraints are boolean conditions that have to evaluate to \ic{true} in order for
the model to be correct ("does \ic{expr} hold?"). An error message that is reported
if the expression evaluates to false ("\ic{expr} does not hold!"). They are
typically associated with language concepts ("for each instances of \ic{x},
\ic{expr-with-x} must hold"). Constraints address model correctness beyond syntax and
scoping/linking, but short of actual execution semantics. Typical examples for constraints are:

\begin{itemize}
  \item uniqueness of names in lists of elements (e.g. functions in a
  namespace);
  \item every non-start state of a state machine has at least one incoming
  transition;
  \item a variable is defined before it is used (statement ordering);
  \item the assignee is type-compatible with the right hand side expression.
\end{itemize}

The last item is an example of a type system rule: these verify the correctness
of types in programs, e.g. making sure you don't assign a \ic{float} to an
\ic{int}. Particularly in expression languages, type calculations and checking
can become quite complicated and therefore warrants special support. This is
why we distinguish between simple constraints (covered in this chapter)  and
type systems (which we cover in the next chapter). 

Constraints can be implemented with any language that is able to query a model
and report errors to the user. To make constraint checking efficient, it is
useful if the language has the following characteristics:

\begin{itemize}
  \item It should be able to effectively navigate and filter the model. Support
  for path expressions (as in \ic{aClass.operations.arguments.type} as a way to
  find out the types of all arguments of all operations in a class) is extremely
  useful.
  \item Support for higher-order functions is useful so one can write
  generic algorithms and traversal strategies
  \item A good collection language, often making use of higher-order functions,
  is very useful, so it is easily possible to filter collections, create
  subsets or get the set of distinct values in a list.
  \item Finally, it is helpful to be able to associate a constraint
  declaratively with the language concept for whose instances it should be
  executed
\end{itemize}

Here is an example constraint written in a pseudo-language:

\begin{code}
constraint for: 
  Class
expression: 
  this.operations.arguments.type.filter(ComplexNumber).isNotEmpty &&
  !this.imports.any(i|i.name == "ComplexNumberSupportLib")
message: 
  "class "+this.name+" uses complex numbers, so the ComplexNumberSupportLib must
  be imported"
\end{code}

Some kinds of constraints require specialized data structures to be built or
maintained in sync with the program. Examples include
dead code detection, missing returns in some branches of a method's body or
read access to an uninitialized variable. To be able to find these kinds of errors statically, a
dataflow graph has to be constructed from the program. A dataflow graph models
the various execution paths through a (part of a) program. Once a dataflow graph
is constructed, it can be checked whether there exists a path from program start
to a variable read without coming across a write to the same variable. We showan example in the MPS example (\sect{mpsconstraints}).


\section{Constraints in Xtext}

Just like scopes, constraints are implemented in Java \todo{still true? Can
Xtend be used?}. Developers fill write methods into a validator
class generated by the Xtext project creation wizard. In the end, these
validations plug into the EMF validation framework. Other EMF\ic{ EValidator}
implementations can be used in Xtext as well.

A check method is a Java method with the following characteristics: it is
public, returns nothing, it can have any name, it has a single argument of the
type for which the check should apply, and it has the \ic{@Check} annotation. 
For example, the following method is a check that is invoked for all instances
of \ic{CustomState} (i.e. not for start states and background states):
	

\begin{code}
@Check(CheckType.NORMAL)
public void checkOrphanEndState( CustomState ctx ) {
    CoolingProgram coopro = Utils.ancestor(ctx, CoolingProgram.class);
    TreeIterator<EObject> all = coopro.eAllContents();
    while ( all.hasNext() ) {
        EObject s = all.next();
        if ( s instanceof ChangeStateStatement ) {
            ChangeStateStatement css = (ChangeStateStatement) s;
            if ( css.getTargetState() == ctx ) return;
        }
    }
    error("no transition ever leads into this state", 
    	CoolingLanguagePackage.eINSTANCE.getState_Name());
}
\end{code}


The method retrieves the cooling program that owns a state, then retrieves all
of its descendants and iterates over them. If the descendant is a \ic{ChangeStateStatement},
and if the \ic{targetState} property of the \ic{ChangeStateStatement} references
the current state, then we return: we have found a transition leading into the current
state. If we don't find one of these, we report an error. The \ic{CheckType.NORMAL}
in the annotation defines when this check should run:

\begin{itemize}
  \item CheckType.NORMAL: run when the file is saved 
  \item CheckType.FAST: run after each model change (i.e. after each keypress) 
  \item CheckType.EXPENSIVE: run only if requested via the context menu
\end{itemize}
 
% The amount of code that needs to be written for constraint checks depends a lot
% on the language used to express the constraints. Just like scoping, constraints
% basically navigate and query the model. The more efficiently a language is able
% to do that, the more suitable it is. Java is not very suitable, because it lacks
% higher order functions and chain expressions. Subsequent versions of the Xtext
% validation API are expected to be based on Xtend2, a language that has these
% features. We'll discuss it in the section on code generation and transformation.


\section{Constraints in MPS}
\label{mpsconstraints}

\subsection{Simple Constraints} 

MPS' approach to constraints is very similar to
Xtext's. The main difference is that the constraint is written in
\ic{BaseLanguage}, which is an extended version of Java that has some of the
features that makes constraints more concise. Here is the code for the same
"state unreachable" constraint, which we can make use of in the state machines
extension to C:

\begin{code}
checking rule stateUnreachable {                                                                                                                                                                         
  applicable for concept = State as state                                                                                                                                                                       
  do {                                                                                                                                                                                                          
    if (!state.initial && 
        state.ancestor<concept = Statemachine>.
            descendants<concept = Transition>.
            where({~it => it.target == state; }).isEmpty) { 
        error "orphan state - can never be reached" -> state; 
    }
  }                                                                                                                                                                                                             
}                                                                                                                                                                                                               
\end{code}

At this point there is no way to control when a constraint is run, it is decided
based on some MPS-internal algorithm. However, pressing \keystroke{F5} in a
program or explicitly running the model checker forces all constraints to be
reevaluated.

\subsection{Dataflow}

The foundation for data flow analysis is the so-called data flow graph. This is
a data structure that describes the flow of data through a program's code. For
example, in \ic{int i = 42; j = i + 1;} the 42 is "flowing" from the init
expression in the local variable declaration into the variable \lcr{i} and then,
after adding 1, into j. Data flow analysis consists of two tasks: building a
data flow graph for a program, and then performing analysis on this data flow
graph to detect problems in the program.

MPS comes with predefined data structures for data flow graphs, a DSL for
defining how the graph can be derived from language concepts (and hence,
programs), a framework for defining your own analyses on the graph as well as a
set of default analyses that can be integrated into your language. We will look
at all these ingredients in this section.

To play with the data flow graph, you can select a method in a Java program and
then use the context menu on the method; select \lcr{Language Debug -> Show Data
Flow Graph}. This will render the data flow graph graphically and constitutes a
good debugging tool when building your own data flow graphs and analyses.


\paragraph{Building a Data Flow Graph} Data flow is specified in the
\emph{Dataflow} aspect of language definitions. There, you can add
data flow builders (DFBs) for your language concepts. These are programs that
build the data flow graph for instances of those concepts in programs. Here is 
the DFB for \lcr{LocalVariableDeclaration}.
\begin{code}
data flow builder for LocalVariableDeclaration { 
  (node)->void { 
    if (node.init != null) { 
      code for node.init 
      write node = node.init 
    } else {
      nop
    }
  } 
}
\end{code}

If the \lcr{LocalVariableDecaration} has an \ic{init} expression (it is
optional!), then the DFB for the \ic{init} expression has to be executed. The
\lcr{code for} statement calls the DFB for the node that is passed as its
argument. Then we perform an actual data flow definition: the \ic{write node =
node.init} specifies that write access is performed on the current node. The
statement also expresses that whatever value was in the \ic{init} expression is
now in the node itself.

If there is no \lcr{init} expression, we still want to mark the
\lcr{LocalVariableDeclaration} node as visited --- the program flow has come
across this node. A subsequent analysis reports all program nodes that have
\emph{not} been visited by a DFB as dead code. So even if a node has no further
effect on a program's data flow, it has to be marked as visited using \lcr{nop}.

To illustrate a \lcr{read} statement, we can take a look at the
\lcr{LocalVariableRef} expression which read-accesses the variable it
references. Its data flow is defined as \ic{read node.var}, where \lcr{var} is
the name of the reference that points to the referenced variable. 

In an \lcr{AssignmentStatement}, we first execute the DFB for the \lcr{rvalue}
and then "flow" the \lcr{rvalue} into the \lcr{lvalue} --- the purpose of an 
assignment:

\begin{code}
data flow builder for AssigmentStatement { 
  (node)->void { 
    code for node.rvalue 
    write node.lvalue = node.rvalue 
  } 
}
\end{code}

For a \lcr{StatementList}, we simply mark the list as visited and then execute
the DFBs for each statement. We are now ready to inspect the data flow graph for
a simple function. \fig{dfgexample} shows the function and the graph.
\begin{figure}
\begin{center} 
  \includegraphics[width=8cm]{figures/4/dfgexample.png}
\end{center}
\caption{An example for a data flow for a simple C function. You can show the
graph by select \lcr{Language Debug -> Show Data Flow Graph} from the context
menu.}
\label{dfgexample}  
\end{figure}

Most interesting data flow
analysis has to do with loops and branching. So specifying the correct DFBs for
things like \lcr{if}, \lcr{switch} and \lcr{for} is important. As an example, we
look at the DFB for the \lcr{IfStatement}. We start with the obligatory 
\lcr{nop} to make the node as visited. Then we run the DFB
for the condition, because that is evaluated in any case. Then it becomes
interesting: depending on whether the condition is true or false, we either run
the \lcr{thenPart} or we jump to where the \lcr{else if} parts begin. Here is
the code so far:

\begin{code}
nop 
code for node.condition 
ifjump after elseIfBlock // elseIfBlock is a label defined later 
code for node.thenPart 
{ jump after node } 
\end{code}

The \lcr{ifjump} statement means that we may jump to the specified label (i.e.
we then execute the \lcr{else if}s). If not (we just "run over" the
\lcr{ifjmp}), then we execute the \lcr{thenPart}. If we execute the
\lcr{thenPart}, we are finished with the whole \lcr{IfStatement} --- no
\lcr{else if}s or \lcr{else} parts are relevant, so we jump after the current
node (the \lcr{IfStatement}) and we're done. However, there is an additional
catch: in the \lcr{thenPart}, there may be a \lcr{return} statement. So we may
never actually arrive at the \lcr{jump after node} statement. This is why it is
enclosed in curly braces: this says that the code in the braces is optional. If
the data flow does not visit it, that's fine (typically because we return from
the method before we get a chance to execute this code).

Let's continue with the \lcr{else if}s. We arrive at the \lcr{elseIfBlock} label
if the condition was false, i.e. the above \lcr{ifjump} actually happened. We
then iterate over the \lcr{elseIf}s and execute their DFB. After that, we run
the code for the \lcr{elsePart}, if there is one. The following code can only be
understood if we know that, if we execute one of the \lcr{else if}s, then we
jump \emph{after the whole \lcr{IfStatement}}. This is specified in the DFB for
the \lcr{ElseIfPart}, which we'll illustrate below. Here is the rest of the code
for the \lcr{IfStatement}'s DFB:

\begin{code}
label elseIfBlock 
foreach elseIf in node.elseIfs { 
  code for elseIf 
} 
if (node.elsePart != null) { 
  code for node.elsePart 
}
\end{code}


We can now inspect the DFB for the \lcr{ElseIfPart}. We first run the DFB for
the condition. Then we may jump to after that \lcr{else if}, because the
condition may be false and we want to try the next \lcr{else if}, if there is
one. Alternatively, if the condition is true, we then run the DFB for the body
of the \lcr{ElseIfPart}. Then two things can happen: either we jump to after
the whole \lcr{IfStatement} (after all, we have found an \lcr{else if} that is
true), or we don't do anything at all anymore because the current \lcr{else if}
contains a return statement. So we have to use the curly braces again for the
jump to after the whole \lcr{if}. Here is the code.

\begin{code}
code for node.condition 
ifjump after node 
code for node.body 
{ jump after node.ancestor<concept = IfStatement> } 
\end{code}

An example data flow graph is shown on figure \fig{ifdfg}.

\begin{marginfigure}
\begin{center} 
  \includegraphics[width=3cm]{figures/4/ifdfg.png}
\end{center}
\caption{A data flow graph for an \lcr{if} statement \ic{if ( i > 0 ) { j = 1; }
else { j = 2; } }}
\label{ifdfg}  
\end{marginfigure}


The DFB for a loop makes use of the fact that loops can be represented using
conditional branching. Here is the DFB for the \lcr{for} loop:
\begin{code}
code for node.iterator 
label start 
code for node.condition 
ifjump after node 
code for node.body 
code for node.incr 
jump after start
\end{code}

We first execute the DFB for the \lcr{iterator} (which is a kind of
\lcr{LocalVariableDeclaration}, so the DFB for it above works). Then we define a
label \lcr{start} so we can jump to this place from further down. We then
execute the \lcr{condition}. Then we have an \lcr{ifjmp} to after the whole loop
(which covers the case where the condition is false and the loop ends). In the
ohter case (the condition is still true) we execute the code for the \lcr{body}
and the \lcr{incr} part of the \lcr{for} loop We then jump to after the
\lcr{start} label we defined above.


\paragraph{Analyses} MPS supports a number of data flow analyses out of the
box. These analyses operate only on the data flow graph, so the same
analyses can be used for any language, once the DFBs for that language map
programs to data flow graphs. The following utility class uses the unreachable
code analysis: 

\begin{code}
public class DataflowUtil { 

  private Program prog; 
   
  public DataflowUtil(node<> root) { 
    prog = DataFlow.buildProgram(root); // build a program object and store it  
  } 
   
  public void checkForUnreachableNodes() { 
    // grab all instructions that are unreachable (predefined functionality) 
    sequence<Instruction> allUnreachableInstructions = 
             ((sequence<Instruction>) prog.getUnreachableInstructions()); 
    // remove those that may legally be unreachable 
    sequence<Instruction> allWithoutMayBeUnreachable = 
            allUnreachableInstructions.where({~instruction =>
                !(Boolean.TRUE.equals(instruction.
                       getUserObject("mayBeUnreachable"))); }); 
    
    // get the program nodes that correspond to the unreachable instructions 
    sequence<node<>> unreachableNodes = allWithoutMayBeUnreachable.
            select({~instruction => ((node<>) instruction.getSource()); }); 
       
    // output errors for each of those unreachable nodes 
    foreach unreachableNode in unreachableNodes { 
      error "unreachable code" -> unreachableNode; 
    } 
  } 
} 
\end{code}

The class constructs a \lcr{Program} object in the constructor. \lcr{Program}s
are wrappers around the data flow graph and provide access to a set of
predefined analyses on the graph. We will make use of one of them here in the
\lcr{checkForUnreachableNodes} method. This method extracts all unreachable
nodes from the graph (see comments in the code above) and reports errors for
them. To actually run the check, we call this method from a
\lcr{NonTypesystemRule} for C functions:

\begin{code}
checking rule check_DataFlow {                            
  applicable for concept = Function as fct                
  overrides false                                         
  do {                                                    
    new DataflowUtil(fct.body).checkForUnreachableNodes();
  }                                                       
}                                                         
\end{code}


MPS also comes with a framework for developing custom analyses; however, this is
beyond the scope of this book.


\section{Constraints in Spoofax}




\chapter{Type Systems}

Type systems are basically sophisticated constraints that check typing rules in
programs. Here is a definition from Wikipedia:

\begin{quote} 
A type system may be defined as a tractable syntactic framework for
classifying phrases according to the kinds of values they compute. A type system
associates types with each computed value. By examining the flow of these
values, a type system attempts to prove that no type errors can occur. The type
system in question determines what constitutes a type error, but a type system
generally seeks to guarantee that operations expecting a certain kind of value
are not used with values for which that operation makes no sense.
\end{quote}

In summary, type systems associate types with values and then check whether
these types conform to predefined typing rules. 

We distinguish between dynamic type systems which perform the type checks as
the program executed, and static type systems, where type checks are performed
ahead of execution, mostly based on type specifications in the program. This
section focuses exclusively on static type checks.
 
 
\section{Type System Basics}

To introduce the basic concepts of type systems, let us go back to the example
used at the beginning of the section on syntax. As a reminder here is the
example code, and \fig{astexample-again} shows the abstract syntax tree. 


\begin{code}
var x: int;
calc y: int = 1 + 2 * sqrt(x)
\end{code}
 

\begin{figure}[ht]
\begin{center}
  \includegraphics[scale=0.6]{figures/1/astexample.png}
  \caption[]{Abstract syntax tree for the above program. Boxes
  represent instances of language concepts, solid lines represent containment,
  dotted lines represent cross-references}
  \label{astexample-again} 
\end{center}
\end{figure}

Using this example, we can illustrate in more detail what type systems have to
do:

\begin{description}

  \item[Declare Fixed Types] Some program elements have fixed types. They don't
  have to be derived or calculated, they are always the same and previously
  known. Examples include the \ic{IntConst} (whose type is \ic{IntType}), the \ic{sqrt} concept
  (whose type is \ic{double}), as well as the type declarations themselves (the type
  of \ic{IntType} is \ic{IntType}, the type of \ic{DoubleType} is \ic{DoubleType}).

  \item[Derive Types] For some program elements, the type has to be derived
  from the types of other elements. For example, the type of a \ic{VarRef} (the
  variable reference) is the type of the referenced variable. The type of a
  variable is the type of it's declared type. In the example above, the type of
  \ic{x} and the reference to \ic{x} is \ic{IntType}.

  \item[Calculate Common Types] Most type systems have some kind of type
  hierarchy. In the example, \ic{IntType} is a subtype of \ic{DoubleType}
  (\ic{IntType} can be used wherever \ic{DoubleType} is expected). A type system
  has to support the specification of such subtype relationships. Also, the type
  of certain program elements may be calculated from the arguments passed to
  them; in many cases the resulting type will be the "more general one".
  examples are the \ic{Plus} and \ic{Multi} constructs: if the left and right
  arguments are two \ic{IntTypes}, the result is an \ic{IntType}. In case of
  two \ic{DoubleType}s, the result is a \ic{DoubleType}. If an \ic{IntType} and a
  \ic{DoubleType} are used, the result is a \ic{DoubleType}, the more general of the
  two.

  \item[Type Checks] Finally, a type system has check for type errors and report
  them to the language user. In the example, a type error would occur if
  something with a \ic{DoubleType} were assigned to an \ic{IntType} variable.

\end{description}

Note that the type of a program element is not generally the same as it's
language concept. For example, the concept (meta class) of the number \ic{1} is
\ic{IntConst} and its type is \ic{IntType}. The type of the \ic{sqrt} is \ic{DoubleType} and its
concept is \ic{Sqrt}. Only for type declarations themselves the two are (usually) the
same: the type of an \ic{IntType} is \ic{IntType}. Often several
instances of the same concept can have different types: a \ic{+} calculates it's
type as the more general of the two arguments. So the type of each \ic{+}
instance depends on what kinds of arguments the particular instance has.
 
The core of a type system can be considered to be a function \ic{typeof} that
calculates the type for a program element: $$typeof ::= element => type$$ 
Types are often represented with the same technology as the language concepts.
As we will see, in case of MPS types are just nodes, i.e. instances of concepts.
In Xtext, we use \ic{EObjects}, i.e. instances of \ic{EClasses} as types \MV{Spoofax?}. In
both cases, we even define the concepts as part of the language. This is useful
because most of the concepts used as types also have to be used in the program
text whenever types are explicitly declared (as in \ic{var x: int}).



\section{Type Calculation Strategies}

In the end, the \ic{typeof} function can be implemented in any way suitable; after
all, it is just program code. However, in practice, three approaches seem to be
used most: recursion, unification and pattern matching. We will explore each of
these conceptually, and then provide examples in the tool sections.


\MV{Eelco mentioned something about Data Flow stuff in Scala. Should we add
this? Does anyone know something about that?}


\subsection{Recursion}

Recursion is widely used in computer science. According to Wikipedia, it refers
to 

\begin{quote}
a method of defining functions in which the function being defined is
applied within its own definition.
\end{quote}

The standard example is the calculation of factorial, where the \ic{factorial}
function calls itself:

\begin{code}
int factorial( int n ) {
    if ( n <= 1 ) return 1;
    else return n * factorial( n-1 );
}
\end{code}
 

In the context of type systems, the recursive approach for calculating a type
defines a polymorhphic function \ic{typeof}, which takes a program element and
returns its type, while calling itself to calculate the types of those elements on which
its own type depends. 

Let us consider the following example grammar (we use Xtext notation here):

\begin{code}
LocalVarDecl:
    "var" name=ID ":" type=Type ("=" init=Expr)?;
\end{code}
 

The following examples are structurally valid example sentences:
 
\begin{code}
var i: int          // 1
var i: int = 42     // 2
var i: int = 33.33  // 3
var i = 42          // 4
\end{code}
 

Let's develop the pseudo-code for \ic{typeof} function the \ic{LocalVarDecl}. 
A first attempt could look as follows:

 
\begin{code}
typeof( LocalVarDecl lvd ) {
	return typeof( lvd.type )
}

typeof( IntType it ) { return it }
typeof( DoubleType dt ) { return dt }
\end{code}
 

Notice how the \ic{typeof} for \ic{LocalVarDecl} recursively calls \ic{typeof}
for its \ic{type} property. Recursion ends with the \ic{typeof} functions for
the types; they return themselves. This implementation successfully calculates
the type of the \ic{LocalVarDecl}, but it does not address the type check that
makes sure that, if an \ic{init} expression is specified, it has the same type
(or a subtype) of the \ic{type} property. This could be achieved as follows:

 
\begin{code} 
typeof( LocalVarDecl lvd ) {
    if isSpecified lvd.init { 
        assert typeof( lvd.init ) isSameOrSubtypeOf typeof( lvd.type )
    } 
    return typeof( lvd.type )
}
\end{code}

Notice in the grammar that the specification of the variable type (in the
\ic{type} property) is also optional. So we have create a somewhat more
elaborate version of the function:

 
\begin{code} 
typeof( LocalVarDecl lvd ) {
    if !isSpecified lvd.type && !isSpecified lvd.init 
        raise error
        
    if isSpecified lvd.type && !isSpecified lvd.init
    	return typeof( lvd.type )
    	
    if !isSpecified lvd.type && isSpecified lvd.init
    	return typeof( lvd.init )
    	 
    if isSpecified lvd.type && isSpecified lvd.init {
        assert typeof( lvd.init ) isSameOrSubtypeOf typeof( lvd.type )
        return typeof( lvd.type )
    } 
}
\end{code}


This code is quite verbose. Assuming that assertions are ignored if one
of the called \ic{typeof} functions returns \ic{null} because the argument is 
not specified, we can simplify this to the following code. 

 
\begin{code} 
typeof( LocalVarDecl lvd ) {
    assert isSpecified lvd.type || isSpecified lvd.init
    assert typeof( lvd.init ) isSameOrSubtypeOf typeof( lvd.type )
    return typeof( lvd.type )
}
\end{code}

This is probably the shortest version of the code that can be imagined using
recursive function calls and a suitable language\footnote{Note how ignoring 
an assertion if an argument is \ic{null} is a good example of custom semantics
that is useful for a given purpose. Essentially, we have just defined a DSL for
type calculations based on recursive function calls)}.


\subsection{Unification}

Unification is the second well-known approach to type calculation. Once again we
start with a definition from Wikipedia:

\begin{quote}
Unification is an operation [..] which produces from [..] logic terms a 
substitution which [..] makes the terms equal modulo some equational theory.
\end{quote}

While this sounds quite sophisticated, we have all used unification in
high-school for solving sets of linear equations. The "equational theory" is 
algebra. Here is an example: 

\begin{code} 
(1) 2 * x == 10
(2) x + x == 10 
(3) x + y == 2 * x + 5
\end{code}

Substitution refers to assignment of values to \ic{x} and \ic{y}. A solution
is \ic{x := 5, y := 10}.

Using unification for type systems means that language developers specify a
number of type equations which contain type variables (cf the \ic{x} and \ic{y}) as well
as type values (the numbers in the above example). Some kind of engine is then
trying to make all equations be true by assigning type values to the type
variables in the type equations.

The interesting property of this approach is that there is no distinction
between typing rules and type checks. We simply specify a set of equations that
must be true for the types to check. If an equation cannot be satisfied for any
assigment of type values to type variables, a type error is detected. To
illustrate this, we return to the \ic{LocalVarDecl} example introduced above.
 
\begin{code}
var i: int          // 1
var i: int = 42     // 2
var i: int = 33.33  // 3
var i = 42          // 4
\end{code}
 

The following two type equations constitute the complete type system
specification. The \ic{:==:} operator expresses type equation (left side must be
the same type as right side), \ic{:<=:} refers to subtype-equation (left side
must be same type or subtype of right side, the pointed side of \ic{<} points
to the "smaller", more specialized type). The operators are taken from MPS,
which uses this technique.

 
\begin{code}
typeof( LocalVarDecl.init ) :<=: typeof( LocalVarDecl.type) 
typeof( LocalVarDecl ) :==: typeof( LocalVarDecl.type ) 
\end{code}
 

Let us look at the four examples cases. We use capital letters for free type
variables. In the first case, the \ic{init} expression is not given, so the first
equation is ignored. The second equation can be satisfied by assigning \ic{T}, the
type of the variable declaration, to be int. The second equations acts as a type
derivation rule and makes the type of the overall \ic{LocalVarDecl} \ic{int}.

\begin{code}
var i: int          // 1

typeof( int ) :<=: typeof( -null- ) // ignore
typeof( T ) :==: typeof( int )      // T := int
\end{code}
 


In the second case the \ic{type} and the \ic{init} expression are given, and
both have types that can be calculated independent of the equations specified
for the \ic{LocalVarDecl} (they are fixed). So the first equation has no free
type variables, but it is true with the type values specified (two \ic{int}s).
Notice how in this case the equation acts as a type check: if the equation were
not true for the two given values, a type error would be reported. The second 
equation works the same as above, deriving \ic{T} to be \ic{int}.
 
\begin{code}
var i: int = 42     // 2

typeof( int ) :<=: typeof( int )    // true
typeof( T ) :==: typeof( int )      // T := int
\end{code}
 

The third case is similar to the second case; but the first equation, in which
all types are specified, is not true, so a type error is raised.

 
\begin{code}
var i: int = 33.33    // 3

typeof( int ) :<=: typeof( double ) // error!
typeof( T ) :==: typeof( int )      // T := int
\end{code}
 

Case four is interesting because no variable type is explicitly specified; the
idea is to use what's known as type inference to derive the type from the \ic{init}
expression. In this case there are two free variables in the equations,
substituting both with \ic{int} solves both equations. Notice how the unification
approach automatically leads to support for type inference!

 
\begin{code}
var i = 42     // 4

typeof( U ) :<=: typeof( int )  // U := int
typeof( T ) :==: typeof( U )    // T := int
\end{code}
 


To further illustrate how unification works, consider the following example
where we try to provide typing rules for array types, incl. array initializers.

 
\begin{code}
var i: int[]
var i: int[] = {1, 2, 3}
var i = {1, 2, 3}
\end{code}
 

Compared to the \ic{LocalVarDecl} example above, the additional complication in
this case is that we need to make sure that \emph{all} the initialization
expressions (inside the curly braces) have the same or compatible types. Here
are the typing equations:
 
\begin{code}
type var T
foreach ( e: init.elements ) 
    T :<=: typeof(e)
typeof( LocalVarDecl.type ) :<=: t
typeof( LocalVarDecl ) :==: typeof( LocalVarDecl.type ) 
\end{code}
 

We introduce an additional type variable \ic{T} and iterate over all the
expression in the array initializer, establishing an equation between each of
these elements and \ic{T}. This results in a set of equations that \emph{each}
must be satisfied. The only way to achieve this is that all array initializer
members are of the same (sub-)type. In the examples, this makes \ic{T} to be
\ic{int}. The rest of the equations works as explained above. Notice that if
we'd write \ic{var i = \{1, 33.33, 3\}}, then \ic{T := double}, but the
equations would still work because we use the \ic{:<=:} operator.


\subsection{Pattern Matching}

In pattern matching, we simply list the possible combinations of types
in a big table. Cases that are not listed in the table will result in errors.
For our \ic{LocalVarDecl} example, such a table could look like the following:

\vspace{5mm}
\begin{tabular}{l l l}
\ic{typeof(type)} & \ic{typeof(init)} & \ic{typeof(LocalVarDecl)}\\
\hline
\ic{int} & \ic{int} & \ic{int}\\
\ic{int} & - & \ic{int}\\
- & \ic{int} & \ic{int}\\
\ic{double} & \ic{double} & \ic{double}\\
\ic{double} & - & \ic{double}\\
- & \ic{double} & \ic{double}\\
\ic{int} & \ic{double} & \ic{int}\\
\ic{double} & \ic{int} & \ic{int}\\
\end{tabular}
\vspace{5mm}
 
To avoid repeating everything for all valid types, variables could be used. \ic{T+}
refers to \ic{T} or subtypes of \ic{T}.


\vspace{5mm}
\begin{tabular}{l l l}
\ic{typeof(type)} & \ic{typeof(init)} & \ic{typeof(LocalVarDecl)}\\
\hline
\ic{T} & \ic{T} & \ic{T}\\
\ic{T} & - & \ic{T}\\
- & \ic{T} & \ic{T}\\
\ic{T} & \ic{T+} & \ic{T}\\
\end{tabular}



\section{Xtext Example}

Up until version 1.0, Xtext provided no support for implementing type systems
(beyond implementing everything manually and plugging it into the constraints).
In 2.0 a type system integrated with the JVM's type system is available. Since
it is limited to JVM-related types, it is not as versatile as it could be.

As a consequence, two third-party libraries have been developed: the Xtext
Typesystem Framework (developed by the
author\footnote{http://code.google.com/a/eclipselabs.org/p/xtext-typesystem/},
and XTypes (developed by Lorenzo
Bettini\footnote{http://xtypes.sourceforge.net/}. In the remainder of this
section we will look at the Xtext Typesystem Framework\todo{and briefly at the
JVM type system integration}.


\paragraph{Xtext Typesystem Framework} The Xtext Typesystem Framework is
fundamentally based on the recursive approach. It provides an interface
\ic{ITypesystem} with a method \ic{typeof( EObject )} which returns the type for the
program element passed in as an argument. In its simplest form, the interface
can be implemented manually with arbitrary Java code. To make sure type errors
are reported as part of the Xtext validation, the framework has to be integrated
into the validation framework manually:

 
\begin{code}
@Inject 
private ITypesystem ts;

@Check(CheckType.NORMAL)
public void validateTypes( EObject m ) {
    ts.checkTypesystemConstraints( m, this );
}    
\end{code}
 

As we have discussed above, most type systems are built from a limited set of
typing strategies (assigning fixed types, deriving the type of an element from
one of its properties, calculating the type as the common type of its two
arguments). The \ic{DefaultTypesystem} class implements \ic{ITypesystem} and
provides support for declaratively specifying these strategies. In the code
below, the initialize method defines one type (the type of the \ic{IntType} is a
clone of itself) and defines one typing constraint (the \ic{expr} property of the
\ic{IfStatement} must be a Boolean). Also, for types which cannot be specified
declaratively, an operation \ic{type(..)} can be implemented to programmatically
define types.

 
\begin{code}
public class CLTypesystem extends CLTypesytemGenerated {

    private CoolingLanguagePackage cl = CoolingLanguagePackage.eINSTANCE;
    
    @Override
    protected void initialize() {
        try { 
            useCloneAsType(cl.getIntType());
            ensureFeatureType(cl.getIfStatement(), 
                cl.getIfStatement_Expr(), cl.getBoolType());
        } catch ( TypesystemConfigurationException tsce ) {
            tcse.printStackTrace();
        }            
    }
        
    public EObject type( NumberLiteral s, TypeCalculationTrace trace ) {
        if ( s.getValue().contains(".")) {
            return create(cl.getDoubleType());
        }
        return create(cl.getIntType());
    }
}
\end{code}
 

In addition to the API used in the code above, the Typesystem Framework also
comes with a textual DSL to express typing rules. From the textual type system
specification, a generator generates the implementation of the Java class that
implements the type system using the APIs. In that sense, the DSL is just a
facade on top of a framework; however, this is a nice example of how a DSL can
provide added value over a framework or API (\fig{fig:xtext-typesyseditor} shows
a screenshot):

\begin{itemize}
  \item the notation is much more concise compared to the API
  \item code completion into the target language meta model is provided
  \item if the typing rules are incomplete, a static error is shown in the
  editor, as opposed to getting runtime error during initialization of the 
  framework (see the warning in (\fig{fig:xtext-typesyseditor})
  \item \keystroke{Ctrl-Click} on a property jumps to the typing rule
  that defines the type for that property.
\end{itemize}



\begin{figure}[ht]
\begin{center} 
  \includegraphics[scale=0.7]{figures/2/xtext-typesyseditor.png}
  \caption[]{The Xtext-based editor for the type system specification
  DSL provided by the Xtext Typesystem Framework. It is a nice example of the
  benefits of a DSL over an API (on which it is based), since it can statically
  show inconsistencies in the type system definition, has a more concise syntax
  and provides customized go-to-definition functionality.}
  \label{fig:xtext-typesyseditor} 
\end{center}
\end{figure}


\paragraph{Type system for the Cooling language} The complete type system for
the cooling language is 200 lines of DSL code, and another 100 lines of Java
code. We'll take a look at some representative examples.

Primitive types usually use a copy of themselves as their type. It has to be a
copy as opposed to the object itself, because the actual program element must
not be pulled out of the EMF containment tree. This is specified as follows:

\begin{code}
typeof BoolType -> clone
typeof IntType -> clone
typeof DoubleType -> clone
typeof StringType -> clone
\end{code}

For concepts that have a fixed type, but not a clone, the type can simply be
specified:

 
\begin{code}
typeof StringLiteral -> StringType
\end{code}
 

Type systems are most important, and most interesting, in the context of
expressions. Since all expressions derive from the abstract \ic{Expr} concept, we can
declare that this class is abstract, and hence no typing rule is given. However,
the editor reports a warning if there are concrete subclasses of an abstract
class for which no type is specified either.

 
\begin{code}
typeof Expr -> abstract
\end{code}
 

The notation provided by the DSL groups typing rules and type checks for a
single concept. The following is the typing information for the \ic{Plus}
concept. It declares the type of \ic{Plus} to be the common type of the
\ic{left} and \ic{right} arguments ("the more general one") and then adds two
constraints that check that the \ic{left} and \ic{right} argument are either
\ic{string}s, \ic{int}s or \ic{double}s.

 
\begin{code}
typeof Plus -> common left right {
    ensureType left :<=: StringType, IntType, DoubleType
    ensureType right :<=: StringType, IntType, DoubleType
} 
\end{code}
 

The typing rules for \ic{Equals} are also interesting. It specifies that the
resulting type is \ic{boolean} that the \ic{left} and \ic{right} arguments must
be \ic{COMPARABLE}, and that the left and right arguments are compatible.
\ic{COMPARABLE} is a so-called type characteristic: this can be considered as
collection of types. In this case it is \ic{IntType}, \ic{DoubleType}, and
\ic{BoolType}. The \ic{:<=>:} operator describes unordered compatibility: the
types of the two properties \ic{left} and \ic{right} must either be the same, 
or \ic{left} must be a subtype or \ic{right}, or vice versa.
 
\begin{code}
characteristic COMPARABLE {
    IntType, DoubleType, BoolType
}
typeof Equals -> BoolType {
    ensureType left :<=: char(COMPARABLE)
    ensureType right :<=: char(COMPARABLE)
    ensureCompatibility left :<=>: right
}
\end{code}
 

There is also support for \emph{ordered} compatibility, as can be seen from the
typing rule for \ic{AssignmentStatement} below. It has no type (it is a
statement!), but the \ic{left} and \ic{right} argument must exhibit ordered
compatibility: they either have to be the same types, or \ic{right} must be a subtype
of \ic{left}, \emph{but not vice versa}.

 
\begin{code}
typeof AssignmentStatement -> none {
    ensureCompatibility left :<=: right
}
\end{code}
 



\section{MPS Example}

MPS includes a DSL for type system rule definition. It is based on
unification, and to some extent, pattern matching. 

The type of a \ic{LocalVariableReference} is calculated with the following typing
rule\footnote{Since only the expression within the \ic{do \curlies{ ... }} block has
to be typed by the developer, we'll only show that expression in future
examples.}. It establishes an equation between the type of the
\ic{LocalVariableReference} itself and the variable it references. \ic{typeof}
is a built-in operator returns the type for its argument.

 
 
\begin{code}
rule typeof_LocalVariableReference {                    
  applicable for concept = LocalVariableReference as lvr
  overrides false                                       
                                                        
  do {                                                  
    typeof(lvr) :==: typeof(lvr.variable);              
  }                                                     
}                                                       
\end{code}
 

The rules for the boolean \ic{NotExpression} contains two equations. The first
one makes sure that the negated expression is boolean. The second one types the
\ic{NotExpression} itself to be boolean. Just as in Xtext, in MPS types are
instances of language concepts. In MPS there are two different ways how language
concepts can be instantiated. The first one (as shown in the first equation)
uses the BaseLanguage \ic{new} expression. The second one uses a quotation,
where "a piece of tree" can be inlined into program code. It uses the concrete
syntax of the quoted construct --- here: a \ic{BooleanType} --- in the 
quotation.

 
\begin{code}
typeof(notExpr.expression) :==: new node<BooleanType>(); 
typeof(notExpr) :==: <boolean>; 
\end{code}
 

A more interesting example is the typing of structs. Consider the
following piece of C code:

 
\begin{code}
struct Person {
    char* name;
    int	age;
}

int addToAge( Person p, int delta ) {
    return p.age + delta;
}
\end{code}
 

At least two program elements have to be typed: the parameter \ic{p} as well as
the \ic{p.age} expression. The type of the \ic{FunctionParameter} concept is the
type of its type: 

\begin{code}
typeof(parameter) :==: typeof(parameter.type);
\end{code}


This is not specific to the fact that the parameter refers to a \ic{struct}. The
language concept that represents the \ic{Person} type in the parameter is a
\ic{StructType}. A \ic{StructType} refers to the \ic{StructDeclaration} it
represents a type of and extends \ic{Type}, which acts as the super type for all
types in mbeddr C. So in essence, this means that the type of \ic{p} is an
instance of \ic{StructType} that has a pointer to the \ic{StructDeclaration}
\ic{Person}.
\begin{marginfigure}[-2cm]
  \includegraphics[width=5cm]{figures/4/structtype.png}
  \caption{Structure Diagram of the language concepts involved in typing
  \ic{struct}s.}
  \label{structtype}
\end{marginfigure} 

\ic{p.age} is an instance of a \ic{StructAttributeReference}. It is defined as
follows. It is an expression, owns another expression property (on the left of
the dot) as well as a reference to a \ic{StructAttribute} (\ic{name} or \ic{age}
in the example).\begin{marginfigure}[2cm]
  \includegraphics[width=5cm]{figures/4/structattrref.png}
  \caption{Structure Diagram of the language concepts involved in references to
  \ic{struct} attributes.}
  \label{structattrref}
\end{marginfigure} 

 
\begin{code}
concept StructAttributeReference extends Expression
                                 implements ILValue
  children:                                        
    Expression context 1 specializes: <none>        
                                                   
  references:                                      
    StructAttribute attribute 1 specializes: <none>  
\end{code}
 
                                                   
The typing rule for the \ic{StructAttributeReference} looks as follows. The \ic{context},
the expression on which we use the dot operator, has to be a \ic{GenericStructType},
or a subtype thereof (i.e. a \ic{StructType} which points to an actual
\ic{StructDeclaration}). Second, the type of the whole expression is the type of the
reference \ic{attribute} (e.g. \ic{int} in case of \ic{p.age}). 

 
\begin{code}
typeof(structAttrRef.context) :<=: new node<GenericStructType>(); 
typeof(structAttrRef) :==: typeof(structAttrRef.attribute);
\end{code}
 

This example also illustrates the interplay between the type system and other
aspects of language definition, specifically scopes. The referenced
\ic{StructAttribute} (on the right side of the dot) may only reference a
\ic{StructAttribute} that is part of the the \ic{StructDeclaration} that is referenced
from the \ic{StructType}. The following scope definition illustrates this:

 
\begin{code}
link {attribute} 
  search scope: 
    (model, scope, referenceNode, linkTarget, enclosingNode)->join(ISearchScope | sequence<node< >>) { 
      node<> varType = referenceNode.variable.type; 
      if (varType.isInstanceOf(StructType)) { 
        return (varType as StructType).struct.attributes;
      } else { 
        return null; 
      } 
    } 
\end{code}
 

As we will discuss in the chapter on language extension and composition, MPS
supports incremental extension of existing languages. Extensions may also
introduce new types, and, specifically, may allow existing operators to be used
with these new types. This is facilitated by MPS' use for pattern matching in
the type system, specifically for binary operators such as \ic{+}, \ic{>} or
\ic{==}. As an example consider the introduction of complex numbers into C. It
should be possible to write code like this:

 
\begin{code}
complex c1 = (1, 2i);
complex c2 = (3, 5i);
complex c3 = c1 + c2; // results in (4, 7i)
\end{code}
 

The \ic{+} in \ic{c1 + c2} should be the \ic{+} defined by the original
language. Alternatively, we could define a new \ic{+} for complex numbers. While
this would work technically (remember there is no parser ambiguity problems), it
would mean that users, when entering a \ic{+}, would have to decide between the
original plus and the new plus for complex numbers. This would not be very
convenient from a usability perspective. By reusing the original plus we avoid
this problem.

However, reusing the original \ic{+} requires that the typing rules defined for
\ic{PlusExpression} in the original C language will now have to accept complex
numbers; the original typing rules must be extended. To enable this, MPS
supports so-called overloaded operations containers. The following container,
taking from the mbeddr C core language, defines the type of \ic{+} and \ic{-} ifboth arguments are \ic{int} or \ic{double}.
 
\begin{code}
overloaded operations rules binaryOperation                                                                          
                                                                                                                     
operation concepts: PlusExpression | MinusExpression
left operand type: <int> is exact: false use strong subtyping false                                                  
right operand type: <int> is exact: false use strong subtyping false                                                 
operation type: (operation, leftOperandType, rightOperandType)->node<> { 
  <int>; 
}                                            

operation concepts: PlusExpression | MinusExpression
left operand type: <double> is exact: false use strong subtyping false                                                  
right operand type: <double> is exact: false use strong subtyping false                                                 
operation type: (operation, leftOperandType, rightOperandType)->node<> { 
  <double>; 
}                                            
\end{code}
 

To integrate these definitions with the regular typing rules, the following
typing rule must be written\footnote{Note that only one such rule must be
written for all binary operations. Everything else will be handled with the
overloaded operations containers}. Using the \ic{operation type} construct, the
typing rules ties in with overloaded operation containers.

 
\begin{code}
rule typeof_BinaryExpression {                                                                                                                                                                                                                                                                                                                                           
  applicable for concept = BinaryExpression as be                                                                                                                                                                                                                                                                                                                        
  overrides false                                                                                                                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                                                                                         
  do {                                                                                                                                                                                                                                                                                                                                                                   
    when concrete (typeof(be.left) as left) { 
        when concrete (typeof(be.right) as right) { 
            node<> optype = operation type( be , left , right ); 
            if (optype != null) { 
                typeof(be) :==: optype; 
            } else { 
                error "operator " + be.concept.name + 
                      " cannot be applied to " +
                      left.concept.name + "/" 
                      + right.concept.name -> be; 
            } 
        } 
    }
  }    
}                                                                                                                                                                                                                                                                                                                                                                    
\end{code}
 

The important aspect of this approach is that overloaded operation containers
are \emph{additive}. Language extensions can simply contribute \emph{additional}
containers. For the complex number example, this could look like the following:
we declare that as soon as one of the arguments is of type complex, the
resulting type will be complex as well.

 
\begin{code}
operation concepts: PlusExpression | MinusExpression                                     
one operand type: <complex> is exact: false use strong subtyping false     
is applicable:                                                         
<no isApplicable>                                                      
operation type:                                                        
(operation, leftOperandType, rightOperandType)->node<> { 
  <complex>; 
}                       
\end{code}
 


The type system DSL in MPS covers a large fraction of the type system rules
encountered in practice. BaseLanguage, which is an extension of Java, covers the
whole Java type system this way. However, for exceptional cases, procedural
BaseLanguage code can be used to implement type checks as well.

\section{Spoofax Example}


Explain why expressions are different than "normal" programs
(precedence, etc.)

Show how Xtext, MPS and SDF do it differently

Explain why type systems are important in this context, although they
are "just constraints". Use as basis:
  TypesystemsForDSLs.pdf in the materials directory

explicit types vs. full type inference vs. local type inference

Recursion, Unification, Pattern Matching, Data Flow stuff (Scala, Eelco?)

attribute grammars