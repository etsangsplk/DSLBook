\chapter{Transformation and Generation}

Transformation of models is an essential step in working with DSLs. We
typically distinguish between two different cases: if models are transformed
into other models we call this \emph{model transformation}. If models are transformed
into text (usually programming language source code) we refer to \emph{code
generation}. However, as we will see in the examples below, depending on the
approach and tooling used, this distinction is not always easy to make, and the
boundary becomes blurred.

A fundamentally different approach to processing models is
\emph{interpretation}. While in case of transformation and generation the model
is migrated to artifacts expressed in a different language, in case of
interpretation no such change happens. Instead, an interpreter traverses a model
and directly performs actions depending on the contents of the AS. Strictly
speaking, we have already seen examples of interpretation in the sections on
constraints and type systems: constraint and type checks can be seen as an
interpreter where the actions performed as the tree is traversed are checks of
various kinds. However, the term interpretation is typically only used for cases
where the actions actually \emph{execute} the model. Execution refers to performing the
actions that are associated with the language concepts as defined by the
(dynamic) semantics of the concepts. A later chapter explores the notions of
semantics in more detail.

We elaborate on the trade-offs between transformation and generation vs.
interpretation in the chapter on language design \todo{}.

\section{Overview of the approaches}

Classical code generation traverses a program's AST and outputs programming
language source code (or other textual output). In this context, a clear
distinction is made between models and source code. Models are represented as an
AST expressed with some preferred AST formalism (or meta meta model); an API
exists for the programmer to interact with the AST. In contrast, the generated
source code is treated as text, i.e. a sequence of characters. The tool of
choice for transforming an AST into text are template languages. They support
the syntactic mixing of model traversal code and to-be-generated text. The two
are separated using some escape character. Since the generated code is treated
merely as text, there is no language awareness (and corresponding tool support)
for the target language while editing templates. Xtend2, the language used for
code generation in Xtext is an example of this approach.

Classical model transformation is the other extreme in that it works with ASTs
only and does not consider the concrete syntax of the either the source or the
target languages. The source AST is transformed using the source language AS API
and a suitable traversal language. As the tree is traversed, the API of the
target language AS is used to assemble the target model. For this to work
smoothly, most specialized transformation languages assume that the source and
target models are build with the same AST formalism (e.g. EMF Ecore). Model
transformation languages typically provide support for efficiently navigating
source models, and for creating instances of AS of the target language (tree construction). 
Examples for this approach once again include Xtext's Xtend2 as well as QVT
operational and ATL. MPS can also be used in this way. A slightly different approach
establishes relationships between the source and target models instead of
"imperatively" constructing a target tree as the source is traversed. While this
is often less intuitive to write down, the approach has the advantage that it
supports transformation in both directions, and also supports model diff. QVT
relational is an example of this approach.
\marginnote{Note that code generators and transformations fit our
definition of interpreters: they traverse a model and perform actions: creating
artifacts in a target language.}



In addition to the two classical cases described above, there are also hybrid
approaches that blur the boundaries between these two clear cut extremes. They
are based on the support for language modularization and composition in the
sense that the template language and the target language can be composed. As a
consequence, the tooling is aware of the syntactic structure and the static
semantics of the template language \emph{and} the target language. Both MPS and
Spoofax/SDF support this approach.


In MPS, program is projected and every editing operation directly modifies the
AST, while using a textual-looking notation as the user interface. Template code
and target-language code can be represented as nested ASTs, each using its own
textual syntax. MPS uses a slightly different approach based on annotations
\MV{Have we introduced annotations already?}: As we have elaborated previously,
projectional editors can store arbitrary information in an AST. Specifically, it
can store information that does not correspond to the AS as defined by the
language we want to represent ASTs of. MPS code generation templates exploit
this approach: template code is fundamentally an instance of the target
language. This "example model" is then annotated with template annotations that
define how the example model relates to the source model, and which example
nodes must be replaced by (further transformed) nodes from the source model. The
MPS example below will elaborate on this approach.


Spoofax, with its Stratego transformation language uses a similar approach based
on parser technology. As we have already seen, the underlying grammar formalism
supports flexible composition of grammars. So the template language and the
target language can be composed, retaining tool support for both of these
languages. Execution of the template actually directly constructs an AST of the
target language, using the concrete sytnax of the target language to specify its
structure. The Spoofax example will provide details.



\section{Xtext Example}

\subsection{Generator}

\subsection{Model-to-Model Transformation}

\section{MPS Example}
 
As we have seen above, the distinction between code generators and
model-to-model transformations is much less clear in MPS. While there is a
specialized language for ASCII text generation it is really just used "at the
end" of the transformation chain as a language like Java or C is generated to
text so it can be passed to existing compilers. \fig{mps-textgen} shows the
\ic{textgen} component for mbeddr C's \ic{IfStatement}. MPS' text generation
language basically appends text to a buffer. We won't discuss this aspect of MPS
any futher, since MPS textgen is basically a wrapper language around a
\ic{StringBuffer}. However, this is perfectly adequate for the task at hand,
since it is only used in the last stage of generation where the AST is
essentially structurally identical to the generated text.
 
\begin{figure}[ht]
\begin{center}
  \includegraphics[scale=0.7]{figures/6/mps-textgen.png}
  \caption[labelInTOC]{}
  \label{mps-textgen} 
\end{center} 
\end{figure}


DSLs and language extensions typically use model-to-model transformations to
"generate" code expressed in a low level programming language. In general,
writing transformation in MPS involves two ingredients. Templates define the
actual transformation. Mapping configurations define which template to run when
and where. Templates are valid sentences of the target language. So-called
macros are used to express dependencies on and queries over the input model. For
example, when the guard condition (a C expression) should be generated into an
\ic{if} statement in the target model, you first write an \ic{if} statement with a dummy
condition into the template. The following would work: \ic{if (true) \{\}}. Then
the nodes that should be replaced by the
transformation with nodes from the input model are annotated with macros. In our
example, this would look like this: \ic{if (COPY\_SRC[true])\{\}}. Inside the
\ic{COPY\_SRC} macro you put an expression that describes which elements from 
the input model should replace the dummy node \ic{true}: \ic{node.guard;}
would use the guard condition of the input node (expected to be of type
\ic{Transition} here). When the transformation is executed, the \ic{true} node
will be replaced by what the macro expression returns --- in this case, theguard of the input transition.


\paragraph{Translating the State Machine}


State machines live inside modules. Just like \ic{struct}s they can be
instantiated. The following code shows an example. Notice the two global
variables \ic{c1} and \ic{c2}, which are instances of the same state machine
\ic{Counter}.

\begin{code}
module Statemachine from cdesignpaper.statemachine imports nothing { 
   
  statemachine Counter { 
  in events 
    start() <no binding> 
    step(int[0..10] size) <no binding> 
  out events 
    started() <no binding> 
    resetted() <no binding> 
    incremented(int[0..10] newVal) <no binding> 
  local variables 
    int[0..10] currentVal = 0 
    int[0..10] LIMIT = 10 
  states ( initial = start ) 
    state start { 
      on start [ ] -> countState { send started(); } 
    } 
    state countState { 
      on step [currentVal + size > LIMIT] -> start { send resetted(); } 
      on step [currentVal + size <= LIMIT] -> countState { 
        currentVal = currentVal + size; 
        send incremented(currentVal); 
      } 
      on start [ ] -> start { send resetted(); } 
    } 
  }
  
  var Counter c1; 
  var Counter c2; 
   
  void aFunction() { 
    trigger(c1, start); 
  } 
}
\end{code}


State Machines are translated to the following lower level C entities:

\begin{itemize}
  \item an \ic{enum} for the states, with a literal for each state
  \item an \ic{enum} for the events, with a literal for each event
  \item a \ic{struct} declaration that contains an attribute for the
  current state, as well as attributes for the local variables declared in the
  state machine
  \item and finally, a function that implements the behaviour of the state
  machine using a \ic{switch} statement. The function takes two arguments: one
  named \ic{instance} typed with the \ic{struct} mentioned in the previous
  item, and one named \ic{event} that is typed to the event \ic{enum}
  mentioned above. The function checks whether the instance's current state can
  handle the event passed in, evaluates the guard, and if a transition fires,
  executes exit and entry actions and updates the current state.
\end{itemize} 

This high level structure is clearly discernable from the two main templates
shown in \fig{mps-sm-gen-1} and \fig{mps-sm-gen-2}. 

\begin{figure}[h]
\begin{center}
  \includegraphics[width=11cm]{figures/6/mps-sm-gen-1.png}
  \caption[labelInTOC]{}
  \label{mps-sm-gen-1} 
\end{center} 
\end{figure}


The MPS transformation engine works in phases. Each phase transforms models
expressed in some languages to other models expressed in the same or other
languages. Model element for which no transformation rules are specified are
simply copied. Reduction rules are used to intercept program elements and
transform them as generation progresses through the phases. \fig{mps-gen-phases}
shows how this affects state machines. A reduction rule is defined that maps
state machines to the various elements we mentioned above. Notice how the
surrounding module remains unchanged, because no reduction rule is defined for
it. 

\begin{figure}[ht]
\begin{center}
  \includegraphics[scale=0.7]{figures/6/mps-gen-phases.png}
  \caption[labelInTOC]{}
  \label{mps-gen-phases} 
\end{center} 
\end{figure}

Let us look in more detail at the template in \fig{mps-sm-gen-1}. It reduce a
\ic{Statemachine}, the input node, to two \ic{enum}s and a \ic{struct}. We use
template fragments (marked with \ic{<TF TF>}) to highlight those parts of the
template that should actually be used to replace the input node as the
transformation executes. The surrounding \ic{ImplementationModule} (\ic{module
dummy}) is only needed because \ic{enum}s and \ic{struct}s \emph{have} to live
in \ic{ImplementationModule}s in a valid instance of the mbeddr C language.


We have to create an \ic{enum} literal for each state and each event. To achieve
this, we iterate over all states (and events, respectively). This is expressed
with the \ic{LOOP} macros in the template (\fig{mps-sm-gen-1}). The expression
that determines what we iterate over is entered in the Inspector;
\fig{mps-sm-inspector1} shows the code for iterating over the states. 
Note that the only really interesting part of \fig{mps-sm-inspector1} is the
body of the anonymous function (\ic{node.states;}), which is why in the future we
will only show this part. For the literals of the events enum we use a similar expression
(\ic{node.events;}). 

\begin{figure}[ht]
\begin{center}
  \includegraphics[width=10cm]{figures/6/mps-sm-inspector1.png}
  \caption[labelInTOC]{}
  \label{mps-sm-inspector1} 
\end{center} 
\end{figure}
 

The \ic{LOOP} macro iterates over collections and then creates an instance of
the concept it is attached to for every iteration. In case of the two
\ic{enum}s, the \ic{LOOP} macro is attached to an \ic{EnumLiteral}, so we create
an \ic{EnumLiteral} for each event and state we iterate over. However, these
various \ic{EnumLiteral}s all have to have different names. In fact, the name of
each literal should be the name of the state/event for which it is created. We
can use a property macro, denoted by the \ic{\$} sign, to achive this. A 
property macro is used to replace
values of properties. In this case we use it to replace the \ic{name} property of the
generated \ic{EnumLiteral}. Here is the implementation expression of the
property macro (also entered in the inspector):


\begin{code}
node.cEnumLiteralName();
\end{code}


\ic{cEnumLiteralName} is a behavior method. It is defined as part of the behavior
aspect of the \ic{State} concept. It concatenates the \ic{name} of the parent
\ic{Statemachine} with the string \ic{\_\_state\_} and the name of the current
state.

\begin{code}
concept behavior State {                      
                                              
  public string cEnumLiteralName() {         
    return this.parent : Statemachine.name + "__state_" + this.name;
  }                                           
                                              
}                                             
\end{code}

We use property macros in a similar way to define the names of the two generated
\ic{enum}s themselves. The first of the \ic{struct} attributes is also
interesting. It is used to remember the current state. It has to be typed to the
state \ic{enum} that is generated from this particular state machine. The type
of the attribute is an \ic{EnumType}; \ic{EnumType}s extend \ic{Type} and
reference the \ic{EnumDeclaration} whose type they represent. How can we
establish the reference to the correct \ic{EnumDeclaration}? We use a reference
macro (\ic{->\$}) to retarget the reference. \fig{mps-ref-macro} shows the
macro's expression.

\begin{figure}[ht]
\begin{center}
  \includegraphics[width=11cm]{figures/6/mps-ref-macro.png}
  \caption[labelInTOC]{}
  \label{mps-ref-macro} 
\end{center} 
\end{figure}

Note how a reference macro expects either the target node (here: an
\ic{EnumDeclaration}) as the return value, or a \ic{string}. That \ic{string}
would be the name of the target element. Our implementation returns the name of
the states \ic{enum} generated in the same template. MPS then uses the target
language's scoping rules to find and link to the correct target element.

 
\begin{figure}[h]
\begin{center}
  \includegraphics[width=11cm]{figures/6/mps-sm-gen-2.png}
  \caption[labelInTOC]{}
  \label{mps-sm-gen-2} 
\end{center} 
\end{figure}


Let us now address the second main template, \fig{mps-sm-gen-2}, which generates
the execute function. Looking at the template fragment markers (\ic{<TF  TF>})
reveals that we only generate the \ic{switch} statement with this template,
\emph{not} the function that contains it. The reason is that we need to be able
to embed the state machine \ic{switch} into other function-like concepts as well
(e.g. component operations), so we have separated the generation of the function
from the generation of the actual state machine behavior. 

The \ic{switch} expression is interesting. It switches over the current state of
the current state machine instance. That instance is represented by the
\ic{instance} parameter passed into the function. It has a \ic{\_\_currentState}
field. Notice how the function that contains the \ic{switch} statement \emph{in
the template} has to have the \ic{instance} argument, and how its type, the
\ic{struct}, has to have the \ic{\_\_currentState} attribute \emph{in the
template}. If the respective elements were not there in the template, we
couldn't write the template code! Since there is a convention that in the
\emph{resulting} function the argument will also be called \ic{instance}, and
the attribute will also be called \ic{\_\_currentState}, we don't have to use a
reference macro to retarget the two.

Inside the \ic{switch} we then \ic{LOOP} over all the states of the state
machine and generate a \ic{case}, using the state's corresponding enum literal.
Inside the case, we embed another \ic{switch} that switches over the \ic{event}
argument. Inside this inner \ic{switch} we iterate over all transitions that are
triggered by the event we currently iterate over:

\begin{code}
node<State> state = (node<State>) node.adapter.getUserObject("outer"); 
state.transitions.where({~it => it.trigger.event == node; });
\end{code}

We then generate an \ic{if} statement that checks at runtime whether the
guard condition for this transition is true. We copy in the guard condition
using the \ic{COPY\_SRC} macro attached to the \ic{true} dummy node. The
\ic{COPY\_SRC} macro copies the original node, but it also applies additional
reduction rules for this node (and all its descendants). For example, in a guard
condition, you can refer to event arguments. The reference to \ic{size} in the
\ic{step} transition is an example.

\begin{code}
statemachine Counter { 
  in events 
    step(int[0..10] size) 
    ... 
  states ( initial = start ) 
    ... 
    state countState { 
      on step [currentVal + size > LIMIT] -> start { send resetted(); } 
    }
}
\end{code}

Event arguments are mapped to the resulting C function via a \ic{void*} array. A
reference to an event argument (\ic{EventArgRef}) hence has to be reduced to 
accessing the n-th element in the array (where n is the index of the event
argument in the list of arguments). \fig{mps-eventArgRef} shows the
reduction rule. The reduction rule creates code that
looks like this (for an \ic{int} event attribute): \ic{*((int*)arguments[0])}.
It accesses the array, casts the element to a pointer to the type of the
argument, and then dereferences everything.

\begin{figure}[h]
\begin{center}
  \includegraphics[width=11cm]{figures/6/mps-eventArgRef.png}
  \caption[labelInTOC]{}
  \label{mps-eventArgRef} 
\end{center} 
\end{figure}

Inside the \ic{if} statement, we have to generate the code that has to be
executed if a transition executes. We first copy in all the exit actions of the
current state. Once again, the \ic{int8\_t exitActions;} is just an arbitrary
dummy statement that will be replaced by a the statements in the exit actions
(\ic{COPY\_SRCL} replaces a node with a \emph{list} of nodes). The respective
expression is this:

\begin{code}
(node, genContext, operationContext)->sequence<node<>> { 
  if (node.parent : State.exitAction != null) { 
    return node.parent : State.exitAction.statements; 
  } 
  new sequence<node<>>(empty); 
}
\end{code}

We then do the same for the transition actions of the current transition, set
the \ic{instance->\_\_currentState} to the target state of the transition using
a reference macro (\ic{node.targetState.cEnumLiteralName();}), and then we
handle the entry actions of the target state. We then return, because at most
one transition can fire as a consequence of calling the state machine execute
function.


As the last example I want to show how the \ic{TriggerSMStatement} is
translated. It is used as follows:


\begin{code}
var Counter c1; 
 
void aFunction() { 
  trigger(c1, start); 
} 
\end{code}


It has to be translated to a call to the generated state machine execute
function that we have discussed at length above. For simplicity, we explain
a version of the \ic{TriggerSMStatement} that does not include event arguments.
\fig{mps-trigger} shows the template. 

 
\begin{figure}[h]
\begin{center}
  \includegraphics[width=11cm]{figures/6/mps-trigger.png}
  \caption[labelInTOC]{}
  \label{mps-trigger} 
\end{center} 
\end{figure}

We use a dummy function \ic{someMethod} so we can embed a function call ---
because we have to generate a function call to the execute function generated
from the state machine. Only the function call is surrounded with the template
fragment markers. The function we call \emph{in the template} is the
\ic{smExecuteFunction} in the template. It has the same signature of the real,
generated state machine execute function. We use a reference macro to retargetthe \ic{function} reference in the function call. It uses the followingexpression, which returns the name of the function generated for the state
machine referenced in the \ic{statemachine} expression of the trigger statement.

\begin{code}
node.statemachine.type : StatemachineType.machine.cFunctionName();
\end{code}

Note how the first argument to the \ic{trigger} statement can be \emph{any}expression (local variable reference, global variable reference, a functioncall). However, we know (and enforce via the type system) that the expression'stype must be a \ic{StatemachineType}, which has a reference to the\ic{Statemachine} whose instance the expression represents. So we can cast,access the machine, and get the name of the execute function generated from thatstate machine. 

The second argument of the \ic{trigger} statement is a reference to the event we
want to trigger in the state machine. We can use another reference macro to find
the enum literal generated for this event. The macro code is straight forward:

\begin{code}
node.event.cEnumLiteralName();
\end{code}





\section{Spoofax Example}



  special languages (target lang level + meta level)
  what are good gen languages (some criteria)
      integrating manually written code (generation gap)        
      parts from My DSL Best Practices Paper
  
  modifying generated code: not
  
  generation gap pattern 
  
  extension of tatget lang to make it more easily generatable (expr blocks)

  
  when to use M2M (see best practices paper) 
  what are good trafo languages
  unidirectional, bidirectional (relational)
  incremental vs. batch)
  parts from My DSL Best Practices Paper
                      

\chapter{Building Interpreters}  
 
Interpreters are basically programs that read a model, traverse the AST and
perform actions corresponding to the semantics of the language constructs whose
instances appear in the AST. How interpreter implementation looks depends a lot
on the programming language used for implementing them. Also, the complexity of
the interpreter directly reflects the complexity of the language it processes.
For example, building an interpreter for a pure expression language with an
object oriented or functional programming language is almost trivial. In
constrast, the interpreter for languages that support paralellism can be much
more challenging. 

The following list explains some typical ingredients that go
into building interpreters. It assumes a programming language that can
polymorphically invoke functions or methods. 

\begin{itemize}
  \item For program elements that can be evaluated to values, i.e., expressions,
  there is typically a function eval that is polymorphically defined for the
  various expression types in the language. Since nested expressions are
  almost always represented as nested trees in the AST, the eval function calls
  itself with the program elements it owns, and then performs the semantic action on the result. Consider an expression \verb#3 * 2 + 5#. Since the plus is at the root of the
  AST, eval(Plus) would be called (by some outside entity). It is implemented as
  actually adding the values obtained by evaluating its arguments. So it calls
  eval(Multi) and eval(5). Evaluating a number literal is trivial, since it
  simply returns the number itself. Multi would call eval(3) and eval(2),
  multiplying their results and returning the result of the multiplication as
  its own result, allowing plus to finish its calculation.
  \item Program elements that don't produce a value only make sense in
  programming languages that have side effects. In other words, execution of
  such a language concept produces some effect either on global data in the
  program (re-assignable variables, object state) or on the environment of the
  program (sending network data or rendering a UI). Such program elements are
  typically called statements. Statements are typically not recursively nested
  in a tree, but rather arranged in a list, typically called a StatementList. To
  execute those, there is typically a function execute that is overloaded for
  all of the different statement types. It is also overloaded for StatementList
  which iterates over all statements and calls execute for each one. Note that
  statements often contain expressions and more statement lists (as in 
  \verb#if (a>3) { print a; a=0; } else { a=1;}#), so an implementation of
  execute may call eval and perform some action based on the result (such as
  deciding whether to execute the then-part of the else-part of the if
  statement). Executing the then-part and the else-part simply boils down to
  called execute on the respecrive statement lists.
  \item Languages that have can express assignment to variables require an
  environment for execution. Consider \verb#int a = 1; a = a + 1;#. In this
  example, the a in a+1 is a variable reference. When evaluating the this
  reference, the system must "remember" that it had assigned 1 to that variable
  in the previous statement. The interpreter must keep some kind of global
  hashtable to keep track of symbols and their values, so it can look them up
  when evaluating a reference to that symbol. Many (though not all) languages
  that support assignable variables allow reassignment to the same variable (as
  we do in a = a + 1;). In this case, the environment must be updatable. Notice
  that in \verb#a=a+1# both mentionings of are references to the same variable,
  and both are expressions (otherwise a couldn't be used as part of the plus
  operator, which expects expressions as arguments). However, only a can be
  assigned to: writing \verb#2 * a = a + 1;# would be invalid. The notion of an
  lvalue is introduced to describe this. lvalues can be used "on the left side"
  of an assignment. Variable references are typically lvalues (if they don't
  point to a const variable). Complex expressions usually aren't, unless they
  evaluate to something that is in turn an lvalue (an example of this is would
  be \verb#*(someFunc(arg1, arg2)) = 12;#, in C, assuming that someFunc returns
  a pointer to an integer).
  \item The ability to call other entities (functions, procedures, methods)
  introduces further complexity, especially regarding parameter and return value
  passing. Assume a function \verb#int add(int a, int b) { return a+b; }#. When
  this function is called via \verb#add(2,3);# the actual arguments 2 and 3 have
  to be bound to the formal arguments a and b. An environment must be established 
  for the execution of add that keeps track of these associations. If functions
  can also access global state (i.e. symbols that are not explicitly passed in
  via arguments), then this environment must delegate to the global environment
  in case a referenced symbol cannot be found in the local environment.
  Supporting recursive callable entities (as in 
  \verb#int fac(int i) { return i == 0 ? 1 : fac(i-1) };# requires that for
  each subsequent call to fac a new environment must be created, with a binding 
  for the formal variables. However, the original environment must be
  "remembered" because it is needed to complete the execution of the outer fac
  after a recursively called fac returns. This is achieved using a stack of
  environments. A new environment is pushed onto the stack as a function is
  called (recursively), and the stack is popped, returning to the previous
  environment, as a called function returns. The return value, which is often
  expressed using some kind of return statement, is usually placed into the
  inner environment using a special symbol or name (such as \verb#__ret__#). It
  can then be picked up from there as the inner environment is popped.
\end{itemize}
 
 
\subsection{Building an Interpreter with Xtext} 
 
This example describes an interpreter for the cooling language. It is used to
allow DSL users to "play" with the programs. The interpreter can execute test
cases (and report success or failure) as well as simulate the program
interactively. 
 
The execution engine, as the interpreter is called here, has to handle the
following language aspects:

\begin{itemize}
  \item Statements and expressions, as described above, as supported by the DSL
  and must be executed
  \item The top level structure of a cooling program is a state machine. So the
  interpreter has to deal with states, events and transitions.
  \item The language supports deferred execution (i.e. perform the following
  set of statements at a later time), so the interpreter has to keep track of
  deferred parts of the program
  \item The language supports writing tests for cooling programs incl. mock
  behaviour for hardware elements. A set of constructs exists to express this
  mock behaviour, specifically, ramps to change temperatures over time. These
  background tasks must be handled by the interpreter as well.
\end{itemize}

\paragraph{Expressions and Statements}

We start our description of the execution engine inside out, by looking at the
interpreter for expressions and statements first. As mentioned above, for
interpreting expressions, there is typically an overloaded eval operation, that
contains the implementation of expression evaluation for each kind of
expression. However, Java doesn't have polymorphically overloaded member
methods. Instead, and Xtext workflow fragment generates a dispatcher. The
fragment is configured with the abstract meta classes that represent expressions
and statements (all specific expressions and statements inherit directly or
indirectly from these classes). The following code shows the fragment
configuration:


\begin{code}
fragment = de.itemis.interpreter.generator.InterpreterGenerator {
    expressionRootClassName = "Expression"
    statementRootClassName = "Statement"
}
\end{code}


This fragment generates an abstract class that acts as the basis for the
interpreter for the particular set of statements and expressions. as the
following piece of code shows, the class contains an eval method that uses
instanceof checks to dispatch to a method specific to the subclass and thereby
emulating polymorphically overloaded methods. The specific methods throw an
exception and are expected to be overridden by a manually written subclass  that
contains the actual interpreter logic for the particular language concepts. the
class also uses a logging framework (based on the LogEntry class) that can be
used to create a tree shaped trace of expression evaluation, which is very
useful for debugging and understanding the execution of the interpreter.



\begin{code}
public abstract class AbstractCoolingLanguageExpressionEvaluator 
                      extends AbstractExpressionEvaluator {

    public AbstractCoolingLanguageExpressionEvaluator( ExecutionContext ctx ) {
        super(ctx);
    }

    public Object eval( EObject expr, LogEntry parentLog ) 
                  throws InterpreterException {

        LogEntry localLog = parentLog.child(LogEntry.Kind.eval, expr, 
                 "evaluating "+expr.eClass().getName());
        
        if ( expr instanceof Equals ) {
            return evalEquals( (Equals)expr, localLog );
        }
        if ( expr instanceof Unequals ) {
            return evalUnequals( (Unequals)expr, localLog );
        }
        if ( expr instanceof Greater ) {
            return evalGreater( (Greater)expr, localLog );
        }
        // the others...
    }

    protected Object evalEquals( Equals expr, LogEntry log ) 
              throws InterpreterException {
        throw new MethodNotImplementedException(expr, 
                 "method evalEquals not implemented");
    } 
    protected Object evalUnequals( Unequals expr, LogEntry log ) 
              throws InterpreterException {
        throw new MethodNotImplementedException(expr, 
              "method evalUnequals not implemented");
    } 
    protected Object evalGreater( Greater expr, LogEntry log )
              throws InterpreterException {
        throw new MethodNotImplementedException(expr, 
              "method evalGreater not implemented");
    } 
    
}
\end{code}

    
A similar class is generated for the statements. Instead of eval, the method is
called execute and it does not return a value. In every other respect the
statement executor is similar to the expression evaluator.

Let us now take a look at some example method implementations. The following
code shows the implementation of evalNumberLiteral which evaluates number
literals such as 2 or 2.3 or -10.2. The following grammar is used for defining
number literals:


\begin{code}
Atomic returns Expression:
    ...
    ({NumberLiteral} value=DECIMAL_NUMBER);

terminal DECIMAL_NUMBER:
    ("-")? ('0'..'9')* ('.' ('0'..'9')+)?;
\end{code}


Before we delve into the details of this code, it is worth mentioning that the
"global data" held by the execution engine is stored and possibly around using
the engine execution context. For example it contains the environment that keeps
track of symbol values, and it also has access to the type system implementation
class for the language. Execution context is available through the eec() method.


\begin{code}
    protected Object evalNumberLiteral(NumberLiteral expr, LogEntry log) {
        String v = ((NumberLiteral) expr).getValue();
        EObject type = eec().typesystem.typeof(expr, new TypeCalculationTrace());
        if (type instanceof DoubleType) {
            log.child(Kind.debug, expr, "value is a double, " + v);
            return Double.valueOf(v);
        } else if (type instanceof IntType) {
            log.child(Kind.debug, expr, "value is a int, " + v);
            return Integer.valueOf(v);
        }
        return null;
    }
\end{code}



With this in mind, the implementation of even outnumber literal should be
obvious. We first retrieve the actual value from the NumberLiteral object, and
we find out that type of the number literal. The type system basically inspects,
whether the value contains a dot or not and returns either a DoubleType or 
IntType. Based on this distinction the evaluate method returns either a Java
Double or Integer as the value of the NumberLiteral. In addition, it creates log
entries that document these decisions.

The evaluator for NumberLiteral was simple because number literals are leaves
in the AST and have no other children, so no recursive invocations of eval are
required. This is different for the logical and for example. The following code
shows the implementation of the logical and. It has two more children in the
left and right properties. the first two statements recursively called the
evaluator, for the left and right children respectively. They use a utility
method called evalCheckNullLog which automatically creates a log entry for this
recursive call and stops the interpreter if the value passed in is null (which
would mean the AST is somehow broken). Once we have evaluated the two children
we can simply return a conjunction of the two.


\begin{code}
protected Object evalLogicalAnd(LogicalAnd expr, LogEntry log) {
    boolean leftVal = ((Boolean)evalCheckNullLog( expr.getLeft(), log ))
                      .booleanValue();
    boolean rightVal = ((Boolean)evalCheckNullLog( expr.getRight(), log ))
                      .booleanValue(); 
    return leftVal && rightVal;
}
\end{code}


So far, we haven't used the environment, since we haven't worked with variables
and their current values. Let's now look and how variable assignment is handled.
We first look at the assignment statement,  which is implemented  in the
statement executor, not in the expression evaluator.


\begin{code}
protected void executeAssignmentStatement(AssignmentStatement s, LogEntry log){
    Object l = s.getLeft();
    Object r = evalCheckNullLog(s.getRight(), log);
    SymbolRef sr = (SymbolRef) l;
    SymbolDeclaration symbol = sr.getSymbol();
    eec().environment.put(symbol, r);
    log.child(Kind.debug, s, "setting " + symbol.getName() + " to " + r);
}
\end{code}


The first two lines get the left argument as well as the value of the right
argument. Note how only the right value is evaluated: the left argument is a
symbol reference (made sure through a constraint). We then retrieve the symbol
referenced by the symbol reference and create a mapping from the symbol to the
value in the environment, effectively "assigning" the value to the symbol during
the execution of the interpreter.

The implementation of the evaluator for a symbol reference (if it is used not
as an lvalue) is shown in the following code. We use the same environment to
lookup the value for the symbol. We then check if the value is null (i.e.
nothing has been assigned to the symbol as yet). In this case we return the
default value for the respective type and log a warning. Otherwise we return the
value.


\begin{code}
protected Object evalSymbolRef(SymbolRef expr, LogEntry log) {
    SymbolDeclaration s = expr.getSymbol();
    Object val = eec().environment.get(s);
    if (val == null) {
        EObject type = eec().typesystem.typeof(expr, new TypeCalculationTrace());
        Object neutral = intDoubleNeutralValue(type);
        log.child(Kind.debug, expr, 
           "looking up value; nothing found, using neutral value: " + neutral);
        return neutral;
    } else {
        log.child(Kind.debug, expr, "looking up value: " + val);
        return val;
    }
}
\end{code}


The cooling language does not support function calls, so we demonstrate function
calls with a similar language that supports it. In that language, function calls
are expressed as symbol references that have argument lists. Below is the
grammar. Constraints make sure that argument lists are only used if the
referenced symbol is actually a FunctionDeclaration.


\begin{code}
FunctionDeclaration returns Symbol:
    {FunctionDeclaration} "function" type=Type name=ID "(" 
        (params+=Parameter  ("," params+=Parameter)* )?  ")" "{"    
        (elements+=Element)*
    "}";    

Atomic returns Expression:
    ...
    {SymbolRef} symbol=[Symbol|QID]  
        ("(" (actuals+=Expr)? ("," actuals+=Expr)* ")")?; 
\end{code}


The following is the code for the evaluation function for the symbol reference.
It must distinguish between references to variables and to functions. 


\begin{code}
protected Object evalSymbolRef(SymbolRef expr, LogEntry log) {
    Symbol symbol = expr.getSymbol();
    if ( symbol instanceof VarDecl ) {
        return log( symbol, ctx.environment.getCheckNull(symbol), log);
    }
    if ( symbol instanceof FunctionDeclaration ) {
        FunctionDeclaration fd = (FunctionDeclaration) symbol;
        return callAndReturnWithPositionalArgs("calling "+fd.getName(), 
                fd.getParams(), expr.getActuals(), fd.getElements(), 
                RETURN_SYMBOL, log);
    }
    throw new InterpreterException(expr, 
        "interpreter failed; cannot resolve symbol reference " 
        +expr.eClass().getName()); }
\end{code}


The code for the FunctionDeclaration uses a predefined utility method
callAndReturnWithPositionalArgs. It accepts as arguments the list of formals of
the called function, the list of actuals passed in, the list of statements in
the function body, a symbol that should be used for the return value as well as
the obligatory log. The utility method is implemented as follows:


\begin{code}
protected Object callAndReturnWithPositionalArgs(String name, 
        EList<? extends EObject> formals, EList<? extends EObject> actuals, 
        EList<? extends EObject> bodyStatements, Object returnSymbol, 
        LogEntry log) {
    ctx.environment.push(name);
    for( int i=0; i<actuals.size(); i++ ) {
        EObject actual = actuals.get(i);
        EObject formal = formals.get(i);
        ctx.environment.put(formal, evalCheckNullLog(actual, log));
    }
    ctx.getExecutor().execute( bodyStatements, log );
    Object res = ctx.environment.get(returnSymbol);
    ctx.environment.pop();
    return res;
}
\end{code}


It first creates a new environment and pushes it on the call stack. The it
iterates over all the actual argument, evaluates each of them and "assigns" them
to the formals by creating an association between the formal argument symbol and
the actual argument value in the new environment. It then uses the statement
executor (available through the context) to execute all the statements in the
body of the function. Notice that if they deal with their own variables and
functions, the use the new environment pushed onto the stack by this method!
When the execution of the body has finished, we retrieve the return value from
the environment. The return statement in the function has put it there under a
name we have prescribed, the returnSymbol, so we know where to find it. Finally,
we pop the environment, restoring the caller's state of the world and return the
return value.


\paragraph{States, Events and the Main program}

Changing a state happens by executing a ChangeStateStatement, which simply
references the state that should be entered. Here is the interpreter code in
StatementExecutor:


\begin{code}
protected void executeChangeStateStatement(ChangeStateStatement s, LogEntry l) {
    l.child(Kind.debug, s, "change state to " + s.getTargetState().getName());
    engine.enterState(s.getTargetState(), log);
}

public void enterState(State ss, LogEntry logger ) 
        throws TestFailedException, InterpreterException, TestStoppedException {
    logger.child(Kind.info, ss, "entering state "+ss.getName());
    context.currentState = ss;
    executor.execute(ss.getEntryStatements(), logger);
    throw new NewStateEntered();
}
\end{code}


It calls back to an engine method that handles the state change (since this is
a more global operation than executing statements, it is handled by the engine
class itself). The method simply sets the current state to the target state
passed into the method (the current state is kept track of in the execution
context). It then executes the set of entry statements of the new state. After
this it throws an exception NewStateEntered which stops the current execution
step. 

The overall engine is step driven, i.e. an external "timer" triggers distinct
execution steps of the engine. A state change always terminates the current
step. The main method step() triggered by the external timer can be considered
the main program of the engine. It looks as follows:


\begin{code}
public int step(LogEntry logger) {
    try {
        context.currentStep++;
        executor.execute(getCurrentState().getEachTimeStatements(), stepLogger);
        executeAsyncStuff(logger);
        if ( !context.eventQueue.isEmpty() ) {
            CustomEvent event = context.eventQueue.remove(0);
            LogEntry evLog = logger.child(Kind.info, null, 
                "processing event from queue: "+event.getName());
            processEventFromQueue( event, evLog );
            return context.currentStep;
        }
        processSignalHandlers(stepLogger);
    } catch ( NewStateEntered se ) {
    }
    return context.currentStep;
}
\end{code}


It first executes the each time statements of the current state. This is
a statement list defined by a state that needs to be re-executed in each step
while the system is in the respective state. It then executes asynchronous
tasks. We'll explain this in the next section. Next it checks if an event is in
the event queue. If so, it removes the first event from the queue and executes
it. After processing an event the step is terminated. Lastly, we process signal
handlers (the check statements in the programs).

Processing events simply checks if the current state declares and event handler
that can deal with the currently processed event. If so, it executes the
statement list associated with this event handler.


\begin{code}
private void processEventFromQueue(CustomEvent event, LogEntry logger) {
    for ( EventHandler deh: getCurrentState().getEvents()) {
        if ( reactsOn( deh, event ) ) {
            executor.execute(deh.getStatements(), logger);
        }
    }
}
\end{code}


Raising events is just another statement that can be put into any statement
list. It adds the respective event to the queue. Also, events can be raised by
external actors (the hardware in the real system, and statements in test cases).

The DSL also supports executing code asynchronously, i.e. after a specified
number of steps. The grammar looks as follows:


\begin{code}
PerformAsyncStatement:
    "perform" "after" time=Expr "{"
        (statements+=Statement)*
    "}";
\end{code}


The interpreter for this statement is simply the following method:


\begin{code}
protected void executePerformAsyncStatement(PerformAsyncStatement s, 
                LogEntry log) throws InterpreterException {
    int inSteps = ((Integer)evalCheckNullLog(s.getTime(), log)).intValue();
    eec().asyncElements.add(new AsyncPerform(eec().currentStep + inSteps, 
        "perform async", s, s.getStatements()));
}
\end{code}


It registers the statement list associated with the PerformAsyncStatement in the
list of async elements in the execution context. The call to executeAsyncStuff
at the beginning of the step method described above checks whether the time has
come and executes those statements.


\begin{code}
private void executeAsyncStuff(LogEntry logger) {
    List<AsyncElement> stuffToRun = new ArrayList<AsyncElement>();
    for (AsyncElement e: context.asyncElements) {
        if ( e.executeNow(context.currentStep) ) {
            stuffToRun.add(e);
        }
    }
    for (AsyncElement e : stuffToRun) {
        context.asyncElements.remove(e);
        e.execute(context, logger.child(Kind.info, null, "Async "+e));
    }
}
\end{code}




\todo{mention interpreter framework!}
\todo{Say something about Xtend2}


\subsection{An interpreter in MPS}

Building an interpreter in MPS is fundamentally similar to building one in Xtext
and EMF. All concept would apply in the same way, intead of EObjects you would
work with the node<> types that are available on MPS to deal with ASTs. However,
since MPS' BaseLanguage is itself built with MPS, it can be extended. So instead
of using a generator to generate the dispatcher that calls the eval methods for 
the expression classes, suitable language extensions can be defined in the first
place.

For example, BaseLanguage (effectively Java) could be extended with support for
polymorphic dispatch (similar to what Xtend2 does). An alternative solution
involves a dispatch statement, a kind of pimped switch. \fig{mps-dispatch} shows
an example.

\begin{figure}[ht]
\begin{center}
  \includegraphics[scale=0.65]{figures/6/mps-dispatch.png}
  \caption[labelInTOC]{}
  \label{mps-dispatch} 
\end{center}
\end{figure}

The dispatch statement tests if the argument ex is an instance of the type
referenced in the "cases". If so, the code on the right side of the arrow is
executed. Notice the special expression \$ used on the right side of the arrow.
It refers to the argument ex, but it is already downcast to the type on the left
of the case's arrow. This way, annoying downcasts can be avoided. 
