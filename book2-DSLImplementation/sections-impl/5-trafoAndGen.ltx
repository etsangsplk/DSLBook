\chapter{Transformation and Generation}
\label{ch:trafoAndGen}

\chapterabstract{Transformation and generation have in common that another
artifact is created from a program. This is in contrast to interpretation,
which executes programs directly, without creating intermediate artifacts.
Transformation refers to the case where the created artifact is an AST, and
code generation refers to the case where textual concrete syntax is created. In
some systems, for example MPS, the two are unified into a common approach. }

\noindent
Transformation of models is an essential step in working with DSLs. We typically
distinguish between two different cases: if models are transformed into other
models we call this \emph{model transformation}. If models are transformed into
text (usually programming language source code, XML or other configuration
files) we refer to \emph{code generation}. However, as we will see in the
examples below, depending on the approach and tooling used, this distinction is
not always easy to make, and the boundary becomes blurred.

A fundamentally different approach to processing models is
\emph{interpretation}. While in case of transformation and generation the model
is migrated to artifacts expressed in a different language, in case of
interpretation no such migration happens. Instead, an interpreter traverses an
AST and \emph{directly} performs actions depending on the contents of the AS.
Strictly speaking, we have already seen examples of interpretation in the
sections on constraints and type systems: constraint and type checks can be seen
as an interpreter where the actions performed as the tree is traversed are
checks of various kinds. However, the term interpretation is typically only used
for cases where the actions actually \emph{execute} the model. Execution refers
to performing the actions that are associated with the language concepts as
defined by the execution semantics of the concepts. We discuss interpretation in
the next chapter\footnote{We elaborate on the trade-offs between transformation
and generation vs. interpretation in the chapter on language design \todo{}.}.


\section{Overview of the approaches}

Classical code generation traverses a program's AST and outputs programming
language source code (or other text). In this context, a clear distinction is
made between models and source code. Models are represented as an AST expressed
with some preferred AST formalism (or meta meta model); an API exists for the
transformation developer to interact with the AST. In contrast, the generated
source code is treated as text, i.e.~a sequence of characters. The tool of
choice for transforming an AST into text are template languages. They support
the syntactic mixing of model traversal code and to-be-generated text. The two
are separated using some escape character. Since the generated code is treated
merely as text, there is no language awareness (and corresponding tool support)
for the target language while editing templates. Xtend\footnote{Xtend is also
sometimes referred to as Xtend2, since it has evolved from the old oAW Xtend
language. In this chapter we use Xtend to refer to Xtend2. It can be found at
http://www.eclipse.org/xtend/}, the language used for code generation in Xtext
is an example of this approach.

Classical model transformation is the other extreme in that it works with ASTs
only and does not consider the concrete syntax of the either the source or the
target languages. The source AST is transformed using the source language AS API
and a suitable traversal language. As the tree is traversed, the API of the
target language AS is used to assemble the target model. For this to work
smoothly, most specialized transformation languages assume that the source and
target models are build with the same AST formalism (e.g.,~EMF Ecore). Model
transformation languages typically provide support for efficiently navigating
source models, and for creating instances of AS of the target language (tree
construction). Examples for this approach once again include Xtext's Xtend as
well as QVT Operational\footnote{http://en.wikipedia.org/wiki/QVT} and
ATL\footnote{http://www.eclipse.org/atl/}. MPS can also be used in this way. A
slightly different approach just establishes relations between the source and
target models instead of "imperatively" constructing a target tree as the source
is traversed. While this is often less intuitive to write down, the approach has
the advantage that it supports transformation in both directions, and also
supports model diff\footnote{(It does so by "relating" two instances of the same
language and marking both as \icsn{readoqnly}; the engine then points out the
difference between the two.}. QVT
relational\footnote{http://en.wikipedia.org/wiki/QVT} is an example of this
approach.


In addition to the two classical cases described above, there are also hybrid
approaches that blur the boundaries between these two clear cut extremes. They
are based on the support for language modularization and composition in the
sense that the template language and the target language can be composed. As a
consequence, the tooling is aware of the syntactic structure and the static
semantics of the template language \emph{and} the target language. Both MPS and
Spoofax/SDF support this approach to various extents.


In MPS, a program is projected and every editing operation directly modifies the
AST, while using a typically textual-looking notation as the "user interface".
Template code (the code that controls the transformation process) and
target-language code (the code you want to generate) can be represented as
nested ASTs, each using its own textual syntax. MPS uses a slightly different
approach based on a concept called annotations: As we have elaborated
previously, projectional editors can store arbitrary information in an AST.
Specifically, it can store information that does \emph{not} correspond to the AS
as defined by the language we want to represent ASTs of. MPS code generation
templates exploit this approach: template code is fundamentally an instance of
the target language. This "example model" is then annotated with template
annotations that define how the example model relates to the source model, and
which example nodes must be replaced by (further transformed) nodes from the
source model. This way, any language can be "templatized" without changing the
language definition itself. The MPS example below will elaborate on this
approach.

Spoofax, with its Stratego transformation language uses a similar approach based
on parser technology. As we have already seen, the underlying grammar formalism
supports flexible composition of grammars. So the template language and the
target language can be composed, retaining tool support for both of these
languages. Execution of the template actually directly constructs an AST of the
target language, using the concrete syntax of the target language to specify its
structure. The Spoofax example will provide details.



\section{Xtext Example}

Since Xtext is based on EMF, generators can be built using any tool that can
generate code from EMF models, including
Acceleo\footnote{http://www.acceleo.org/pages/home/en},
Jet\footnote{http://www.eclipse.org/modeling/m2t/?project=jet} and Xtend
(mentioned above). Xtend is a Java-like general-purpose language that removes
some of Java's noise (it has type inference, property access syntax, operator
overloading) and adds syntactic sugar (extension methods, multiple-dispatch and
closures). Xtend comes with an interpreter and a compiler, the latter generating
Java source. Xtend is built with Xtext, so it comes with a powerful Xtext-based
editor. One particularly interesting language feature in the context of code
generators are Xtend's \emph{template expressions}. Inside these expressions, a
complete template language is available (similar to the older Xpand language).
It also provides automatic whitespace management\footnote{Indentation of template code
is traditionally a challenge, because it is not clear whether whitespace in
template code is intended to go into the target file, or is just used for
indenting the template itself.} The functional abstractions and higher-order
functions provided by Xtend make it also very well suited for navigating and
querying models. In the rest of this section we will use Xtend for writing code
generators and model transformations.

\todo{allContentsIterable was removed. Why not just resource.getContents.
filter() or something like that. It's usually not required to traverse the 
complete model to find the top level structures}
\begin{figure}[ht]
\begin{center}
  \includegraphics[width=\columnwidth]{figures-impl/5/xtext-gen-1.png}
  \caption[]{The top level structure of a generator written in Xtext is a class
  that implements the \icsn{IGenerator} interface, which requires the
  \icsn{doGenerate} method. Inside generator methods, template expressions
  (using the triple single quotes) are typically used. Inside those, 
  guillemets (the small double angle brackets) are used to switch between
  to-be-generated code (grey background) and template control code. Note also the grey whitespace in the
  \icsn{init} function. Grey whitespace is whitespace that will end up in the
  generated code. White whitespace is used for indentation of template code.
  Xtend figures out which is which automatically.}
  \label{xtext-gen-1} 
\end{center} 
\end{figure}


\subsection{Generator}

We will take a look at generating the C code that implements cooling programs.
\fig{xtext-gen-1} shows a screenshot of a typical generator. The generator is an
Xtend class that implements \ic{IGenerator}, which requires the \ic{doGenerate}
method to be implemented. The method is called for each model file that has
changed\footnote{This is achieved by a Builder that comes with Xtext.
Alternatively, Xtend generators can also be run from the command line, from
another Java program or from and and maven.} (represented by the \ic{resource}
argument), and it has to output the corresponding generated code via the
\ic{fsa} (file system access) object\footnote{Like any other Xtext language
aspect, the generator has to be registered with the runtime module, Xtext's main
configuration data structure. Once this is done, the generator is automatically
called for each changed resource associated with the respective language.}.

When generating code from models there are two distinct cases. In the first
case, the majority of the generated code is fixed; only some isolated parts
of the code depend on the input model. In this case a template language is the
right tool, because template control code can be "injected" into code that looks
similar to what shall be generated. In the other case there are fine grained
structures, such as expressions. Since those are basically trees, using template
languages for these parts of programs seems unnatural and implies a lot of
syntactic noise. A more functional approach is useful. We will illustrate both
cases as part of this example.

We start with the high-level structure of the C code generated for a cooling
program. The following piece of code illustrates Xtend's power to navigate a
model as well as the template syntax for text generation.

\begin{lstlisting}[language=xtend]
def compile(CoolingProgram program) { 
    '''
    <<FOR appl:  program.moduleImports.map(mi|mi.module).filter(typeof(Appliance))>> 
        <<FOR c: appl.contents>> 
            #define <<c.name>> <<c.index>>
        <<ENDFOR>>
    <<ENDFOR>>
  
    // more ...
    '''
}
\end{lstlisting}

\noindent 
The \ic{FOR} loop iterates over the \ic{moduleImports} collection of the
\ic{program}, follows the \ic{module} reference of each of these, and then
selects all \ic{Appliance}s from the resulting collection. The nested loop then iterates
over the contents of each \ic{appl}iance and generates a \ic{\#define}. Notice
how the the first two and the last two lines are enclosed in the guillemets.
Since we are in template expression mode (\ic{''' \ldots '''}) the guillemets escape
to template control code. The \ic{\#define} is \emph{not} in guillemets, so it
is generated into the target file. After the \ic{\#define} we generate the name
of the respective content element and then its \ic{index}. From within
templates, the properties and references of model elements (such as the
\ic{name} or the \ic{module} or the \ic{contents}) can simply be accessed using
the dot operator. \ic{map} and \ic{filter} are collection methods defined by the
Xtend standard library\footnote{\icsn{map} creates a new collection from an existing
collection where, for each element in the existing collection, the expression
after the \icsn{|} creates the corresponding value for the new collection.
\icsn{filter} once again creates a new collection from an existing one where only
those elements are included that are an instance of the type passed as an
argument to \icsn{filter}.}. We also have to generate an \ic{enum} for the
states in the cooling program.

\begin{lstlisting}[language=xtend]
typedef enum states {
    null_state, 
    <<FOR s : program.concreteStates SEPARATOR ",">>
        <<s.name>>
    <<ENDFOR>>
};
\end{lstlisting}

\noindent Here we embed a \ic{FOR} loop inside the \ic{enum} text. Note how we
use the \ic{SEPARATOR} keyword to put a comma \emph{between} two subsequent
states. In the \ic{FOR} loop we access the \ic{concreteStates} property on the
cooling program. However, if you looked at the grammar or the meta model, you
will see that no \ic{concreteStates} property is defined there. Instead, we call
an extension method\footnote{An extension method is an \emph{additional} methods
for an \emph{existing} class, defined without invasively changing the definition
of this class}; since it has no arguments, it looks like property access. The
method is defined further down in the \ic{CoolingLanguageGenerator} class and
is essentially a shortcut for a complex expression:

\begin{lstlisting}[language=xtend]
def concreteStates(CoolingProgram p) {
    p.states.filter(s | !(s instanceof BackgroundState) && !(s instanceof ShadowState))
}
\end{lstlisting}

\noindent 
The following code is part of the generator that generates the code
for a state transition. It first generates code to execute the exit actions of
the current state, then performs the state change (\ic{current\_state =
new\_state;}) and finally executes the entry actions of the new state (not
shown):

\begin{lstlisting}[language=xtend]
if (new_state != current_state) {
    <<IF program.concreteStatesWitExitActions.size > 0>>
        // execute exit action for state if necessary
        switch (current_state) {
            <<FOR s: p.concreteStatesWitExitActions>>
                case <<s.name>>:
                    <<FOR st: s.exitStatements>>
                        <<st.compileStatement>>
                    <<ENDFOR>>
                    break;
            <<ENDFOR>>
            default:
                break;
    }
    <<ENDIF>>
    
    // The state change
    current_state = new_state;
    
    // similar as above, but for entry actions
}
\end{lstlisting}

\noindent 
The code first uses an \ic{IF} statement to check whether the program has any
states with exit actions (by calling the \ic{concreteStatesWitExitActions} 
extension method). Only if we have such states is the subsequent \ic{switch} statement generated. The \ic{switch}
switches over the \ic{current\_state}, and then adds a \ic{case} for each state
with exit actions\footnote{The \icsn{s.name} expression in the \icsn{case}
is actually a reference to the enum literal generated earlier for
the particular state. From the perspective of Xtend, we simply generate text: it is not obvious
from the template that the name corresponds to an enum literal. Potential
structural or type errors are only revealed upon compilation of the generated
code.}. Inside the case we iterate over all the \ic{exitStatements} and call
\ic{compileStatement} for each of them.

\ic{compileStatement} is a multimethod: it is polymorphically overloaded based
on its argument\footnote{Note that Java can only perform a polymorphic dispatch
based on the \icsn{this} pointer. Xtend can dispatch polymorphically over the
arguments of methods marked as \icsn{dispatch}.}. For each statement in the
cooling language, represented by a subclass of \ic{Statement}, there is an
implementation of this method. The next piece of code shows some example
implementations.

\begin{lstlisting}[language=xtend]
class StatementExtensions {
    
    def dispatch compileStatement(Statement s){
        // raise error if the overload for the abstract class is called
    }
    
    def dispatch compileStatement(AssignmentStatement s){
        s.left.compileExpr +" = " + s.right.compileExpr +";"
    }

    def dispatch compileStatement(IfStatement s){
        '''
        if( <<s.expr.compileExpr>> ){
            <<FOR st : s.statements>>
                <<st.compileStatement>>
            <<ENDFOR>>
        }<<IF s.elseStatements.size > 0>> else {
            <<FOR st : s.elseStatements>>
                <<st.compileStatement>>
            <<ENDFOR>>
        }<<ENDIF>>
        '''
    }

    // more ...
}
\end{lstlisting}
    
\noindent 
The implementation of the overloaded methods simply returns the text string that
represents the C implementation for the respective language construct. The two
examples shown are simple because the language construct in the DSL closely
resembles the C code in the first place. Notice how the implementation for the
\ic{IfStatement} uses a template string, whereas the one for
\ic{AssignmentStatement} uses normal string concatenation.

The \ic{compileStatement} methods are implemented in the
\ic{StatementExtensions} class. However, from within the
\ic{CoolingLanguageGenerator} they are called using method syntax
(\ic{st.compileStatement}). This works because they are injected as extensions
using the following statement:

\begin{lstlisting}[language=xtend]
@Inject extension StatementExtensions
\end{lstlisting}


\noindent Expressions are handled in the same way as statements. The injected
class \ic{ExpressionExtensions} defines a set of overloaded \ic{dispatch}
methods for \ic{Expression} and all its subtypes\footnote{Earlier we
distinguished between generating a lot of code with only specific parts being
model dependent and fine-grained tree structures in expressions? This is an
example of the latter.}.

\begin{lstlisting}[language=xtend]
def dispatch String compileExpr (Equals e){
    e.left.compileExpr + " == " + e.right.compileExpr
}

def dispatch String compileExpr (Greater e){
    e.left.compileExpr + " > " + e.right.compileExpr
}

def dispatch String compileExpr (Plus e){
    e.left.compileExpr + " + " + e.right.compileExpr
}

def dispatch String compileExpr (NotExpression e){
    "!(" + e.expr.compileExpr + ")"
}

def dispatch String compileExpr (TrueExpr e){
    "TRUE"
}

def dispatch String compileExpr (ParenExpr pe){
    "(" + pe.expr.compileExpr + ")"
}

def dispatch compileExpr (NumberLiteral nl){
    nl.value
}
\end{lstlisting}

\noindent 
Since expressions are trees, a \ic{compileExpr} method typically calls
\ic{compileExpr} recursively on the children of the expression, if it has any.



\subsection{Model-to-Model Transformation}
\label{m2mxtext}

For model-to-model transformations, the same argument can be made as for code
generation: since Xtext is based on EMF, any EMF-based model-to-model
transformation engine can be used with Xtext models. Examples include ATL,
QVT-O, QVT-R and Xtend\footnote{Of course you could use any JVM-based
compatible programming language, including Java itself. However, Java is
really not very well suited because of its clumsy support for model navigation
and object instantiation. Scala and Groovy are much more interesting in this
respect}.

Essentially, model-to-model transformations are similar to code generators in
the sense that they traverse over the model. But instead of producing a text
string as the result, they produce another AST. So the general
structure of a transformation is similar. In fact, the two can be mixed. Let us
go back to the first code example of the generator:

\begin{lstlisting}[language=xtend]
def compile(CoolingProgram program) { 
    val transformedProgram = program.transform
    '''
    <<FOR appl : transformedProgram.modules.map(m|m.module).filter(typeof(Appliance))>>  
        <<FOR c : appl.contents>>
            #define <<c.name>> <<c.index>>
        <<ENDFOR>>
    <<ENDFOR>>
  
      // more ...
      '''
}
\end{lstlisting}

\noindent We have added a call to a function \ic{transform} at the beginning of
the transformation process. This function creates a new \ic{CoolingProgram} from
the original one, and we store it in the \ic{transformedProgram} variable.
The code generator then uses the \ic{transformedProgram} as the source from
which it generates code. In effect, we have added a "preprocessor"
model-to-model transformation to the generator. As discussed in the design
section \todoref{}, this is one of the most common uses of model-to-model
transformations.

The \ic{transform} function (described below) enriches the existing model. It
creates a new state (\ic{EMERGENCY\_STOP}), creates a new event
(\ic{emergency\_button\_pressed}) and then adds a new transition to each
existing state that checks if the new event occurred, and if so, transitions to
the new state. Essentially, this adds emergency stop behavior to any existing
state machine. Let us look at the implementation:

\begin{lstlisting}[language=xtend, morekeywords={for, return}]
class Transformation {
    
    @Inject extension CoolingBuilder 
    
    CoolingLanguageFactory factory = CoolingLanguageFactory::eINSTANCE
    
    def CoolingProgram transform(CoolingProgram p ) {
        p.states += emergencyState
        p.events += emergencyEvent
        for ( s: p.states.filter(typeof(CustomState)).filter(s|s != emergencyState) ) {
            s.events += s.eventHandler [
                symbolRef [
                    emergencyEvent()
                ]
                changeStateStatement(emergencyState())
            ]
        }
        return p;
    }
    
    def create result: factory.createCustomState emergencyState() {
        result.name = "EMERGENCY_STOP"
    }
    
    def create result: factory.createCustomEvent emergencyEvent() {
        result.name = "emergency_stop_button_pressed"
    }
 
}
\end{lstlisting}

\noindent The two \ic{create} methods create new objects, as the \ic{create}
prefix suggests\footnote{The \icsn{factory} used in these methods is the way to
create model elements in EMF. It is generated as part of the EMF code
generator}. However, simply creating objects can be done with a regular method
as well:

\begin{lstlisting}[language=xtend]
def emergencyState() {
    val result = factory.createCustomState
    result.name = "EMERGENCY_STOP"
    result
}
\end{lstlisting}

\noindent 
What is different in \ic{create} methods is that they can be called several
times, and they still only ever create one object (per combination of
arguments). The result of the first invocation is cached, and all subsequent
invocations return the object \emph{created during the first invocation}. Such a
behavior is very useful in transformations, because it removes the need to keep
track of already created objects. For example, in the \ic{transform} method, we
have to establish references to the state created by \ic{emergencyState} and the
event created by \ic{emergencyEvent}. To do that, we simply call the same
\ic{create} extension again. Since it returns the \emph{same} object as during
the first call in the first two lines of \ic{transform}, this actually
establishes references to those already created objects\footnote{This is a major
difference between text generation and model transformation. In text, two
textual occurrences of a symbol are the same thing (in some sense, text strings
are value objects). In model transformation the identity of elements does
matter. It is not the same if we create \emph{one} new state and then reference
it, or if we create five new states. So a good transformation language helps
keep track of identities. The \icsn{create} methods are a very nice implementation
of this principle.}.

We can now look at the implementation of \ic{transform} itself. It starts out by
adding the \ic{emergencyState} and the \ic{emergencyEvent} to the program (these
are the first calls to the respective functions, so the objects are actually
created at this point). We then iterate over all \ic{CustomState}s except the
emergency state we've just created. Notice how we just call the
\ic{emergencyState} function again; It returns the same object! We then use a
builder to add the following code to each of the existing states.

\begin{lstlisting}[language=cooling]
on emergency_button_pressed {
    state EMERGENCY_STOP
}
\end{lstlisting}


\noindent 
This code could be constructed by procedurally calling the respective
factory methods:

\begin{lstlisting}[language=xtend]
val eh = factory.createEventHandler
val sr = factory.createSymbolRef
sr.symbol = emergencyEvent
val css = factory.createChangeStateStatement
css.targetState = emergencyState
eh.statements += css
s.events += eh
\end{lstlisting}

\noindent 
The notation used in the actual implementation is more concise and resembles the
tree structure of the code much more closely. It uses the well-known
\emph{builder} notation\todoref{}. Builders are implemented in Xtend with a 
combination of closures and implicit arguments and a number of functions implemented in the
\ic{CoolingBuilder} class\footnote{Of course, if you add the line count and
effort for implementing the builder, then using this alternative over the
plain procedural one might not look so interesting. However, if you just
create these builder functions once, and then create many different
transformations, this approach makes a lot of sense.}. Since this class is
imported with the \ic{@Inject extension} construct, the methods become available "just so":

\begin{lstlisting}[language=xtend]
class CoolingBuilder {
    
    CoolingLanguageFactory factory = CoolingLanguageFactory::eINSTANCE
    
    def eventHandler( CustomState it, (EventHandler)=>void handler ) {
        val res = factory.createEventHandler
        res
    }
    
    def symbolRef( EventHandler it, (SymbolRef)=>void symref ) {
        val res = factory.createSymbolRef
        it.events += res
    }
    
    def symbol( SymbolRef it, CustomEvent event ) {
        it.symbol = event
    }
    
    def changeStateStatement( EventHandler it, CustomState target ) {
        val res = factory.createChangeStateStatement
        it.statements += res
        res.targetState = target
    }
}
\end{lstlisting}



\section{MPS Example}

\todo{Do we want to discuss the builder lang extension?}
 
The distinction between code generators and model-to-model transformations is
much less clear in MPS. While there is the specialized \ic{textgen} language for
text generation, it is really just used "at the end" of the transformation chain
where code expressed in GPLs (like Java or C) is generated to text so it can be passed
to existing compilers.
\fig{mps-textgen} shows the \ic{textgen} component for mbeddr C's
\ic{IfStatement}. MPS' text generation language basically appends text to a
buffer. We won't discuss this aspect of MPS any further, since MPS \ic{textgen} is
basically a wrapper language around a \ic{StringBuffer}. However, this is
perfectly adequate for the task at hand, since it is only used in the last stage
of generation where the AST is essentially structurally identical to the
generated text\footnote{If you want to generate text that is structurally
different, then the textgen language is a bit of a pain to use; in this case,
the MPS philosophy recommends you build a suitable intermediate language (such
as for XML, or even for a particular schema).}.
 
\begin{figure}[ht]
\fbox{
\begin{minipage}{104.5mm}
  \includegraphics[width=8cm]{figures-impl/5/mps-textgen.png}
  \caption[]{The AST-to-text generator for an \icsn{if} statement. If first
  checks if the condition happens to be a \icsn{true} literal, in which case the \icsn{if}
  statement is optimized away and only the \icsn{thenPart} is output. Otherwise
  we generate an \icsn{if} statement, the condition in parentheses, and then the
  \icsn{thenPart}. We then iterate over all the \icsn{elseIfs}; an \icsn{elseIf} has
  its own textgen, and we delegate to that one. We finally output the code for
  the \icsn{else} part.}
  \label{mps-textgen} 
\end{minipage}
}
\end{figure}


\noindent 
DSLs and language extensions typically use model-to-model transformations to
"generate" code expressed in a low level programming language. In general,
writing transformations in MPS involves two ingredients. Templates define the
actual transformation. Mapping configurations define which template to run when
and where. Templates are valid sentences of the target language. So-called
macros are used to express dependencies on and queries over the input model. For
example, when the guard condition (a C expression) should be generated into an
\ic{if} statement in the target model, you first write an \ic{if} statement with
a dummy condition into the template. The following would work: \ic{if (true)
\{\}}. Then the nodes that should be replaced by the transformation with nodes
from the input model are annotated with macros. In our example, this would look
like this: \ic{if (COPY\_SRC[true])\{\}}. Inside the \ic{COPY\_SRC} macro you
put an expression that describes which elements from the input model should
replace the dummy node \ic{true}: \ic{node.guard;} would use the guard condition
of the input node (expected to be of type \ic{Transition} here). When the
transformation is executed, the \ic{true} node will be replaced by what the
macro expression returns --- in this case, the guard of the input transition. Wewill explain this process in detail below.


\parhead{Translating the State Machine} State machines live inside modules. Just
like \ic{struct}s they can be instantiated. The following code shows an example.
Notice the two global variables \ic{c1} and \ic{c2}, which are instances of the
same state machine \ic{Counter}.

\begin{lstlisting}[language=mbeddr]
module Statemachine imports nothing { 
   
  statemachine Counter { 
    in events 
      start()  
      step(int[0..10] size) 
    out events 
      started()  
      resetted() 
      incremented(int[0..10] newVal)  
    local variables 
      int[0..10] currentVal = 0 
      int[0..10] LIMIT = 10 
    states ( initial = start ) 
      state start { 
        on start [ ] -> countState { send started(); } 
      } 
      state countState { 
        on step [currentVal + size > LIMIT] -> start { send resetted(); } 
        on step [currentVal + size <= LIMIT] -> countState { 
          currentVal = currentVal + size; 
          send incremented(currentVal); 
        } 
        on start [ ] -> start { send resetted(); } 
      } 
  }
  
  Counter c1; 
  Counter c2; 
   
  void aFunction() { 
    trigger(c1, start); 
  } 
}
\end{lstlisting}


\noindent 
State Machines are translated to the following lower level C entities:

\begin{itemize}
  \item an \ic{enum} for the states (a literal for each state)
  \item an \ic{enum} for the events (a literal for each event)
  \item a \ic{struct} declaration that contains an attribute for the
  current state, as well as attributes for the local variables declared in the
  state machine
  \item and finally, a function that implements the behavior of the state
  machine using a \ic{switch} statement. The function takes two arguments: one
  named \ic{instance} typed with the \ic{struct} mentioned in the previous
  item, and one named \ic{event} that is typed to the event \ic{enum}
  mentioned above. The function checks whether the instance's current state can
  handle the event passed in, evaluates the guard, and if the guard is
  \ic{true}, executes exit and entry actions and updates the current state.
\end{itemize} 

\noindent This high level structure is clearly discernable from the two main
templates shown in \fig{mps-sm-gen-1} and \fig{mps-sm-gen-2}. 

\begin{figure}[h]
\fbox{
\begin{minipage}{104.5mm}
  \includegraphics[width=10cm]{figures-impl/5/mps-sm-gen-1.png}
  \caption[]{The MPS generator that inserts two \icsn{enum} definitions
  and a \icsn{struct} into the module which contains the \icsn{StateMachine}.}
  \label{mps-sm-gen-1}  
\end{minipage}
}
\end{figure}


\noindent 
The MPS transformation engine works in phases. Each phase transforms models
expressed in some languages to other models expressed in the same or other
languages. Model elements for which no transformation rules are specified are
simply copied from one phase to the next. Reduction rules are used to intercept
program elements and transform them as generation progresses through the phases. \fig{mps-gen-phases}
shows how this affects state machines. A reduction rule is defined that maps
state machines to the various elements we mentioned above. Notice how the
surrounding module remains unchanged, because no reduction rule is defined for
it. 

\todo{change figures to remove the med stuff}
\begin{figure}[ht]
\begin{center}
  \includegraphics[width=\columnwidth]{figures-impl/5/mps-gen-phases.png}
  \caption[]{State machines are transformed (via a model-to-model
  transformation, if you will) into two \icsn{enum}s, a \icsn{struct} and a
  function. These are then transformed to text via the regular
  \icsn{com.mbeddr.core} textgen.}
  \label{mps-gen-phases} 
\end{center} 
\end{figure}

\noindent 
Let us look in more detail at the template in \fig{mps-sm-gen-1}. It reduce a
\ic{Statemachine}, the input node, to two \ic{enum}s and a \ic{struct}. We use
template fragments (marked with \ic{<TF ... TF>}) to highlight those parts of
the template that should actually be used to replace the input node as the
transformation executes. The surrounding \ic{ImplementationModule} (\ic{module
dummy}) is scaffolding: it is only needed because \ic{enum}s and \ic{struct}s
\emph{must} live in \ic{ImplementationModule}s in a valid instance of the
mbeddr C language.

We have to create an \ic{enum} literal for each state and each event. To achieve
this, we iterate over all states (and events, respectively). This is expressed
with the \ic{LOOP} macros in the template (\fig{mps-sm-gen-1}). The expression
that determines what we iterate over is entered in the Inspector, MPS'
equivalent to a properties window; \fig{mps-sm-inspector1} shows the code for
iterating over the states\sidenote[][-10mm]{Note that the only really
interesting part of \fig{mps-sm-inspector1} is the body of the anonymous function
(\icsn{node.states;}), which is why in the future we will only show this part.}.
For the literals of the events \ic{enum} we use a similar expression
(\ic{node.events;}).
\todo{above, the sidenote is somehow broken (-10)}

\begin{figure}[ht]
\fbox{
\begin{minipage}{104.5mm}
  \includegraphics[width=\columnwidth]{figures-impl/5/mps-sm-inspector1.png}
\end{minipage}
}
\caption[]{The inspector is used to provide the implementation
details for the macros used in the templates. This one belongs to a
\icsn{LOOP} macro, so we provide an expression that returns a
collection, over which the \icsn{LOOP} macro iterates.}
\label{mps-sm-inspector1} 
\end{figure}
 

\noindent 
The \ic{LOOP} macro iterates over collections and then creates an instance of
the concept it is attached to for each iteration. In case of the two
\ic{enum}s, the \ic{LOOP} macro is attached to an \ic{EnumLiteral}, so we create
an \ic{EnumLiteral} for each event and state we iterate over. However, these
various \ic{EnumLiteral}s all must have different names. In fact, the name of
each literal should be the name of the state/event for which it is created. We
can use a property macro, denoted by the \ic{\$} sign, to acheive this. A
property macro is used to replace values of properties\footnote{The node
macros used above (\icsn{COPY\_SRC}) replace whole nodes as opposed toprimitive \emph{properties} of nodes.}. In this case we use it to replace the\ic{name} property of the generated \ic{EnumLiteral}. Here is the implementation 
expression of the property macro (also entered in the inspector):

\begin{lstlisting}[language=mps]
node.cEnumLiteralName();
\end{lstlisting}

\todo{clean up I and we}

\noindent In the code above, \ic{cEnumLiteralName} is a behavior method.
Behavior methods are defined as part of the behavior aspect of the \ic{State}
concept.
It concatenates the \ic{name} of the parent \ic{Statemachine} with the string
\ic{\_\_state\_} and the name of the current state (in order to get a unique
name for each state). We use property macros in a similar way to define the
names of the two generated \ic{enum}s themselves.

\begin{lstlisting}[language=mps]
concept behavior State {                      
                                              
  public string cEnumLiteralName() {         
    return this.parent : Statemachine.name + "__state_" + this.name;
  }                                           
                                              
}                                             
\end{lstlisting}

\noindent 
The first of the \ic{struct} attributes is also interesting. It is used to
store the current state. It has to be typed to the state \ic{enum} that is
generated from this particular state machine. The type of the attribute is an
\ic{EnumType}; \ic{EnumType}s extend \ic{Type} and reference the
\ic{EnumDeclaration} whose type they represent. How can we establish the
reference to the correct \ic{EnumDeclaration}? We use a reference macro
(\ic{->\$}) to retarget the reference. \fig{mps-ref-macro} shows the macro's
expression.

\begin{figure*}[ht]
\fbox{
\begin{minipage}{105mm}
  \includegraphics[width=17cm]{figures-impl/5/mps-ref-macro.png}
\end{minipage}
}
  \caption[][-10mm]{A reference macro has to return either the target node,
  or the name of the target node. The name is then resolved using the scoping
  rules for the particular reference concept.}
  \label{mps-ref-macro} 
\end{figure*}

\noindent Note how a reference macro expects either the target node (here: an
\ic{EnumDeclaration}) as the return value, or a \ic{string}. That \ic{string}
would be the name of the target element. Our implementation returns the name of
the states \ic{enum} generated in the same template. MPS then uses the target
language's scoping rules to find and link to the correct target
element\footnote{So this is not simply a global name lookup! Since MPS knows the
reference is an \icsn{EnumLiteralRef} expression, the scope of the that concept is
used. As long as the name is unique within the scope, this is completely
deterministic. Alternatively, the actual node can be identified and returned
from the reference macro using mapping labels. However, using names is much more
convenient and works also for cross-model references, where mapping labelsdon't work.}.

 
\begin{figure}[h]
\fbox{
\begin{minipage}{105mm}
  \includegraphics[width=\columnwidth]{figures-impl/5/mps-sm-gen-2.png}
\end{minipage}
}
  \caption[][40mm]{The transformation template for generating the
  \icsn{switch}-based implementation of a \icsn{StateMachine}. See the text for
  details.}
  \label{mps-sm-gen-2} 
\end{figure}


\noindent 
Let us now address the second main template, \fig{mps-sm-gen-2}, which generates
the execute function. Looking at the template fragment markers (\ic{<TF ...
TF>}) reveals that we only generate the \ic{switch} statement with this
template, \emph{not} the function that contains it. The reason is that we need
to be able to embed the state machine \ic{switch} into other function-like
concepts as well (e.g.,~operations in components defined in the mbeddr
components extension), so we have separated the generation of the function fromthe generation of the actual state machine behavior.

The \ic{switch} expression is interesting. It switches over the current state of
the current state machine instance. That instance is represented by the
\ic{instance} parameter passed into the function. It has a \ic{\_\_currentState}
field. Notice how the function that contains the \ic{switch} statement \emph{in
the template} has to have the \ic{instance} argument, and how its type, the
\ic{struct}, has to have the \ic{\_\_currentState} attribute \emph{in the
template}. If the respective elements were not there in the template, we
couldn't write the template code! Since there is a convention that in the
\emph{resulting} function the argument will also be called \ic{instance}, and
the attribute will also be called \ic{\_\_currentState}, we don't have to use a
reference macro to retarget the two.

Inside the \ic{switch} we then \ic{LOOP} over all the states of the state
machine and generate a \ic{case}, using the state's corresponding \ic{enum}
literal. Inside the \ic{case}, we embed another \ic{switch} that switches over
the \ic{event} argument. Inside this inner \ic{switch} we iterate over all
transitions that are triggered by the event we currently iterate over:

\begin{lstlisting}[language=mps]
node<State> state = // get current state from context 
state.transitions.where({~it => it.trigger.event == node; });
\end{lstlisting}

\noindent 
We then generate an \ic{if} statement that checks at runtime whether the guard
condition for this transition is \ic{true}. We copy in the guard condition using
the \ic{COPY\_SRC} macro attached to the \ic{true} dummy node. The
\ic{COPY\_SRC} macro copies the original node, but it also applies additional
reduction rules for this node (and all its descendants), if there are any. For
example, in a guard condition, you can refer to event arguments. The reference
to \ic{size} in the \ic{step} transition is an example.

\begin{lstlisting}[language=mbeddr]
statemachine Counter { 
  in events 
    step(int[0..10] size) 
    ... 
  states ( initial = start ) 
    ... 
    state countState { 
      on step [currentVal + size > LIMIT] -> start { send resetted(); } 
    }
}
\end{lstlisting}

\noindent 
Event arguments are mapped to the resulting C function via a \ic{void*} array. A
reference to an event argument (\ic{EventArgRef}) hence has to be reduced to
accessing the \ic{n}-th element in the array (where \ic{n} is the index of the
event argument in the list of arguments). \fig{mps-eventArgRef} shows the
reduction rule. The reduction rule creates code that looks like this (for an
\ic{int} event attribute): \ic{*((int*)arguments[0])}. It accesses the array,
casts the element to a pointer to the type of the argument, and then
dereferences everything.

\begin{figure}[h]
\fbox{ 
\begin{minipage}{105mm}
  \includegraphics[width=\columnwidth]{figures-impl/5/mps-eventArgRef.png}
\end{minipage}
}
  \caption[]{The reduction rule for references to event arguments (to
  be used inside guard conditions of transitions). }
  \label{mps-eventArgRef} 
\end{figure}

\noindent 
Inside the \ic{if} statement, we have to generate the code that has to be
executed if a transition fires. We first copy in all the exit actions of the
current state. Once again, the \ic{int8\_t exitActions;} is just an arbitrary
dummy statement that will be replaced by a the statements in the exit actions
(\ic{COPY\_SRCL} replaces a node with a \emph{list} of nodes). The respective
expression is this:

\begin{lstlisting}[language=mps]
(node, genContext, operationContext)->sequence<node<>> { 
  if (node.parent : State.exitAction != null) { 
    return node.parent : State.exitAction.statements; 
  } 
  new sequence<node<>>(empty); 
}
\end{lstlisting}

\noindent 
We then do the same for the transition actions of the current transition, set
the \ic{instance->\_\_currentState} to the target state of the transition using
a reference macro (\ic{node.targetState.cEnumLiteralName();}), and then we
handle the entry actions of the target state. Finally we return, because at
most one transition can fire as a consequence of calling the state machine execute
function.


As the last example I want to show how the \ic{TriggerSMStatement} is
translated. It "injects" an event into a state machine, and is used as follows:

\begin{lstlisting}[language=mbeddr]
Counter c1; 
 
void aFunction() { 
  trigger(c1, start); 
} 
\end{lstlisting}


\noindent 
It has to be translated to a call to the generated state machine execute
function that we have discussed at length above. For simplicity, we explain
a version of the \ic{TriggerSMStatement} that does not include event arguments.
\fig{mps-trigger} shows the template. 

 
\begin{figure}[h]
\fbox{
\begin{minipage}{105mm}
  \includegraphics[width=\columnwidth]{figures-impl/5/mps-trigger.png}
\end{minipage}
}
  \caption[][-55mm]{The reduction rule for a \ic{trigger} statement. It is
  transformed to a call to the function that implements the behavior of the
  state machine that is referenced in the first argument of the \ic{trigger}
  statement.}
  \label{mps-trigger} 
\end{figure}

\noindent We use a dummy function \ic{someMethod} so we can embed a function
call --- because we have to generate a function call to the execute function generated
from the state machine. Only the function call is surrounded with the template
fragment markers (so only it will be generated). The function we call \emph{in
the template} is the \ic{smExecuteFunction} in the template. It has the same
signature of the real, generated state machine execute function. We use a
reference macro to retarget the \ic{function} reference in the function call. It
uses the following expression, which returns the name of the function generated
for the state machine referenced in the \ic{statemachine} expression of the
trigger statement:
\begin{lstlisting}[language=mps]
node.statemachine.type : StatemachineType.machine.cFunctionName();
\end{lstlisting}

\noindent 
Note how the first argument to the \ic{trigger} statement can be \emph{any}expression (local variable reference, global variable reference, a functioncall). However, we know (and enforce via the type system) that the expression'stype must be a \ic{StatemachineType}, which has a reference to the\ic{Statemachine} whose instance the expression represents. So we can cast,access the machine, and get the name of the execute function generated from thatstate machine\footnote{This is an example of where we use the type system in
the code generator --- not just for checking a program for type correctness.}.

The second argument of the \ic{trigger} statement is a reference to the event we
want to trigger. We can use another reference macro to find
the \ic{enum} literal generated for this event. The macro code is straight forward:

\begin{lstlisting}[language=mps]
node.event.cEnumLiteralName();
\end{lstlisting}





\section{Spoofax Example}

In Spoofax, model-to-model transformations and code generation are both
specified by rewrite rules\footnote{Rewrite rules have been introduced in
\todoref{}.}. This allows for the seamless integration of model-to-model
transformation steps into the code generation process; the clear distinction 
between model-to-model transformation and code generation vanishes.

\parhead{Code Generation by String Interpolation} Pure code generation from
abstract syntax trees to text can be realised by rewriting to strings. The
following simple rules rewrite types to their corresponding representation in
Java:

\begin{lstlisting}[language=stratego]
to-java: IntType()     -> "int"
to-java: BoolType()    -> "boolean"
to-java: StringType()  -> "String"
to-java: EntType(name) -> name
\end{lstlisting}
\noindent
For entity types, we use their name as the Java representation.
Typically, more complex rules are recursive and use string
interpolation\footnote{We used string interpolation already before to compose
error messages \todoref{}.} to construct strings from fixed and variable parts.
For example, the following two rewrite rules generate Java code for entities and
their properties:

\begin{lstlisting}[language=stratego]
  to-java:
    Entity(x, ps) ->
    $[ class [x] {
           [ps']
       }
    ]
    with
      ps' := <map(to-java)> ps

to-java:
    Property(x, t) -> 
    $[ private [t'] [x];
      
       public [t'] get_[x] {
           return [x];
       }
      
       public void set_[x] ([t'] [x]) {
           this.[x] = [x];    
       }
    ]
    with
      t' := <to-java> t
\end{lstlisting}


\noindent 
String interpolation takes place inside \ic{\$[\ldots]} brackets and allows to
combine fixed text with variables that are bound to strings. Variables can be
inserted using brackets \ic{[\ldots]} without a dollar sign\footnote{You can
also use any other kind of bracket: \icsn{\{\ldots\}}, \icsn{<\ldots>}, and
\icsn{(\ldots)} are allowed as well.}. Instead of variables, we can also use
directly the results from other rewrite rules that yield strings or lists of
strings:

\begin{lstlisting}[language=stratego]
  to-java:
    Entity(x, ps) ->
    $[ class [x] {
           [<map(to-java)> ps]
       }
     ]
\end{lstlisting}

\noindent 
Indentation is important both for the readability of rewrite rules and of the
generated code: the indentation leading up to the \ic{\$[\ldots]} brackets is
removed, but any other indentation beyond the bracket level is preserved in the
generated output. This way, we can indent the generated code, but also our
rewrite rules. Applying \ic{to-java} to the initial \ic{shopping} entity, will
yield the following Java code:

\begin{lstlisting}[language=java]
class Item {
    
    private String name;
    
    public String get_name {
        return name;
    }
    
    public void set_name (String name) {
        this.name = name;    
    }
    
    private boolean checked;
    
    public boolean get_checked {
        return checked;
    }
    
    public void set_checked (boolean checked) {
        this.checked = checked;    
    }
    
    private Num order;
    
    public Num get_order {
        return order;
    }
    
    public void set_order (Num order) {
        this.order = order;    
    }
}
\end{lstlisting}

\noindent When we prefer camelcase in method names, we need to slightly change
our code generation rules, replacing \ic{get\_[x]} and \ic{set\_[x]} by
\ic{get[<to-upper-first>x]} and \ic{set[<to-upper-first>x]}. We also need to
specify the following rewrite rule, which turns a string into a list of
characters, upper-cases the first character, and turns the characters back into
a string:

\begin{lstlisting}[language=stratego]
to-upper-first: s -> s'
  where
    [first|chars] := <explode-string> s ;
    upper         := <to-upper> first ;
    s'            := <implode-string> [upper|chars]
\end{lstlisting}

\guido{what are these explode/implode-strings? 
are they library functions of Spoofax rewrite rules? are they fix, can they 
be extended with new functions?}

\parhead{Editor Integration} To integrate the code generation into our editor,
we first have to define the following rewrite rule:

\begin{lstlisting}[language=stratego]
  generate-java:
    (selected, position, ast, path, project-path) -> (filename, result)
    with
      filename := <guarantee-extension(|"java")> path;
      result   := <to-java> selected
\end{lstlisting}

\noindent Generation happens on a per-file basis. The rule follows Spoofax'
convention for editor integration. On the left-hand side, it matches the current
\ic{selection} in the editor, its \ic{position} in the abstract syntax tree, the abstract syntax tree itself, the \ic{path}
of the source file in the editor, and the path of the project this file belongs
to. On the right-hand side, it results in the name of the generated file and its
content as a string. The file name is derived from the source file's path, while
the file content is generated from the current selection. If the generation
should consider the whole abstract syntax regardless of the selection, we can
replace the last line by \ic{result := <to-java> ast}.

Once we have defined this rule, we can register it as a \ic{builder} in
\ic{editor/Lang-Builders.esv}. Here, we add the following rule:

\begin{lstlisting}[morekeywords={builder, generate, java, openeditor, realtime}]
builder: "Generate Java code (for selection)" = generate-java (openeditor) (realtime)
\end{lstlisting}

\guido{for somebody that does not know spoofax, this is too detailed}

\noindent 
This defines a label for our transformation, which is added to the editor's
\emph{Transform} menu. Additional options can be used to customize the behaviour
of the transformation: \ic{(openeditor)} tells Spoofax to open the generated
file in an editor, while \ic{(realtime)} enforces an automatic re-generation
after changes to the source in the editor. Further options are shown in
\fig{Fig:spoofax-builder-options}.

\begin{figure}[t]
\begin{tabular}{|l|l|}
\hline
\textbf{Option} & \textbf{Description} \\ 
\hline
\ic{(openeditor)} & Opens the generated file in an editor. \\
\ic{(realtime)} & Re-generates the file as the source is edited. \\ 
\ic{(meta)} & Excludes the transformation  \\
            & from the deployed plugin. \\
\ic{(cursor)} & Transforms always the tree node at the cursor. \\                               
\hline
\end{tabular}                  
  
\caption{Options for builders in Spoofax.}
\label{Fig:spoofax-builder-options}
\end{figure}

\parhead{Code Generation by Model Transformation} Rewrite rules with string
interpolation support a template-based approach to code generation.
Thus, they share two typical problems of template languages. First, they are not
\emph{syntax safe}, that is, they do not guarantee the syntactical correctness
of the generated code: we might accidently generate Java code which can not be
parsed by a Java compiler. Such errors can only be detected by testing the code
generator. Second, they inhibit subsequent transformation steps. For example, we
might want to optimize the generated Java code, generate Java Bytecode from it,
and finally optimize the generate Java Bytecode. At each step, we would first
need to parse the generated code from the previous step before we can apply the
actual transformation.

Both problems can be avoided by generating abstract syntax trees instead of
concrete syntax, i.e.~by using model-to-model transformations instead of code
(text) generation. This can be achieved by constructing terms on the left-hand
side of rewrite rules:

\begin{lstlisting}[language=stratego]
  to-java: IntType()    -> IntBaseType()
  to-java: BoolType()   -> BooleanBaseType()
  to-java: StringType() -> ClassType("java.lang.String")
  to-java: EntType(t)   -> ClassType(t)

  to-java:
    Entity(x, ps) -> Class([], x, ps')
       ps' := <mapconcat(to-java)> ps

  to-java:
    Property(x, t) -> [field, getter, setter]
    with
      t'     := <to-java> t ;
      field  := Field([Private()], t', x) ;
      getter := Method([Public()], t', $[get_[x]], [], [Return(VarRef(x))]) ;
      setter := Method([Public()], Void(), $[set_[x]], [Param(t', x)], [assign]) ;
      assign := Assign(FieldRef(This(), x), VarRef(x)) 
\end{lstlisting}

\guido{the Concrete Object Syntax paragraph header shows up twice. Can't be
intended, right?}

\parhead{Concrete Object Syntax}%
%
When we generate abstract syntax trees instead of concrete syntax, we can easily compose transformation steps into a transformation chain by using the output of transformation $n$ as the input for transformation $n+1$. 
But this chain will still result in abstract syntax trees.
To turn them back into text, it has to be pretty printed (or serialized).
Spoofax generates a language-specific rewrite rule \ic{pp-<LanguageName>-string} in \ic{lib/editor-common.generated} which rewrites an abstract syntax tree into a string according to a pretty-printer definition. 
Spoofax generates a default pretty-printer definition in \ic{syntax/<LanguageName>.generated.pp} from the
syntax definition of a language.
We will discuss these pretty-printer definitions and how they can be customized in the next chapter.

\parhead{Concrete Object Syntax} Both template-based and term-based approaches
to code generation have distinctive benefits. While template-based generation
with string interpolation allows for concrete syntax in code generation rules,
abstract syntax tree generation guarantees syntactical correctness of the
generated code and enables transformation chains. To combine the benefits of
both approaches, Spoofax can parse user-defined concrete syntax quotations at
compile-time, checking their syntax and replacing them with equivalent abstract
syntax fragments. For example, a Java return statement can be expressed as
\ic{|[ return |[x]|; ]|}, rather than the abstract syntax form
\ic{Return(VarRef(x))}. Here, \ic{|[...]|} surrounds Java syntax. It quotes Java
fragments inside Stratego code. Furthermore, \ic{|[x]|} refers to a Stratego
variable \ic{x}, matching the expression in the return statement. In this case,
\ic{|[...]|} is an antiquote, switching back to Stratego syntax in a Java
fragment.


To enable this functionality, we have to customize Stratego, Spoofax'
transformation language. This requires four steps. First, we need to combine
Stratego's syntax definition with the syntax definitions of the source and
target languages. There, it is important to keep the sorts of the languages
disjunct. This can be achieved by renaming sorts in an imported module, which we
do in the following example for the \ic{Java} and the \ic{Stratego} module:

\begin{lstlisting}[language=sdf]
module Stratego-Mobl-Java
imports Mobl
imports Java     [ ID   => JavaId ]
imports Stratego [ Id   => StrategoId
                   Var  => StrategoVar
                   Term => StrategoTerm ]
\end{lstlisting}

\noindent 
Second, we need to define quotations, which will enclose concrete syntax
fragments of the target language in Stratego rewrite rules. We add a production
rule for every sort of concrete syntax fragments that we like to use in our
rewrite rules:

\begin{lstlisting}[language=sdf]
exports context-free syntax

  "|[" Module "]|"         -> StrategoTerm {"ToTerm"}
  "|[" Import "]|"         -> StrategoTerm {"ToTerm"} 
  "|[" Entity "]|"         -> StrategoTerm {"ToTerm"}
  "|[" EntityBodyDecl "]|" -> StrategoTerm {"ToTerm"}

  "|[" JClass  "]|"   -> StrategoTerm {"ToTerm"} 
  "|[" JField "]|"    -> StrategoTerm {"ToTerm"}
  "|[" JMethod "]|"   -> StrategoTerm {"ToTerm"}
  "|[" JFeature* "]|" -> StrategoTerm {"ToTerm"}
\end{lstlisting}

\todo{@Guido what exactly do we do we the above definitions? and what does
StrategoTerm {"ToTerm"} mean?}

\noindent 
\ic{StrategoTerm} is the sort for terms in a Stratego program. 
With these rules, we allow quoted Java fragments whereever an ordinary Stratego term is allowed.
We further use \ic{ToTerm} as a constructor in the abstract syntax tree.
This way, Stratego can recognise places where we use concrete object syntax inside Stratego code.
It will then lift the subtrees at these places into Stratego code.
For example, the abstract syntax of \ic{|[ return |[x]|; ]|} would be \ic{ToTerm(Return(...))}.
Stratego lifts this to \ic{NoAnnoList(Op(\"Return\", [...]))}, which is the abstract syntax tree for the term \ic{Return(x)}.

Third, we need to define antiquotations, which will enclose Stratego code in
target language concrete syntax fragments. Here, we add a production rule for
every sort where we like to inject Stratego code into concrete syntax fragments:

\begin{lstlisting}[language=sdf]
exports context-free syntax

  "|[" StrategoTerm "]|" -> JavaId    {"FromTerm"}
\end{lstlisting}

\noindent 
We use \ic{FromTerm} as a constructor in the abstract syntax tree.
Like \ic{ToTerm}, Stratego uses this to recognise places where we switch between concrete object syntax and Stratego code.
For example, the abstract syntax of \ic{|[ return |[x]|; ]|} would be \ic{ToTerm(Return(FromTerm(Var("x"))))}.
Stratego lifts this to \ic{NoAnnoList(Op(\"Return\", [Var("x")]))}, which is the abstract syntax tree for the term \ic{Return(x)}.

Finally, we need to create a \ic{<filename>.meta} file for every transformation
file \ic{<filename>.str} with concrete syntax fragments. In this file, we tell
Spoofax to use our customized Stratego syntax definition:

\begin{lstlisting}
Meta([ Syntax("Stratego-Mobl-Java") ])
\end{lstlisting}

\noindent 
Now, we can use concrete syntax fragments in our rewrite rules:

\begin{lstlisting}[language=stratego]
  to-java:
    |[ entity |[x]| { |[ps]| } ]| ->
    |[ class |[x]| { |[<mapconcat(to-java)> ps]| } ]|

to-java:
    |[ |[x]| : |[t]| ]| -> 
    |[ private |[t']| |[x]|;
       
       public |[t']| |[x]| { return |[x]|; }
       
       public void |[x]| (|[t']| |[x]|) { this.|[x]| = |[x]|; } ]|
    with
      t' := <to-java> t
\end{lstlisting}

\noindent Since Spoofax replaces concrete syntax fragments with equivalent
abstract syntax fragments, indentation in the fragments is lost. But the
generated code will still be indented by the pretty-printer.

Using concrete object syntax in Stratego code combines the benefits of string
interpolation and code generation by model transformation. With string
interpolation, we can use the syntax of the target language in code generation
rules, which makes them easy to write. However, it is also easy to make
syntactic errors, which are only detected when the generated code is compiled.
With code generation by model transformation, we can check if the generated
abstract syntax tree corresponds to the grammar of the target language. Actually
we can check each transformation rule and detect errors early. With concrete
object syntax, we can now use the syntax of the target language in code
generation. This syntax is checked by the parser which is derived from the
combined grammars of the target language and Stratego.

This comes at the price of adding quotations and antiquotation rules manually.
These rules might be generated from a declarative, more concise embedding
definition in the future. However, we cannot expect full automation here, since
choices for the syntactic sorts involved in the embedding and of quotation and
antiquotation symbols require an understanding of Stratego, the target language,
and the transformation we want to write. These choices have to be made carefully
in order to avoid ambiguities.

In general, there is room for more improvements of the embedding of the target
language into Stratego. When the target language comes with a Spoofax editor, we
want to get editor services like code completion, hover help, and content
folding also in the embedded editor. Until now, only syntax highlighting is
supported, using the Stratego coloring rules. Keywords of the target language
will be highlighted like Stratego keywords and embedded code fragments will get
a grey background color.



                      

\chapter{Building Interpreters}  
 
\chapterabstract{Interpreters are programs that execute DSL programs by
directly traversing the DSL program and performing the semantic actions
associated with the respective program elements. The chapter contains examples
for interpeters with Xtext, MPS and Spoofax.}
 
\noindent Interpreters are basically programs that read a model, traverse the
AST and perform actions corresponding to the semantics of the language
constructs whose instances appear in the AST\footnote{They may also produce text
(in which case such an interpreter is typically called a generator), inspecting
the structure and check constraints (in which case they are called a validator).
In this section we focus on interpreters that directly execute the program
according to its semantics.}. How an interpreter implementation looks depends a
lot on the programming language used for implementing it. Also, the complexity
of the interpreter directly reflects the complexity of the language it
processes in terms of size, structure and semantics\footnote{For example,
building an interpreter for a pure expression language with a functional programming language is almost trivial. In contrast,
the interpreters for languages that support parallelism can be much more
challenging.}. The following list explains some typical ingredients that go into
building interpreters for functional and procedural languages. It assumes a
programming language that can polymorphically invoke functions or methods.

\parhead{Expressions} For program elements that can be evaluated to values,
i.e., expressions, there is typically a function \ic{eval} that is defined for
the various expression concepts in the language, i.e.~it is polymorphically
overridden for subconcepts of \ic{Expression}. Since nested expressions are
almost always represented as nested trees in the AST, the \ic{eval} function
calls itself with the program elements it owns, and then performs some semantic
action on the result. Consider an expression \ic{3 * 2 + 5}. Since the \ic{+} is
at the root of the AST, \ic{eval(Plus)} would be called (by some outside
entity). It is implemented to add the values obtained by evaluating its
arguments. So it calls \ic{eval(Multi)} and \ic{eval(5)}. Evaluating a number
literal is minimal, since it simply returns the number itself. \ic{eval(Multi)}
would call \ic{eval(3)} and \ic{eval(2)}, multiplying their results and
returning the result of the multiplication as its own result, allowing plus to
finish its calculation\marginnote{Technically, \icsn{eval} could be implemented
as a method of the AST classes in an object-oriented language. However, this is
tyically not done since the interpreter should be kept separate from the AST
classes, for example, because there may be several interpreters or because the
interpreter is developed by other people than the AST.}.

  
\parhead{Statements} Program elements that don't produce a value only make sense
in programming languages that have side effects. In other words, execution of
such a language concept produces some effect either on global data in the
program (re-assignable variables, object state) or on the environment of the
program (sending network data or rendering a UI). Such program elements are
typically called \ic{Statements}. Statements are either arranged in a list
(typically called a statement list) or arranged recursively nested as a tree
(an \ic{if} statement has a \ic{then} and an \ic{else} part which are themselves
statements or statement lists). To execute those, there is typically a function
\ic{execute} that is overloaded for all of the different statement
types\footnote{It is also overloaded for
\icsn{StatementList} which iterates over all statements and calls \icsn{execute}
for each one.}. Note that statements often contain expressions and more
statement lists (as in \ic{if (a > 3) \{ print a; a=0; \} else \{ a=1;\}}), so
an implementation of \ic{execute} may call \ic{eval} and perform some action
based on the result (such as deciding whether to execute the \ic{then}-part of
the \ic{else}-part of the \ic{if} statement). Executing the \ic{then}-part and
the \ic{else}-part simply boils down to called \ic{execute} on the respective
statement lists.



\parhead{Environments} Languages that have can express assignment to variables
(or modify any other global state) require an environment during execution to
remember the values for the variables at each point during program execution.
Consider \ic{int a = 1; a = a + 1;}. In this example, the \ic{a} in \ic{a + 1}
is a variable reference. When evaluating this reference, the system must
"remember" that it had assigned \ic{1} to that variable in the previous
statement. The interpreter must keep some kind of global hash table, known as
the \emph{environment}, to keep track of symbols and their values, so it can
look them up when evaluating a reference to that symbol. Many (though not all)
languages that support assignable variables allow reassignment to the same
variable (as we do in \ic{a = a + 1;}). In this case, the environment must be
updatable. Notice that in \ic{a = a + 1} both mentions of \ic{a} are references
to the same variable, and both \ic{a} and \ic{a+1} are expressions.
However, only \ic{a} (and not \ic{a+1}) can be assigned to: writing \ic{a * 1 =
10 * a;} would be invalid. The notion of an \ic{lvalue} is introduced to
describe this. lvalues can be used "on the left side" of an assignment. Variable
references are typically lvalues (if they don't point to a \ic{const} variable).
Complex expressions usually are not, unless they evaluate to something that is
in turn an lvalue (an example of this is would be \ic{*(someFunc(arg1, arg2)) =
12;}, in C, assuming that \ic{someFunc} returns a pointer to an integer).
  
  
\parhead{Call Stacks} The ability to call other entities (functions, procedures,
methods) introduces further complexity, especially regarding parameter and
return value passing, and the values of local variables. Assume a function
\ic{int add(int a, int b) \{ return a + b; \}}. When this function is called via
\ic{add(2, 3);} the actual arguments \ic{2} and \ic{3} have to be bound to the
formal arguments \ic{a} and \ic{b}. An environment must be established for the
execution of \ic{add} that keeps track of these assignments. If functions can
also access global state (i.e.~symbols that are not explicitly passed in via
arguments), then this environment must delegate to the global environment in
case a referenced symbol cannot be found in the local environment. Supporting
recursively callable entities (as in \ic{int fac(int i) \{ return i == 0 ? 1 :
fac(i-1); \}}) requires that for each recursive call to \ic{fac} a new
environment is created, with a binding for the formal variables. However, the
original environment must be "remembered" because it is needed to complete the
execution of the outer \ic{fac} after a recursively called \ic{fac} returns.
This is achieved using a stack of environments. A new environment is pushed onto
the stack as a function is called (recursively), and the stack is popped,
returning to the previous environment, as a called function returns. The return
value, which is often expressed using some kind of \ic{return} statement, is
usually placed into the inner environment using a special symbol or name (such
as \ic{\_\_ret\_\_}). It can then be picked up from there as the inner
environment is popped.
 


 
\sect{Building an Interpreter with Xtext} 

\marginnote[3mm]{The example discussed in this section is built using the Xtext
interpreter framework that ships with the Xtext typesystem framework discussed earlier:
http://code.google.com/a/eclipselabs.org/p/xtext-typesystem/} 
 
This example describes an interpreter for the cooling language. It is used to
allow DSL users to "play" with the cooling programs before or instead of
generating C code. The interpreter can execute test cases (and report success or
failure) as well as simulate the program interactively. Since no code generation
and no real target hardware is involved, the turn-around time is much shorter
and the required infrastructure is trivial --- just the IDE\footnote{ The
abstraction level of such an interpreter must be decided. One alternative might
ignore for example the use of registers when performing an assignment, avoiding
problems resulting from parallelism. Alternatively, the interpreter might model
everything and thereby can address issues related to parallelism. In other
words, an interpreter defines a virtual machine and it is fundamental that this
virtual machine has an adequate abstraction level and/or the users are aware of
exactly what it means for the execution of the program on the target hardware if
the program runs on the virtual machine.}. The execution engine, as the
interpreter is called here, has to handle the following language aspects:
\todo{I think the big footnote above should go into the design part.}

\begin{itemize}

  \item The DSL supports expressions and statements, for example in the entry
  and exit actions of states. These have to be supported in the way described
  above.

  \item The top level structure of a cooling program is a state machine. So the
  interpreter has to deal with states, events and transitions.

  \item The language supports deferred execution (i.e.~perform a set of
  statements at a later time), so the interpreter has to keep track of deferred
  parts of the program
  \item The language supports writing tests for cooling programs incl. mock
  behavior for hardware elements. A set of constructs exists to express this
  mock behavior, specifically, ramps to change temperatures over time. These
  background tasks must be handled by the interpreter as well.

\end{itemize}


\parhead{Expressions and Statements} We start our description of the execution
engine inside out, by looking at the interpreter for expressions and statements
first. As mentioned above, for interpreting expressions, there is typically an
overloaded \ic{eval} operation, that contains the implementation of expression
evaluation for each subtype of a generic \ic{Expression} concept. However, Java
doesn't have polymorphically overloaded member methods\footnote{Java only
supports polymorphic dispatch on the \icsn{this} pointer, but not on method
arguments}. We compensate this by generating a dispatcher that calls a
\emph{different} method for each subtype of \ic{Expression}\footnote{If the
interpreter had been built with Xtend instead, we would not have had to generate
the dispatcher for the \icsn{StatementExecutor} or the \icsn{ExpressionEvaluator}
since Xtend provides polymorphic dispatch on method arguments. However, the
fundamental logic and structure of the interpreter would have been similar.}.
The generation of this dispatcher is integrated with Xtext via an Xtext workflow
fragment, i.e.~the dispatcher is generated during the overall Xtext code
generation process. The fragment is configured with the abstract meta classes
for expressions and statements. The following code shows the fragment
configuration:

\begin{lstlisting}[morekeywords={fragment}]
fragment = de.itemis.interpreter.generator.InterpreterGenerator {
    expressionRootClassName = "Expression"
    statementRootClassName = "Statement"
}
\end{lstlisting}


\noindent 
This fragment generates an abstract class that acts as the basis for the
interpreter for the particular set of statements and expressions. As the
following piece of code shows, the class contains an \ic{eval} method that uses
\ic{instanceof} checks to dispatch to a method specific to the subclass and
thereby emulating polymorphically overloaded methods. The specific methods throw
an exception and are expected to be overridden by a manually written subclass
that contains the actual interpreter logic for the particular language concepts.
The class also uses a logging framework (based on the \ic{LogEntry} class) that
can be used to create a tree shaped trace of expression evaluation, which, short
of building an actual debugger, is very useful for debugging and understandingthe execution of the interpreter.

\begin{lstlisting}[language=java]
public abstract class AbstractCoolingLanguageExpressionEvaluator 
                      extends AbstractExpressionEvaluator {

    public AbstractCoolingLanguageExpressionEvaluator( ExecutionContext ctx ) {
        super(ctx);
    }

    public Object eval( EObject expr, LogEntry parentLog ) 
                  throws InterpreterException {
        LogEntry localLog = parentLog.child(LogEntry.Kind.eval, expr, 
                 "evaluating "+expr.eClass().getName());
        if ( expr instanceof Equals ) {
            return evalEquals( (Equals)expr, localLog );
        }
        if ( expr instanceof Unequals ) {
            return evalUnequals( (Unequals)expr, localLog );
        }
        if ( expr instanceof Greater ) {
            return evalGreater( (Greater)expr, localLog );
        }
        // the others...
    }

    protected Object evalEquals( Equals expr, LogEntry log ) 
              throws InterpreterException {
        throw new MethodNotImplementedException(expr, 
              "method evalEquals not implemented");
    } 
    
    protected Object evalUnequals( Unequals expr, LogEntry log ) 
              throws InterpreterException {
        throw new MethodNotImplementedException(expr, 
              "method evalUnequals not implemented");
    } 
    
    protected Object evalGreater( Greater expr, LogEntry log )
              throws InterpreterException {
        throw new MethodNotImplementedException(expr, 
              "method evalGreater not implemented");
    } 
    
}
\end{lstlisting}

    
\noindent 
A similar class is generated for the statements. Instead of \ic{eval}, the
method is called \ic{execute} and it does not return a value. In every other
respect the \ic{StatementExecutor} is similar to the \ic{ExpressionEvaluator}.

Let us now take a look at some example method implementations. The following
code shows the implementation of \ic{evalNumberLiteral} which evaluates number
literals such as \ic{2} or \ic{2.3} or \ic{-10.2}. To recap, the following
grammar is used for defining number literals:
\begin{lstlisting}[language=xtextgrammar]
Atomic returns Expression:
    ...
    ({NumberLiteral} value=DECIMAL_NUMBER);

terminal DECIMAL_NUMBER:
    ("-")? ('0'..'9')* ('.' ('0'..'9')+)?;
\end{lstlisting}


\noindent 
Before we dive into the details of the interpreter code below, it is worth
mentioning that the "global data" held by the execution engine is stored and
passed around using an instance of \ic{EngineExecutionContext}. For example, it
contains the environment that keeps track of symbol values, and it also has
access to the type system implementation class for the language. The
\ic{ExecutionContext} is available through the \ic{eec()} method in the
\ic{StatementExecutor} and \ic{ExpressionEvaluator}. 

With this in mind, the implementation of \ic{evalNumberLiteral} should be easily
understandable. We first retrieve the actual value from the \ic{NumberLiteral}
object, and we find out that type of the number literal using the \ic{typeof}
function in the type system. The type system basically inspects whether the
value contains a dot or not and returns either a \ic{DoubleType} or
\ic{IntType}. Based on this distinction, \ic{evalNumberLiteral} returns either a
Java \ic{Double} or \ic{Integer} as the value of the \ic{NumberLiteral}. In
addition, it creates log entries that document these decisions.

\begin{lstlisting}[language=java]
protected Object evalNumberLiteral(NumberLiteral expr, LogEntry log) {
    String v = ((NumberLiteral) expr).getValue();
    EObject type = eec().typesystem.typeof(expr, new TypeCalculationTrace());
    if (type instanceof DoubleType) {
        log.child(Kind.debug, expr, "value is a double, " + v);
        return Double.valueOf(v);
    } else if (type instanceof IntType) {
        log.child(Kind.debug, expr, "value is a int, " + v);
        return Integer.valueOf(v);
    }
    return null;
}
\end{lstlisting}


\noindent The evaluator for \ic{NumberLiteral} was simple because number
literals are leaves in the AST and have no children, so no recursive invocations
of \ic{eval} are required. This is different for the \ic{LogicalAnd}, which has
two children in the \ic{left} and \ic{right} properties. The following code
shows the implementation of \ic{evalLogicalAnd}. The first statement calls the
evaluator, for the \ic{left} properties. If \ic{leftVal} is \ic{false} we return
without evaluating the right argument\footnote{Most programming languages never
evaluate the right argument of a logical and if the left one is \icsn{false} and
hence the overall logical and can never become \icsn{true}.} If it is \ic{true} we
evaluate the right argument. The argument evaluation uses a utility method
called \ic{evalCheckNullLog} which automatically creates a log entry for this
recursive call and stops the interpreter if the value passed in is \ic{null}
(which would mean the AST is somehow broken). 

\begin{lstlisting}[language=java]
protected Object evalLogicalAnd(LogicalAnd expr, LogEntry log) {
    boolean leftVal = ((Boolean)evalCheckNullLog( expr.getLeft(), log ))
                      .booleanValue();
    if ( !leftVal ) return false;                  
    boolean rightVal = ((Boolean)evalCheckNullLog( expr.getRight(), log ))
                      .booleanValue(); 
    return rightVal;
}
\end{lstlisting}


\noindent 
So far, we haven't used the environment, since we haven't worked with variables
and their (changing) values. Let's now look and how variable assignment is
handled. We first look at the \ic{AssignmentStatement},  which is implemented 
in the \ic{StatementExecutor}:
\begin{lstlisting}[language=java]
protected void executeAssignmentStatement(AssignmentStatement s, LogEntry log){
    Object l = s.getLeft();
    Object r = evalCheckNullLog(s.getRight(), log);
    SymbolRef sr = (SymbolRef) l;
    SymbolDeclaration symbol = sr.getSymbol();
    eec().environment.put(symbol, r);
    log.child(Kind.debug, s, "setting " + symbol.getName() + " to " + r);
}
\end{lstlisting}


\noindent 
The first two lines get the \ic{left} argument as well as the value of the
\ic{right} argument. Note how only the right value is evaluated: the left
argument is a symbol reference (made sure through a constraint, since only
\ic{SymbolRef}s are lvalues in this language). We then retrieve the symbol
referenced by the symbol reference and create a mapping from the symbol to the
value in the environment, effectively "assigning" the value to the symbol during
the execution of the interpreter.

The implementation of the \ic{ExpressionEvaluator} for a symbol reference (if it
is used not as an lvalue) is shown in the following code. We use the same
environment to look up the value for the symbol. We then check if the value is
\ic{null} (i.e.~nothing has been assigned to the symbol as yet). In this case we
return the default value for the respective type and log a warning\footnote{This
is specialized functionality in the cooling language; in most other languages,
we would probably just return \icsn{null}, since nothing seems to have been
assigned to the symbol yet}. Otherwise we return the value.


\begin{lstlisting}[language=java]
protected Object evalSymbolRef(SymbolRef expr, LogEntry log) {
    SymbolDeclaration s = expr.getSymbol();
    Object val = eec().environment.get(s);
    if (val == null) {
        EObject type = eec().typesystem.typeof(expr, new TypeCalculationTrace());
        Object neutral = intDoubleNeutralValue(type);
        log.child(Kind.debug, expr, 
           "looking up value; nothing found, using neutral value: " + neutral);
        return neutral;
    } else {
        log.child(Kind.debug, expr, "looking up value: " + val);
        return val;
    }
}
\end{lstlisting}


\noindent 
The cooling language does not support function calls, so we demonstrate function
calls with a similar language that supports them. In that language, function
calls are expressed as symbol references that have argument lists. Below is the
grammar. Constraints make sure that argument lists are only used if the
referenced symbol is actually a \ic{FunctionDeclaration}.


\begin{lstlisting}[language=xtextgrammar]
FunctionDeclaration returns Symbol:
    {FunctionDeclaration} "function" type=Type name=ID "(" 
        (params+=Parameter  ("," params+=Parameter)* )?  ")" "{"    
        (statements+=Statement)*
    "}";    

Atomic returns Expression:
    ...
    {SymbolRef} symbol=[Symbol|QID]  
        ("(" (actuals+=Expr)? ("," actuals+=Expr)* ")")?; 
\end{lstlisting}


\noindent 
The following is the code for the evaluation function for the symbol reference.
It must distinguish between references to variables and to
functions\footnote{This is once again a consequence of the fact that all
references to any symbol are handled via the \icsn{SymbolRef} class. We have
discussed this in \todoref{}.}.


\begin{lstlisting}[language=java]
protected Object evalSymbolRef(SymbolRef expr, LogEntry log) {
    Symbol symbol = expr.getSymbol();
    if ( symbol instanceof VarDecl ) {
        return log( symbol, eec().environment.getCheckNull(symbol), log);
    }
    if ( symbol instanceof FunctionDeclaration ) {
        FunctionDeclaration fd = (FunctionDeclaration) symbol;
        return callAndReturnWithPositionalArgs("calling "+fd.getName(), 
                fd.getParams(), expr.getActuals(), fd.getElements(), 
                RETURN_SYMBOL, log);
    }
    throw new InterpreterException(expr, 
        "interpreter failed; cannot resolve symbol reference " 
        +expr.eClass().getName()); }
\end{lstlisting}


\noindent 
The code for handling the \ic{FunctionDeclaration} uses a predefined utility
method \ic{callAndReturnWithPositionalArgs}. It accepts as arguments the list of
formal arguments of the called function, the list of actual arguments
(expressions) passed in at the call site, the list of statements in the function
body, a symbol that should be used for the return value in the environment as
well as the obligatory log. The utility method is implemented as follows:


\begin{lstlisting}[language=java]
protected Object callAndReturnWithPositionalArgs(String name, 
        EList<? extends EObject> formals, EList<? extends EObject> actuals, 
        EList<? extends EObject> bodyStatements) {
    eec().environment.push(name);
    for( int i=0; i<actuals.size(); i++ ) {
        EObject actual = actuals.get(i);
        EObject formal = formals.get(i);
        eec().environment.put(formal, evalCheckNullLog(actual, log));
    }
    eec().getExecutor().execute( bodyStatements, log );
    Object res = eec().environment.get(RETURN_SYMBOL);
    eec().environment.pop();
    return res;
}
\end{lstlisting}


\noindent 
Remember from the above discussion about environments and function calls, that
each invocation of a function has to get its own environment to handle the local
variables for the particular invocation. We can see this in the first line of
the implementation above: we first create a new environment and push it onto
the call stack. Then the implementation iterates over the actual arguments,
evaluates each of them and "assigns" them to the formals by creating an
association between the formal argument symbol and the actual argument value in
the new environment. It then uses the \ic{StatementExecutor} to execute all the
statements in the body of the function. Notice that as the executed function
deals with its own variables and function calls, it uses the \emph{new}
environment created, pushed onto the stack and populated by this method! When
the execution of the body has finished, we retrieve the return value from the
environment. The \ic{return} statement in the function has put it there under a
name we have prescribed, the \ic{RETURN\_SYMBOL}, so we know how to find it in
the environment. Finally, we pop the environment, restoring the caller's state of
the world and return the return value as the resulting value of the thefunction call expression.


\parhead{States, Events and the Main program} Changing a state (state as in
state machine, not as in program state) from within a cooling program is done by
executing a \ic{ChangeStateStatement}, which simply references the state that
should be entered. Here is the interpreter code in \ic{StatementExecutor}:


\begin{lstlisting}[language=java]
protected void executeChangeStateStatement(ChangeStateStatement s, LogEntry l) {
    engine.enterState(s.getTargetState(), log);
}

public void enterState(State targetState, LogEntry logger ) 
        throws TestFailedException, InterpreterException, TestStoppedException {
    logger.child(Kind.info, targetState, "entering state "+targetState.getName());
    context.currentState = targetState;
    executor.execute(ss.getEntryStatements(), logger);
    throw new NewStateEntered();
}
\end{lstlisting}


\noindent 
\ic{executeChangeStateStatement} calls back to an engine method that handles the
state change (since this is a more global operation than executing statements,
it is handled by the engine class itself). The method simply sets the current
state to the target state passed into the method (the current state is kept
track of in the execution context). It then executes the set of entry statements
of the new state. After this it throws an exception \ic{NewStateEntered} which
stops the current execution step. The overall engine is step driven, i.e.~an
external "timer" triggers distinct execution steps of the engine. A state change
always terminates the current step. The main method \ic{step()} triggered by the
external timer can be considered the main program of the interpreter. It looks
as follows:

\begin{lstlisting}[language=java]
public int step(LogEntry logger) {
    try {
        context.currentStep++;
        executor.execute(getCurrentState().getEachTimeStatements(), stepLogger);
        executeAsyncStuff(logger);
        if ( !context.eventQueue.isEmpty() ) {
            CustomEvent event = context.eventQueue.remove(0);
            LogEntry evLog = logger.child(Kind.info, null, 
                "processing event from queue: "+event.getName());
            processEventFromQueue( event, evLog );
            return context.currentStep;
        }
        processSignalHandlers(stepLogger);
    } catch ( NewStateEntered se ) {
    }
    return context.currentStep;
}
\end{lstlisting}

\noindent 
It first increments a counter that keeps track of how many steps haven been
executed since the interpreter had been started up. It then executes the
\ic{each time} statements of the current state. This is a statement list defined
by a state that needs to be re-executed in each step while the system is in the
respective state. It then executes asynchronous tasks. We'll explain those
below. Next it checks if an event is in the event queue. If so, it removes the
first event from the queue and executes it. After processing an event the step
is always terminated. Lastly, if there was no event to be processed, we process
signal handlers (the \ic{check} statements in the cooling programs).

Processing events simply checks if the current state declares an event handler
that can deal with the currently processed event. If so, it executes the
statement list associated with this event handler.


\begin{lstlisting}[language=java]
private void processEventFromQueue(CustomEvent event, LogEntry logger) {
    for ( EventHandler eh: getCurrentState().getEventHandlers()) {
        if ( reactsOn( eh, event ) ) {
            executor.execute(eh.getStatements(), logger);
        }
    }
}
\end{lstlisting}


\noindent 
The DSL also supports executing code asynchronously, i.e.~after a specified
number of steps (representing logical program time). The grammar looks as
follows:

\begin{lstlisting}[language=xtextgrammar]
PerformAsyncStatement:
    "perform" "after" time=Expr "{"
        (statements+=Statement)*
    "}";
\end{lstlisting}


\noindent 
The following method interprets the \ic{PerformAsyncStatement}s:


\begin{lstlisting}[language=java]
protected void executePerformAsyncStatement(PerformAsyncStatement s, 
                LogEntry log) throws InterpreterException {
    int inSteps = ((Integer)evalCheckNullLog(s.getTime(), log)).intValue();
    eec().asyncElements.add(new AsyncPerform(eec().currentStep + inSteps, 
        "perform async", s, s.getStatements()));
}
\end{lstlisting}


\noindent 
It registers the statement list associated with the \ic{PerformAsyncStatement} in the
list of async elements in the execution context. The call to \ic{executeAsyncStuff}
at the beginning of the \ic{step} method described above checks whether the time has
come and executes those statements:


\begin{lstlisting}[language=java]
private void executeAsyncStuff(LogEntry logger) {
    List<AsyncElement> stuffToRun = new ArrayList<AsyncElement>();
    for (AsyncElement e: context.asyncElements) {
        if ( e.executeNow(context.currentStep) ) {
            stuffToRun.add(e);
        }
    }
    for (AsyncElement e : stuffToRun) {
        context.asyncElements.remove(e);
        e.execute(context, logger.child(Kind.info, null, "Async "+e));
    }
}
\end{lstlisting}


\todo{Talk a little bit about Xtend for building interpeters using
extension methods and the cool switch statement}



\section{An interpreter in MPS}
\label{mpsinterpreter}

Building an interpreter in MPS is essentially similar to building an interpreter
in Xtext and EMF. All concept would apply in the same way, instead of
\ic{EObjects} you would work with the \ic{node<>} types that are available on
MPS to deal with ASTs. However, since MPS' BaseLanguage is itself built with
MPS, it can be extended. So instead of using a generator to generate the
dispatcher that calls the \ic{eval} methods for the expression classes, suitable
modular language extensions can be defined in the first place.
 
For example, BaseLanguage could be extended with support for polymorphic
dispatch (similar to what Xtend does). An alternative solution involves a
dispatch expression, a kind of "pimped switch". \fig{mps-dispatch} shows an
example.

\begin{figure}[ht]
\fbox{
\begin{minipage}{105mm}
  \includegraphics[width=\columnwidth]{figures-impl/5/mps-dispatch.png}
\end{minipage}
}
  \caption[][4cm]{An extension to MPS' BaseLanguage that makes writing
  interpreters simpler. The \icsn{dispatch} statement has the neat feature that,
  on the right side of the \icsn{->}, the \icsn{\$} reference to the \icsn{ex}
  expression is already downcast to the type mentioned on the left of the
  \icsn{->}.}
  \label{mps-dispatch} 
\end{figure}

\noindent 
The dispatch expression tests if the argument \ic{ex} is an instance of the
type referenced in the cases. If so, the code on the right side of the arrow is
executed. Notice the special expression \ic{\$} used on the right side of the
arrow. It refers to the argument \ic{ex}, but it is already downcast to the type
on the left of the case's arrow. This way, annoying downcasts can be avoided.

Note that this extension is modular in the sense that the definition of
BaseLanguage was not changed. Instead, an additional language module was defined
that \emph{extends} BaseLanguage. This module can be used as part of the program
that contains the interpreter, making the \ic{dispatch} statement available
there\footnote{We discuss language modularization and composition is
\todoref{}.}. Also, the \ic{\$} expression is restricted to only be usable on
the right side of the \ic{->}. This way the overall base language namespace is kept
clean.

Since MPS is a projectional editor, it can show things in the editor that are
read-only. For example, the result of an interpreter run can be integrated
directly into the editor. \todo{Show the insurance example thingy, and also
show how it is actually called.}


\section{An Interpreter in Spoofax}

State-based interpreters can be specified with rewrite rules in Spoofax,
realising transitions between execution states. This requires:
\begin{itemize}

  \item A representation of \emph{states}. The simplest way to represent 
  states are terms, but we can also define a new DSL for representing the 
  states in concrete syntax.

  \item An \emph{initialisation transformation} from a program in the DSL to 
  the initial state of the interpreter.

  \item A \emph{step transformation} from an actual state of the interpreter 
  to the next state of the interpreter.

\end{itemize}

\noindent In the remainder of the section, we develop an interpreter for a
subset of Mobl.
We start with a simple interpreter for expressions, which we then extend to
handle statements.

\subsection{An Interpreter for Expressions}

If we want to evaluate simple arithmetic expressions without variables, the
expression itself is the state of the interpreter\footnote{Remember how in the
design chapter we discussed building debuggers for purely functional languages,
and in particular, expression languages. We argues that a debugger is trivial,
because there is no real "flow" of the program; instead, the expression can be
debugged by simply showing the values of all intermediate expressions in a
tree-like for. We exploit the same "flowless" nature of pure expression
languages when building this interpreter.}. Thus, no extra term signatures are
needed and the initialisation transformation is given by identity. For the step
transformation, we can define rewrite rules for the different expression kinds:

\begin{lstlisting}[language=stratego]
eval: Add(Int(x), Int(y)) -> Int(z) where z := <add> (x, y)
eval: Mul(Int(x), Int(y)) -> Int(z) where z := <mul> (x, y)

eval: Not(True())  -> False()
eval: Not(False()) -> True()

eval: And(True(), True())   -> True()
eval: And(True(), False())  -> False()
eval: And(False(), True())  -> False()
eval: And(False(), False()) -> False()

eval: LazyAnd(True(), True()) -> True()
eval: LazyAnd(False(), _)     -> False()
eval: LazyAnd(_, False(), _)  -> False()
\end{lstlisting}

\noindent We can orchestrate these rules in two different styles. For a
small-step interpreter, we only apply one rule in each step:
\guido{the distinction in purpose between small-step and big-step interpreters
is not clear in this section}

\begin{lstlisting}[language=stratego]
eval-one: exp -> <oncebu(eval)> exp
\end{lstlisting}

\noindent Here, \ic{oncebu} tries to apply \ic{eval} at one position in the
tree, starting from the leaves. The \ic{bu} in \ic{oncebu} stands for bottom-up.
We could also use \ic{oncetd}, traversing the tree top-down. However,
evaluations are likely to happen at the bottom of the tree, why \ic{oncebu} is
the better choice. The result of \ic{eval-one} will be a slightly simpler
expression, which might need further evaluation.

In contrast, we can directly apply as many rules as possible, trying to evaluate
the whole expression. This will give us a big-step interpreter:

\begin{lstlisting}[language=stratego]
eval-all: exp -> <bottomup(try(eval))> exp
\end{lstlisting}

Here, \ic{bottomup} tries to apply \ic{eval} at every node, starting at the leaves.
The result of \ic{eval-all} will be the final result of the expression.

\subsection{An Interpreter for Statements}

If we want to evaluate statements, we need states which capture the value of
variables and the list of statements which needs to be evaluated. We can define
these states with a signature for terms:

\begin{lstlisting}[language=sdf]
signature constructors

     : ID * IntValue  -> VarValue
     : ID * BoolValue -> VarValue

State: List(VarValue) * List(Statement) -> State
\end{lstlisting}

\noindent The first two rules define binary tuples which combine a variable name
(\ic{ID}) and a value (either \ic{IntValue} or \ic{BoolValue}). The last rule
defines a binary constructor \ic{State} which combines a list of variable values
with a list of statements. We first have to adapt the evaluation of expressions
to handle variable references in expressions.
\begin{lstlisting}[language=stratego]
eval(|varvals): exp -> <eval> exp
eval(|varvals): VarRef(var) -> <lookup> (var, varvals)
    
eval-one(|s): exp -> <oncebu(eval(|s))> exp
eval-all(|s): exp -> <bottomup(try(eval(|s)))> exp  
\end{lstlisting}

\noindent The first two rules take the actual list of variable values of the
interpreter (\ic{varvals}) as a parameter. The first rule integrates the old
evaluation rules, which do not need any state information. The second rule looks
up the current value \ic{val} of the variable \ic{var} in the list of variable
values. The last two rules define small-step and big-step interpreters of
expressions, just as before.

We can now define evaluation rules for statements. These rules rewrite the
current state into a new state:

\begin{lstlisting}[language=stratego]
eval: 
  (varvals, [Init(type, var, exp)|stmts]) -> (varvals', stmts)
  where
    val      := <eval-all(|varvals)> exp;
    varvals' := <update> ((var, val), varvals)
    
eval: 
  (varvals, [Assign(VarRef(var), exp)|stmts]) -> (varvals', stmts)
  where
    val      := <eval-all(|varvals)> exp;
    varvals' := <update> ((var, val), varvals)
    
eval:
  (varval, [Block(stmts1)|stmts2]) -> (varvals, <conc> (stmts1, stmts2))
\end{lstlisting}

\noindent The first rule handles variable declarations. It evaluates the
expression on the right-hand side to a value, updates the list of variable
values and removes the statement from the list of statements. The second rule
handling assignments is quite similar. The third rule handles block statements,
by concatenating the statements from a block with the remaining statements.The following rule handle an \ic{if} statement:

\begin{lstlisting}[language=stratego]
eval:
  (varvals, [If(exp, then, else)|stmts]) -> (varvals, [stmt|stmts])
  where
    val := <eval-all(|varvals)> exp;
    if !val => True() then
      stmt := then
    else 
      !val => False();
      stmt := else
    end
\end{lstlisting}

\noindent First, it evaluates the condition. Dependent of the result, it chooses
the next statement to evaluate. When the result is \ic{True()}, the statement
from the \ic{then} branch is chosen. Otherwise the result has to be \ic{False()} and
the statement from the \ic{else} branch is chosen. If the result is neither
\ic{True()} nor \ic{False()}, the rule will fail. The following rule handles
\ic{while} loops:

\begin{lstlisting}[language=stratego]
eval:
  (varvals, [While(exp, body)|stmts]) -> (varvals, stmts')
  where
    val := <eval-all(|varvals)> exp;
    if !val => True() then
      stmts' := [body, While(exp, body)|stmts]
    else 
      !val => False();
      stmts' := stmts
    end
\end{lstlisting}

\noindent Again, the condition is evaluated first. If it evaluates to
\ic{True()}, the list of statements is updated to the body of the loop, the
\ic{while} loop again, followed by the remaining statements. If it evaluates to
\ic{False()}, only the remaining statements need to be evaluated.

The \ic{eval} rules define already a small-step interpreter, going from one
evaluation state to the next. We can define a big-step interpreter by adding a
driver, which repeats the evaluation until it reaches a final state:

\begin{lstlisting}[language=stratego]
eval-all: state -> <repeat(eval)> state
\end{lstlisting}


\subsection{More Advanced Interpreters}

We can extend the interpreter to handle function calls and objects in a similar
way we did for statements. First, we always have to think about the states of
the extended interpreter. Functions will require a call stack, objects will
require a heap. Next, we need to consider how the old rules can deal with the
new states. Adjustments might be needed. For example, when we support objects,
the heap needs to be passed to expressions. Expressions which create objects
will change the heap, so we cannot only pass it, but have to propagate the
changes back to the caller.

\subsection{IDE Integration}

We can integrate interpreters as builders into the IDE. For big-step
interpreters, we can simply calculate the overall execution result and show it
to the user. For small-step interpreters, we can use the initialisation
transformation in the builder. This will create an initial state for the
interpreter. When we define a concrete syntax for these states, they can be
shown in an editor. The transition transformation can then be integrated as a
refactoring on states, changing the current state to the next one. This way, the
user can control the execution, undo steps, or even modify the current state.
\todo{This last paragraph, and especially the last part of it hints at how to
build a debugger, right? So maybe we can discuss some of this in the debugging
chapter.}
