\chapter{DSLs and Product Lines}

\chapterabstract{This chapter discusses the role of DSLs in Product Line
Engineering (PLE). We first briefly introduce PLE and feature models and
discuss how feature models can be connected to programs expressed in DSLs. We
then explain the difference in expressivity between feature models and DSLs and
argue why sometimes features models are not enough to express the variability
in a product line, and how DSLs can help. The chapter concludes with a couple
of examples as well as a conceptual mapping of the concepts relevant to PLE and
DSLs.}

\section{Introduction}

The goal of product line engineering (PLE) is to efficiently manage a range of
products by factoring out commonalities such that definitions of products can be
reduced to a specification of their variable aspects\footnote{PLE also involves
a lot product management, process and organizational aspects. We do not cover
them in this book.}. One way of achieving this is the expression of product
configurations on a higher level of abstraction than the actual
implementation\footnote{This higher level of abstraction is often called the
problem space, the lower level is often called the solution space or
implementation space.}. An automated mapping transforms the configuration to the
implementation.  


\section{Feature Models}

In PLE, this this higher level of abstraction is typically realized with feature
models. Feature models express configuration options and the constraints among
them. A graphical notation, called feature diagrams, is often used to represent
feature models (\fig{examplefm} shows an example). If a product line's
variability were just expressed by a set of Boolean options, the configuration
space would grow with $2^n$, with $n$ representing the number of options. With
feature models, constraints are expressed regarding the combinations of
features, limiting the set of valid configurations to a more manageable size.
Constraints include:

\begin{itemize}
  \item \textbf{mandatory} (filled circles): mandatory features have to be in
  each product. For example, in \fig{examplefm}, each \ic{Stack} has to have
  the feature \ic{ElementType}.
  \vspace{-2mm}
  \item \textbf{optional} (empty circles): optional features may or may not
  be in a product. \ic{Counter} and \ic{Optimization}
  are examples of optional features.
  \vspace{-2mm}
  \item \textbf{or} (filled arc): a product may include zero, one or
  any number of the features in an \ic{or} group. In the example, a product
  may include any number of features from \ic{ThreadSafety}, \ic{BoundsCheck}
  and \ic{TypeCheck}.
  \vspace{-2mm}
  \item \textbf{xor} (empty arc): a product must include exactly
  one of the features grouped into a \ic{xor} group. The \ic{ElementType}
  must either be \ic{int}, \ic{float}, or \ic{String}.
\end{itemize}

\noindent Additionally, non-hierarchical constraints can be expressed as well.
For example, a feature can declare \ic{conflicts with} and a \ic{requires also}
constraints relative to arbitrary other features.


\begin{figure}[h]
\centering
  \includegraphics[width=110mm]{figures/ple/examplefm.png}
\caption{An example feature diagram for a product line of \ic{Stack} data
structures. Filled circles represent mandatory features, empty circles
represent optional features. Filled arcs represent n-of-m selection and empty
arcs represent 1-of-m.}
\label{examplefm}
\end{figure}  

A \emph{configuration} represents a product in the product line. It comprises a
set of feature selections from a feature model that comply with the constraints
expressed in the feature model. For example, the configuration
\ic{Optimization}, \ic{Memory Use}, \ic{Additional Features}, \ic{Type Check},
\ic{Element Type}, \ic{int}, \ic{Size}, \ic{Dynamic} would be valid. A
configuration that includes \ic{Speed} and \ic{Memory Usage} would be invalid
because it violates the \ic{xor} constraint between those two features expressed
in the feature model.

Note that a feature model does not yet describe the \emph{implementation} of a
product or the product line. The feature model has to be connected to
implementation artifacts.


\section{Connecting Feature Models to Artifacts}

By definition, feature models express product line variability at a level that
is more abstract than the implementation. In many systems, the implementation of
variability is scattered over (parts of) many implementation artifacts.
However, to result in a correct system, several variation points (VP) may need
to be configured in a consistent, mutually dependend way. If each VP has to be
configured separately, the overall complexity grows quickly. By identifying
logical variation points and factoring them into feature in a feature model, and
then tying the (potentially many) implementation variation points to these
logical variation points, related implementation variations can be tied together
and managed as one (\fig{externalDescriptionOfVariability}).

\begin{figure}[h]
\begin{center}
  \includegraphics[width=60mm]{figures/ple/externalDescriptionOfVariability.png}
  \caption{The Artifact Level represents realization artifacts such as models,
code or documentation. The Logical Level is the external description of
variation points and the conceptual constraints among them, typically a feature
model. One or more VPs in the implementation level
are associated with variation points in the logical level (n:1, n:m).}
\end{center}
\label{externalDescriptionOfVariability}
\end{figure}


If DSLs are used, then the artifacts configured from the feature model are
typically DSL programs, the variation points are program elements. By using DSL
models instead of low-level implementation code, the number of variation points
in the artifacts will be reduced because you then use the DSL-to-code
transformation to expand all the details in a consistent way. The trade-off is
that you have to define this high-level domain specific language,
including a way to define variants of programs written in that language. You
also need to define the transformation down to the actual implementation
artifacts (\fig{modelBasedImpl}).


 
\begin{figure}[h]
\begin{center}
  \includegraphics[width=60mm]{figures/ple/modelBasedImpl.png}
  \caption{A model describes domain abstractions in a formal and concise way.
Transformations map that model to (typically more than one) implementation
artifact. Variability is expressed with fewer VPs in the models compared to
implementation artifacts.}
\end{center}
\label{modelBasedImpl}
\end{figure}  



The configuration of models (and other artifacts) can be done in several
different ways: removal, injection and parametrization.


\begin{marginfigure}[-15mm]
  \includegraphics[width=50mm]{figures/ple/strategy-Removal.png}
  \caption{Removal represents negative varibility in that it takes optional
  things (small squares) away from a comprehensive whole, based on the
  configuration \ic{a,b,c}. The optional parts are annotated with presence
  conditions referring to the configuration features.}
\label{strategy-Removal} 
\end{marginfigure} 
\parhead{Removal} (also known as Negative Variability) In this approach, the
mapping from a feature model to implementaton artifacts remove parts of a 
comprehensive whole
(\fig{strategy-Removal}). This implies marking up the various optional parts of 
the comprehensive whole with boolean expressions that determine when to
remove the part. These expressions are called presence conditions. The biggest
advantage of this approach is its apparent simplicity. However, the comprehensive 
whole has to contain the parts for \emph{all}
variants (maybe even parts for combinations of variants), making it potentially
large and complex. Also, depending on the tool support, the comprehensive whole
might not be a valid instance of the underlying language or formalism. For
example, in an IDE, the respective artefact might show errors which makes this
approach annoying at times.

\ic{ifdefs} in C and C++ are a well-known implementation of this strategy. A
preprocessor removes all code regions, whose \ic{ifdef} condition evaluates to
false. When calling the compiler/preprocessor, you have to provide a number of
symbols that are evaluated as part of the conditions. Conditional compilation
can also be found in other languages. Preprocessors that treat the source code
simply as text are available for many languages and are part of many PLE tool
suites. The AUTOSAR \todo{ref} standard, as well as other modeling formalisms,
support the annotation of model elements with presence conditions.
The model element (and all its children) are removed from the model
if the condition evaluates to false.


\begin{marginfigure}[-46mm]
  \includegraphics[width=50mm]{figures/ple/strategy-Injection.png}
  \caption{A minimal base artifact made of various parts (the small rectangles)
  exists. There is also variant specific code (the strange shapes), connected to features
  external to the actual artifact and pointing to the parts of the artifact to
  which they can be attached. Implementing a variant means that the variant 
  specific code associated with the selected features are injected into the 
  base artifact, attached to the parts they designate.}
\label{strategy-Injection}  
\end{marginfigure} 
\parhead{Injection} (also known as Positive Variability) In this approach,
additions are defined relative to a minimal core (\fig{strategy-Injection}).
The core does not know about the variability, the additions point to the place 
where they need to be added. The clear advantage of this
approach is that the core is typically small and contains only what is common
for all products. The parts specific to a variant are kept external and added to
the core only when necessary. To be able to do this, however, there must be a
way to refer to the location in the minimal core at which to add a variable
part. This either requires the markup of hotspots or hooks in the minimal core
or some way of pointing into the core from an external source. Also,
interactions between the additions for various features may also be hard to
manage.

AOP is a way of implementing this strategy. Pointcuts are a way of selecting
from a set of join points in the base asset. A joint point is an addressable
location in the core. Instead of explicitly defining hooks, all instances of a
specific language construct are automatically addressable. Various preprocessors
can also be used in this way. However, they typically require the explicit
markup of hooks in the minimal core. For models, injection is especially simple
since in most formalisms model elements are addressable by default. So it is
possible to point to a model element, and add additional model elements to it,
as long as the result is still a valid instance of the meta model.

 


\begin{marginfigure}[45mm]
  \includegraphics[width=50mm]{figures/ple/strategy-Parameters.png} \caption{An
  artifact defines a number of (typed) parameters.
  A variant provides values for the parameters.}
\label{strategy-Parameters} 
\end{marginfigure} 
\parhead{Parameterization} The artifact that shall be varied has to define
parameters. A variant is constructed by providing values for those parameters
(\fig{strategy-Parameters}). The parameters are usually typed to restrict the
range of valid values. In most cases, the values for the parameters are
relatively simple, such as strings, integers, booleans or regular expressions.
However, in principle, they can be arbitrarily complex. The artifact that shall
be parameterized needs to explicitly define the parameters, as well as a way to
specify values. The artifact has to query the values of those parameters
explicitly and use them for whatever it does. The approach requires the core to
be explicitly aware and define all parameters.

A configuration file that is read out by the an application is a form of
parameterization. The names of the parameters are predefined by the application,
and when defining a variant, a set of values is supplied. The strategy pattern
is a form of parameterization, especially in combination with a factory. A
variant is created by supplying an implementation of an interface defined by the
configurable application. All kinds of other small, simple, or domain specific
languages can be used as a form of parameterization. A macro language in an
application is a form of parameterization. That type of parameter is "valid
program written in language X"\footnote{There is an obvious connection to DSLs
--- a DSL can be used here.}.


\subsection{A real world example}

In mbeddr we use a textual notation for feature models, since support for
graphical syntax in MPS will become available only in 2013. \fig{fminmbeddr}
shows this notation. Note how the constraint affects all children of a feature,
so we had to introduce the intermediate feature \ic{options} to separate
mandatory features from optional features. Features can also have configuration
attributes (of any type).

\begin{figure}[h]
\centering
  \includegraphics[width=70mm]{figures/ple/fminmbeddr.png}
\caption{An example feature model in mbeddr. Until MPS will provide support for
graphical notations (planned for 2013), we use a textual notation.}
\label{fminmbeddr}
\end{figure}


A configuration is a named set of selections from the features in a feature
model. The selection has to be valid regarding the constraints defined in the
feature model. \fig{twoconfigs} shows two example configurations. If an invalid
configuration is created, errors will be shown in the configuration model.
 

\begin{figure}[h]
\begin{center} 
  \includegraphics[width=110mm]{figures/ple/twoconfigs.png}
\end{center}
\caption{Two valid configurations of the feature model.}
\label{twoconfigs}
\end{figure}



Presence conditions can be attached to any program element\footnote{...
expressed in any language, without this language having to know about it.
Thanks to MPS' annotations (discussed in \todo{ref}).}.
For example the two \ic{report} statements and the message list in the left program in
\fig{projection} are only part of a product if the \ic{logging} feature is
selected in the product configuration. The background color of an annotated node
is computed from the expression: annotated nodes using the same expression have
the same color (an idea borrowed from Christian Kaestner's CIDE
\cite{Kastner07b}).

Note that the fact that you can make arbitrarily detailed program elements
depend on features is not meant to imply that no further structuring of the
product line is necessary, and all variability should be expressed via
fine-grained presence conditions. Instead, presence conditions should be used to
configure more coarse grained entities such as the instantiation and wiring of
components.

It is possible to edit the program as a
product line (with the annotations), undecorated (without annotations) as well
as a specific product. \fig{projection} shows an example. During
transformation, those parts of programs that are not in the product are removed
from the model. 

\begin{figure}[h] 
\begin{center} 
  \includegraphics[width=118mm]{figures/ple/projection.png}
\end{center} 
\caption{\textbf{Left:} A C program with product line annotations.
\textbf{Right:} The program rendered in in the \ic{Production} variant.}
\label{projection} 
\end{figure}


\vspace{-10mm}

\section{From Feature Models to DSLs}
\label{sec:featureModelsVsDSLs}

A feature model is a compact representation of the features of the products in a
product line, as well as the constraints imposed on configurations. Feature
models are an efficient formalism for \emph{configuration}, i.e. for
\emph{selecting} a valid combination of features from the feature model. The set
of products that can be defined by feature selection is fixed and finite: each
valid combination of selected features constitutes a product. This means that
all valid products have to be "designed into" the feature model, encoded in the
features and the constraints among them. Some typical examples of variation
points that can be modeled with feature models are the following:

\begin{itemize}
  \item Does the communication system support encryption?
  \item Should the in-car entertainment system support MP3s?
  \item Should the system be optimized for performance or memory footprint?
  \item Should messages be queued? What is the queue size?
\end{itemize}

Feature models provide an abstraction over the implementation of the product.
Based on the feature configuration, mappings derive the necessary adaptations of
the underlying implementation artifacts. Because of this abstraction, feature
model-based configuration is simple to use --- product definition is basically a
decision tree. This makes product configuration efficient, and potentially
accessible for stakeholders other than software developers.



As described by Batory \cite{Batory05} and Czarnecki \cite{CzarneckiW07}, a
particular advantage of feature models is that a mapping to logic exists. Using
SAT solvers, it is possible to check, for example, whether a feature model has
valid configurations at all. The technique can also be used to automatically
complete partial configurations. 


In the rest of this section we will discuss the limitations of feature models.
We argue that in cases in which feature models are unsuitable, we should not
regress to low-level programming, but use DSLs instead, to avoid losing the
differentiation between problem space and solution space.  As an example we use
a product line of water fountains as found in recreational parks\footnote{This
is an anonymized version of an actual project the authors have been working on.
The real domain was different, but the example languages presented in this paper
have been developed and used for that other domain.}. Fountains can have several
basins, pumps and nozzles. Software is used to program the behavior of the pumps
and valves to make the sprinkling waters aesthetically pleasing. The feature
model in \fig{exfm} represents valid hardware combinations for a simple water
fountain product line. The features correspond to the presence of a hardware
component in a particular fountain installation.


\begin{figure}[htp]
\begin{center}
  \includegraphics[scale=0.7]{figures/ple/exfeaturemodel.png}
  \caption[labelInTOC]{Feature model for the simple fountains product line used
  as the example. Fountains have basins, with one or two nozzles, and an
  optional full sensor. In addition, fountains have a pump. }
  \label{exfm} 
\end{center} 
\end{figure}
  
 
The real selling point of water fountains is their \emph{behavior}. A fountain's
behavior determines how much water each pump should pump, at which time, with
what power, or how a pump reacts when a certain condition is met, e.g. a basin
is full. Expressing the full range of such behaviors is not possible with
feature models. Feature models can be used to select among a fixed number of
predefined behaviors, but approximating all possible behaviors would lead to
unwieldy feature models. Instead we could program the behavior in a general
purpose language such as~C. However, this means that we lose the abstraction
feature models provide, reducing efficiency and understandability, as well as
the possibility for direct involvement of non-programmers. Domain-specific
languages can serve as a middle ground between the controlled setting of 
feature model-based configuration and the complete lack of restrictions of 
general purpose programming languages. 
 

\subsection{Feature Models as Grammars}

To understand the limitations of feature models, consider their relation to
grammars. Feature models essentially correspond to context-free grammars without
recursion~\cite{CzarneckiHE05}. For example, the feature model in \fig{exfm} is
equivalent to the following grammar. We use all caps to represent terminals, and
camel-case identifiers as non-terminals:

\begin{code}
Fountain -> Basin PUMP
Basin -> ISFULLSENSOR? (ONENOZZLE | TWONOZZLES)
\end{code}


\noindent This grammar generates a finite number of sentences, i.e there are
exactly four possible configurations, which correspond to the finite number of
products in the product line. However, this formalism does not make sense for
modeling behavior, for which there is typically an infinite range of variability. To
accommodate for unbounded variability, the formalism needs to be extended.
Allowing recursive grammar productions is sufficient to model unbounded
configuration spaces, but for convenience, we consider also attributes and
references.



\emph{Attributes} express properties of features. For example, the \ic{PUMP}
could have an integer attribute \ic{rpm}, representing the power setting of
the pump. Some feature modeling tools (e.g. pure::variants) support attributes.

\begin{code}
Fountain -> Basin PUMP(rpm:int)
Basin -> ISFULLSENSOR? (ONENOZZLE | TWONOZZLES)
\end{code}


\emph{Recursive} grammars can be used to model repetition and nesting.
Repetition is also supported by cardinality-based feature models, as described
in \cite{CzarneckiHE05}. Nesting is necessary to model tree structures such as
those occurring in expressions. The following grammar extends the fountain
feature model with a \ic{Behavior}, which consists of a number of
\ic{Rules}. The \ic{Basin} can now have any number of \ic{Nozzles}.

\begin{code}
  Fountain -> Basin PUMP(rpm:int) Behavior
  Basin -> ISFULLSENSOR? NOZZLE*
  Behavior -> Rule*
  Rule -> CONDITION CONSEQUENCE
\end{code}


\emph{References} allow the creation of context-sensitive relations
between parts of generated sentences --- or subtrees of the generated
derivation trees. For example, by further extending our fountain grammar
we can describe a rule whose condition refers to the \ic{full} attribute of
the \ic{ISFULLSENSOR} and whose consequence sets a \ic{PUMP}'s
\ic{rpm} to 0.


\begin{code} 
  Fountain -> Basin id:PUMP(rpm:int)? Behavior
  Basin -> id:ISFULLSENSOR(full:boolean)? id:NOZZLE*
  Behavior -> Rule*

  Rule -> Condition Consequence
  Condition -> Expression
  Expression -> ATTRREFEXPRESSION | AndExpression | 
               GreaterThanExpression | INTLITERAL;

  AndExpression -> Expression Expression
  GreaterThanExpression -> Expression Expression

  Consequence -> ATTRREFEXPRESSION Expression
\end{code}



\begin{figure}[t]
\begin{center}
  \includegraphics[scale=0.6]{figures/ple/exfeaturemodel_extended.png}
  \caption[labelInTOC]{An extended feature modeling formalism is used to
  represent the example feature model with attributes, recursion and and
  references (the dotted boxes).}   
  \label{exfm-extended}
\end{center}
\end{figure}
 

\fig{exfm-extended} shows a possible rendering of the grammar with an
enhanced feature modeling notation. We use cardinalities, as well as references
to existing features, the latter are shown as dotted boxes. A valid
configuration could be the one shown in \fig{exfm-extended-inst}. It shows a fountain with one basin,
two nozzles named \ic{n1} and \ic{n2}, one sensor \ic{s} and a pump
\ic{p}. It contains a rule that expresses that if the \ic{full}
attribute of \ic{s} is set, and the \ic{rpm} of pump \ic{p} is
greater than zero, then the \ic{rpm} should be set to zero.
 


\begin{figure}[htp]  
\begin{center}
  \includegraphics[scale=0.6]{figures/ple/exfeaturemodel_extended_inst.png}
  \caption[labelInTOC]{Example configuration using a tree
  notation. Referenceable identities are rendered as
  labels left of the box. The dotted lines represent references to variables.}
  \label{exfm-extended-inst}
\end{center}
\end{figure}


\subsection{Domain-Specific Languages}

While the extended grammar formalism discussed above enables us to cover the
full range of behavior variability, the use of trees to instantiate these
grammars is not practical. Another interpretation of these grammars is as
definition of a \emph{language} with a \emph{textual concrete syntax} --- the
tree in \fig{exfm-extended-inst} looks like an abstract tree (AST). 
To make the language readable we need to add concrete syntax
definitions (keywords), as in the following extension of the fountain grammar:



\begin{code} 
  Fountain -> "fountain" Basin Pump Behavior
  Basin -> "basin" IsFullSensor Nozzle*
  Behavior -> Rule*

  Rule -> "if" Condition "then" Consequence
  Condition -> Expression
  Expression -> AttrRefExpression | AndExpression | 
               GreaterThanExpression | IntLiteral;

  AndExpression -> Expression "&&" Expression
  GreaterThanExpression -> Expression ">" Expression
  AttrRefExpression -> <attribute-ref-by-name> 
  IntLiteral -> (0..9)*

  Consequence -> AttrRefExpression "=" Expression

  IsFullSensor: "sensor" ID (full:boolean)?
  Nozzle: "nozzle" ID
  Pump: "pump" ID (rpm:int)?
\end{code}


\noindent We can now write a program that uses a convenient textual notation,
which is especially useful for the expressions in the rules. We have created a
\emph{domain-specific language} for configuring the composition \emph{and}
behavior of fountains. A complete language definition would also include typing
rules and other constraints, but that is beyond the scope of this paper.



\begin{code} 
  fountain
    basin sensor s
          nozzle n1
          nozzle n2
    pump p
    if s.full && p.rpm > 0 then p.rpm = 0
\end{code}


DSLs fill the gap between feature models and programming languages. They can be
more expressive than feature models, but they are not as unrestricted and
low-level as programming languages. Like programming languages, DSLs, support
\ic{construction}, allowing the composition of an unlimited number of
programs. Construction happens by
instantiating language concepts, establishing relationships, and defining values for attributes. We do not a-priori know all
possible valid programs. In contrast to programming languages, DSLs keep the
distinction between problem space and solution space intact since they consist
of concepts and notations relevant to the problem domain. Non-programmers can
continue to contribute directly to the product development process, without
being exposed to implementation details.


DSLs are a good fit when instances of concepts need to be created, when
relationships between these instances must be established, or when algorithmic
behavior has to be described, e.g. in business rules, calculations, or events.
Examples of the application of DSLs include calculating the VAT and other taxes
in an invoicing product line, specifying families of pension contracts,
and defining communication protocols in embedded systems.





\section{Combining DSLs and Feature Models}
\label{sec:combining}

In the previous sections we have explained the difference in expressive power
between feature models and DSLs. We have also outlined the benefits and
drawbacks of both approaches. In this section we categorize how both approaches
can be combined.




\subsection{Variations in the Transformation or Execution}

When working with DSLs, the execution of models --- by transformation, code
generation or interpretation --- is under the control of the domain
engineer. The transformations or the interpreter can also be varied based on a
feature model.

\parhead{Negative Variability via Removal} The transformations or the
interpreter can be annotated with presence conditions, the configuration
happens before the transformations or the interpreter are executed.

\parhead{Branching} The interpreter or the transformations can query over
a feature configuration and then branch accordingly at runtime.

\parhead{Positive Variability via Superimposition} Transformations or
interpreters can be composed via superposition before execution. For
transformations, this is especially feasible if they transformation language
is declarative, which means that the order in which the transformations are
specified is irrelevant. Interpreters are usually procedural, object-oriented or
functional programs, so declarativeness is hard to achieve in those.

\parhead{Positive Variability via Aspects} If the transformation language
or the interpreter implementation language support aspect oriented
programming, then this can be used to configure the execution environment. For
example, the Xpand code generation engine (http://wiki.eclipse.org/Xpand)
supports AOP for code generation templates.


Examples for all of these are described by Voelter and
Groher~\cite{VoelterGroher2007} based on the openArchitectureWare tool
suite\footnote{openArchitectureWare has since been migrated to the Eclipse Xpand
and Xtext projects}.

Creating transformations with the help of other transformations or by any of the
above variability mechanisms is also referred to as \emph{higher-order
transformations} \cite{OldevikH07}. Note that if a bootstrapped environment is
used, the transformations are themselves models created with a transformation
DSL. This case then reduces to just variation over models, as described in the
previous subsection.




\subsection{DSLs as Attribute Types}
\label{DSLsAsAttribute}

Some feature modeling tools support feature attributes. Typically, the types
of these attributes are primitive (integer, string, float). They could also 
be typed with a DSL, the set of valid programs expressed in
this DSL would be the range of values.

This approach is useful when the primary product definition can be expressed
with a feature model. The DSL-typed attributes can be used for those variation
points for which selection is not expressive enough.


\subsection{Feature Models on Language Elements}

The opposite approach is also possible. The primary product definition is done
with DSLs. However, some language elements may have a feature model associated
with them for detailed configuration. When the particular language concept is
instantiated, a new ("empty") feature configuration is created, and can be
configured by the application engineer.


\subsection{Merging of the two approaches}

We have described the limitations of the feature modeling approach. The feature
modeling community is working on alleviating some of these limitations.

For example, cardinality based feature models \cite{CzarneckiHE05} support the
multiple instantiation of feature subtrees. References between features could be
established by using feature attributes typed with another feature --- the value
range would be the set of instances of this feature. Name references are an
approximation of this approach.

Clafer \cite{291} combines meta modeling and feature modeling. In addition to
providing a unified syntax and a semantics based on sets, Clafer also provides
a mapping to SAT solvers to support validation of models. The following code is
Clafer code (adapted from Michal Antkiewicz' \emph{Concept Modeling Using
Clafer} tutorial at http://gsd.uwaterloo.ca/node/310). 

\begin{code} 
  abstract Person
    name : String
    firstname : String
    or Gender
       Male
       Female
    xor MaritalStatus
      Single
      Married
      Divorced
    Address
      Street : String  
      City : String
      Country : String
      PostalCode : String
      State : String ?

  abstract WaitingLine 
    participants -> Person *
\end{code}

\noindent
The Clafer code example describes a concept \ic{Person} with the following
characteristics:
\begin{itemize}
  \item a name and a first name of type \ic{String} (similar to attributes)
  \item a gender which is \ic{Male} or \ic{Female}, or both (similar to
  or-groups in feature models)
  \item a marital status which is either \ic{single}, \ic{married} or
  \ic{divorced} (similar to xor-groups in feature models)
  \item an \ic{Address} (similar composition is language definitions) 
  \item and an optional \ic{State} attribute on the address (similar to
  optional features in feature modeling)
\end{itemize}

The code also shows a reference: a \ic{WaitingLine} refers to any number of
\ic{Persons}.


Note, however, that an important ingredient for making DSLs work in practice is
the domain-specific concrete syntax. None of the approaches mentioned in this
section provide customizable syntax. However, approaches like Clafer are a very
interesting backend for DSLs to support analysis, validation and automatic creation of valid
programs from partial configurations (\sect{sec:future}). 





\section{Examples}
\label{sec:examples}

This section contains industry examples in which DSLs are used to implement
product lines. Note that we cannot reveal the actual companies using the DSL,
and in case of the fountains, which we had already introduced in 
\sect{sec:featureModelsVsDSLs}, we even had to move the example into another
domain. However the cases and the languages are real world examples.

\subsection{Alarm System Menus}

The company manufactures burglar alarm systems. These systems detect when
buildings are compromised. They consist of sensors that detect the burglary, and
actuators including sirens, lights, and alarm propagation facilities to the
police. These systems also have configuration devices, used by the house owner
to configure, among other things, when the system should be active, and
which kinds of alarms should be raised under which conditions.

The company sells many different alarm systems, sensors, and actuators. Based on
the configuration of an individual system, the menus in the configuration device
need to be adapted. Traditionally these menus have been described using Word
documents, developers then implemented the menus in~C.


A new approach uses a DSL that formally describes the menu structure. Code
generation creates the C implementation. \fig{alarmmenus} shows some example
code. The language is purely structural, no behavior is described explicitly. A
templating mechanism is provided that supports multiple instantiations of the
same template in several locations in the tree, configuring each instance with
different values passed into the template instance. Menus can also inherit from
other menus to avoid code duplication for related systems.




\begin{figure}[htp]
\begin{center}
  \includegraphics[scale=0.4]{figures/ple/alarmmenus.png}
  \caption[labelInTOC]{Example menu definition for the alarm systems. Menus
  contain submenus and items. Templates can be defined, and template instances
  can be embedded into a menu tree several times with different parameter
  values.}
  \label{alarmmenus}
\end{center}
\end{figure}



While the DSL is relatively simple, it plays an important role nonetheless,
because product management can directly describe the menus in a formal way,
making the overall development process much simpler, faster, and less error
prone.

We have used a DSL instead of a feature model for the following reasons: menus
require recursion in the underlying formalism to be able to define unlimited
numbers of instances of submenus. The ability to define standalone submenus that
can be included in other menus is an example of references. Finally, the various
elements have many fine grained attributes. A textual notation works much better
in these cases than trees.




\subsection{Fountains}

This is the example used in section \ref{sec:featureModelsVsDSLs}. Before using
DSLs, fountain designers experimented with different arrangements of basins and
pumps, writing down, in prose text, interesting configurations and behaviors.
Developers wrote the corresponding controller code in C. The domain from which
this example is derived is very complex, with ca. 700 different products!

Several DSLs are used. The first one (\fig{bsh-appl}) is used to describe
the logical structure of basins, pumps and valves. It uses a form of multiple
inheritance similar to classes (here: appliances) and traits (here: features),
quite similar to what Scala provides (http://scala-lang.org).

\begin{figure}[htp]
\begin{center}
  \includegraphics[scale=0.4]{figures/ple/bsh-appl.png}
  \caption[labelInTOC]{Fountains can be composed from features, who contribute hardware elements.
  Parametrized features (those with brackets) can be included more than once,
  binding the parameter differently each time.}
  \label{bsh-appl}
\end{center}
\end{figure}

A second language (\fig{bsh-cool}) is used to describe the behavior. The
behavior model refers to a hardware structure. All the hardware elements have
events, properties and commands defined, which can be accessed from the behavior
model. A state based, reactive, asynchronous language is used to describe the
behavior, driving the activation of the pumps and valves based on
sensor input and timing events.


\begin{figure}[htp]
\begin{center}
  \includegraphics[scale=0.4]{figures/ple/bsh-cool.png}
  \caption[labelInTOC]{The fountain behavior is defined with a reactive,
  asynchronous language. A pumping program is defined for a combination of
  hardware features. The properties, events and commands of the hardware
  elements defined by these features can be used in the programs.}
  \label{bsh-cool}
\end{center}
\end{figure}

In addition to generating C code, there is also an in-IDE interpreter that can
run the pumping programs and execute tests. These tests are also described with
a textual language. A simulation engine to "play" with the programs is
available as well. This is an example where additional tools make the
use of DSLs much more feasible for domain experts.

The behavior language also overlays configuration over the pumping behavior,
an example of negative variability of a model (\sect{sec:combining}).
The behavior can be varied depending on whether certain optional hardware
components are installed in the fountain, as shown in \fig{bsh-cool2}.


We have used DSLs in this case because algorithmic behavior is described. The
expressions used in the language cannot sensibly be represented with feature
models. The hardware structure language has to be able to instantiate the same
hardware component several times, another reason for using a DSL instead of a
feature model. We use negative variability to overlay hardware structure
dependencies over the behavior specifications.




\begin{figure}[htp]
\begin{center}
  \includegraphics[scale=0.68]{figures/ple/bsh-cool2.png}
  \caption[labelInTOC]{Within a pumping program, \ic{variant} statements can
  be used to implement negative variability over optional hardware features.
  The example shows code that is only executed if the \ic{WithAlarm} feature
  is present.}
  \label{bsh-cool2}
\end{center} 
\end{figure}


\subsection{Architecture DSLs}

Many product lines are built on a common software architecture, while the
application functionality varies from product to product. Architecture DSLs
\cite{Volter10, GokhaleBKBEDTPS08} can be used very effectively in these cases.
An architecture DSL is a DSL, in which the abstractions of the language
correspond to the architectural concepts of the execution platform. They are
defined by architects, and used by developers as they develop applications. When
developing products in challenging environments such as distributed real-time
embedded systems, architecture DSLs can provide the benefit of simulation and
automatic optimization as described by Balasubramanian and Schmidt in
\cite{BalasubramanianS08}.

One project in the transportation industry has used an architecture DSL overlaid
with configuration-based variability. The architecture models directly refer to
the features defined in the configuration model, a form of presence conditions.
Tooling is based on Eclipse Xtext and pure::variants. \fig{archdslvar} shows a
screenshot. The system also supported AOP: aspects are available to
"contribute" additional properties to existing model elements. The article in
\cite{Volter10} describes this example, and the general approach, in more
detail. 



\begin{figure}[htp]
\begin{center}
  \includegraphics[scale=0.32]{figures/ple/archdslvar2.png}
  \caption[labelInTOC]{Tool support (Eclipse Xtext and pure::variants) for
  referring to feature models from DSLs, implementing negative variability over
  DSL code.}
  \label{archdslvar}
\end{center}
\end{figure}  

A DSL was used in this case because architecture definition makes heavy use of
identities and references, attributes and recursion. For example, it must be
possible to define any number of components, and these than have to be
instantiated and connected. So even while no expressions are used, DSLs are
still useful in this case.


\section{Conceptual Mapping from PLE to DSLs}
\label{sec:conceptualMapping}

This section looks at the bigger picture of the relationship between PLE and
DSLs. It contains a systematic mapping from the core concepts of PLE to the
technical space of DSLs. First we briefly recap the core PLE concepts.

 
\begin{itemize}
  \item \emph{Core Assets} designate reusable artifacts that are used in more
  than one product. As a consequence of their strategic relevance, they are
  usually high quality and maintained over time. Some of the core assets might
  have variation points.

  \item \emph{A Variation Point} is a well-defined location in a core asset
  where products differ from one another.

  \item \emph{Kind of Variability} classifies the degrees of freedom one has
  when binding the variation point. This ranges from setting a simple Boolean
  flag over specifying a database URL to a DSL program to a Java class hooked
  into a platform framework.

  \item \emph{Binding Time} denotes the point in time when the decision is made
  as to which alternative should be used for a variation point. Typical binding
  times include source time (changes to the source code are required), load time
  (bound when the system starts up) and runtime (the decision is made while the
  program is running).

  \item \emph{The Platform} are those core assets that actually form a part of
  the running system. Examples include libraries, frameworks or middleware. 

  \item \emph{Production Tools} are core assets that are not part of the
  platform, but are used during the possibly automated development of products.

  \item \emph{Domain Engineering} refers to activities in which the core assets
  are created. An important part of domain engineering is domain analysis,
  during which a fundamental understanding of the domain and its
  commonalities and variability is established.

  \item \emph{Application Engineering} is the phase in which the domain
  engineering artifacts are used to create products. Unless variation points use
  runtime binding, they are bound during this phase.

  \item \emph{The Problem Space} refers to the application domain in which the
  product line resides. The concepts found in the problem space are typically
  meaningful to non-programmers as well.

  \item \emph{The Solution Space} refers to the technical space that is used
  to implement the products. In case of \emph{software} product line
  engineering, this space is software development. The platform lives in the
  solution space. The production tools create or adapt artifacts in the solution
  space based on a specification of a product in the problem space.

\end{itemize}

In the following sections we now elaborate on how these concepts are realized
when DSLs are used.


\subsection{Variation Points and Kinds of Variability}

This represents the core of the chapter and has been discussed extensively
above: DSLs provide more expressivity than feature models, while not being
completely unrestricted as programming languages.


\subsection{Domain Engineering and Application Engineering}

As we develop an understanding of the domain, we classify the variability. If
the variability at a particular variation point is suitable for DSLs, we develop
the actual languages together with the IDEs during domain engineering. The
abstract syntax of the DSL constitutes a formal model of the variability found
at the particular variation point. This is similar to analysis models, with the
advantage that DSLs are executable. Users can immediately express exemplary
domain structures or behavior and thereby validate the DSL. This should be
exploited: language definition should proceed incrementally and iteratively,
with user validation after each iteration. The example models created in this
way should be kept around, they constitute unit tests for the language.


The combination of several DSLs is often necessary. Different variation
points may have different DSLs that must be used together to describe a complete
product. In the fountains example, one DSL describes the hardware structure of
the fountains, and another one describes the behavior. The behavior DSL refers
to elements from the hardware DSL for sensor values and events. In this case,
one language merely refers to an element of another language. Deeper integration
may also be necessary. For example, we may want to embed a reusable expression
language into the fountain behavior DSL. Different language workbenches support
language composition to different degrees. References between languages are
always possible. Language embedding is not yet mainstream. It supported for
example by Spoofax \cite{KatsV10} and MPS \cite{VoelterSolomatov2010}. 

Application engineering involves using the DSLs to bind the respective variation
points. The language definition, the constraints, and the IDE guide the
user along the degrees of freedom supported by the DSL.



\subsection{Problem Space and Solution Space}

DSLs can represent any domain. They can be technical, inspired by a library,
framework or middleware, expected to be used by programmers and architects. DSLs
can also cover application domains, inspired by the application logic for which
the application is built. In this case they are expected to be used by
application domain experts. In the case of application DSLs, the DSL resides in
the problem space. For execution they are mapped to the solution space by the
production tools. Technical DSL can, however, also be part of the solution
space. In this case, DSL programs are possibly created by the mapping of an
application domain DSL to the solution space. This is an example of cascading
\cite{Voelter2009, CzarneckiAK06}: one DSL is executed by mapping it to another
DSL. It is also possible that technical DSLs are used by developers as an
annotation for the application domain DSLs, controlling the mapping to the
solution space or configuring some technical aspect of the solution directly
\cite{Voelter2009}.



\subsection{Binding Time}

DSLs can be executed in two ways. \emph{Transformation} maps a DSL program to
another formalism for which an execution infrastructure already exists. If this
formalism is another DSL, we speak of model-to-model transformation, or simply
transformation. If the target is a programming language, we speak of code
generation. Alternatively, the DSL can also be interpreted: a meta program that
is part of the platform executes the DSL program directly.
 


\begin{itemize}
  \item If we generate source code that has to be compiled, packaged and
  deployed, the binding time is source. We speak of static variability, or
  static binding.

  \item If the DSL programs are interpreted, and the DSL programs can be changed
  as the system runs, this constitutes runtime binding, and we
  speak of dynamic variability.

  \item If we transform the DSL program into another formalism that is then
  interpreted by the running system, we are in a middle ground. It depends on
  the details of how and when the result of the transformation is (re-)loaded
  into the running system whether the variability is load-time or runtime.

\end{itemize}

When to use transformation vs. interpretation depends on various, usually
non-functional concerns. Transformation and code generation is the more
mainstream approach because most people find it easier to implement and debug.
It has a couple of advantages compared to interpretation, better performance
being the most important one, especially in embedded systems. Interpretation is
intriguing because of the fast turnaround time. A detailed discussion of the
trade-offs is beyond the scope of this paper.




\subsection{Core Assets, Platform and the Production Tools}

DSLs constitute core assets, they are used for many, and often all
of the products in the product line. It is not so easy to answer the question
whether they are part of the platform or the production tools:


\begin{itemize}
  \item If the DSL programs are transformed, the transformation code is a
  production tool. It is used in the production of the products. The DSL or the
  models are not part of the running system.

  \item In case of interpretation, the interpreter is part of the platform.
  Since it directly works with the DSL program, the language definition becomes
  a part of the platform as well.

  \item If we can change the DSL programs as the system runs, even the IDE for
  the DSL is part of the platform.

  \item If the DSL programs are transformed into another formalism that is in
  turn interpreted by the platform, then the transformations constitute
  production tools and the interpreter of the target formalism is a part of the
  platform.
\end{itemize}



