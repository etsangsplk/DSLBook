
\chapter{DSLs and Software Architecture}


\chapterabstract{In this chapter we explore the relationship between DSLs and
software architecture. In particular we establish the notion of an Architecture
DSL (or ADSL), which is a DSL specifically created for a specific architecture.
We first discuss ADSLs based on an extensive example and then discuss the
conceptual details. The paper also looks at embedding business logic DSLs as
well as at the role software components can play in the context of DSLs.}

\sect{What is Software Architecture}

\subsection{Definitions}

Software architecture has many definitions by various groups of people. Here are
a few. Wikipedia defines software architecture in the following way: \emph{The
software architecture of a program or computing system is the structure or structures of
the system, which comprise software elements, the externally visible properties
of those elements, and the relationships between them}.

This is a classic definition that refers to the structure of a software system,
observable by analyzing an existing system. It emphasizes the structure (as
opposed to the behavior) and focusses on the coarse grained building blocks
found in the system. A definition by Boehm builds on this: \emph{A software
system architecture comprises a collection of software and system components,
connections, and constraints, a collection of system stakeholders' need
statements as well as a rationale which demonstrates that the components,
connections, and constraints define a system that, if implemented, would satisfy
the collection of system stakeholders' need statements.}

In addition to the structure, this definition also emphasizes the relevance of
the stakeholders and their needs and ties the structure of the system to what
the system is required to do.

Hayes-Roth introduce another concern: \emph{The architecture of a complex
software system is its style and method of design and construction.} Instead of
looking at the structures, they emphasize that there are different architectural
styles and they emphasize the "method of design and construction". Eoin Woods
takes it one step further: \emph{Software architecture is the set of design
decisions which, if made incorrectly, may cause your project to be cancelled.}
He emphasizes the design decisions that lead to a given system. So he doesn't
look at the system as a set of structures, but rather considers the architecture
as a process --- the design decisions --- that leads to a given system.

Let us propose another definition: \emph{Software architecture is everything
that needs to be consistent throughout a software system}. This definition is
useful because it includes structures \emph{and} behavior, it doesn't say anything
about coarse-grained vs.\ detailed (after all, a locking protocol is possibly a
detail, but it is important to implement it consistently) and it implies that
there needs to be some kind of process or method to achieve the consistency.

\begin{marginfigure}
\begin{center}
  \includegraphics[width=50mm]{figures-sweng/arch/archlayers.png}
  \caption[labelInTOC]{Conceptual structure of a software architecture}
  \label{archlayers}
\end{center}
\end{marginfigure}

Figure \ref{archlayers} looks at software architecture in more detail. At the
center of the diagram you can see the conceptual architecture. It defines
architectural concepts from which systems are built (we will come back to this
in the next section). Examples could include: \emph{task}, \emph{message},
\emph{queue}, \emph{component}, \emph{port}, or \emph{replicated data
structure}. Note that these concepts are independent of specific implementation
technologies: it is the technology mapping that defines how the architecture
concepts are implemented based on specific technologies. Separating the two has
the advantage that the conceptual discussions are not diluted by what certain
technologies may or may not be able to do, and how. The decision what technology
to map to is then driven by non-functional concerns, i.e.~whether and how a given
technology can provide the required quality of service.

The programming model is the way how the architectural concepts are implemented
in a given programming language. Ideally, the programming model should not
change as long as the architectural concepts remain stable --- even if the
technology mapping or the implementation technologies change. Applications are
implemented by instantiating the architectural concepts, and implementing them
based on the programming model.

I want to reemphasize the importance of the conceptual architecture. When asking
people about the architecture of systems, one often gets answers like: "it's a
Web service architecture", or "it's an XML architecture" or "it's a JEE
architecture". Obviously, all this conveys is that a certain technology is used.
When talking about architectures per se, we want to talk about architectural
\emph{concepts} and how they relate to each other. Only in a second step, a
mapping to one or more technologies should be discussed. Here are some of these
fundamental architectural concepts:

\begin{description}
  \item[Modularize] Break big things down into smaller things, so they can be
  understood (and potentially reused) more easily. Examples: Procedures,
  Classes, Components, Services, User Stories.
  \item[Encapsulate] Hide the innards of a module so they can be changed
  without affecting clients. Examples: Private Members, Facade Pattern, 
  Components, Layers/Rings/Levels.
  \item[Contracts] Describe clearly the external interface of a module.
  Examples: Interfaces, Pre/Post Conditions, Protocol State Machines,  
  Message Exchange Patterns, Published APIs.
  \item[Decoupling] Reduce dependencies in time, data structure or contention.
  Examples: Message Queues, Eventual Consistency, Compensating Transactions.
  \item[Isolate Crosscuts] Encapsulate handling of cross-cutting concerns.
  Examples: Aspect Orientation, Interceptors, Application Servers, Exception 
  Handling.
\end{description}

\noindent As we will see in the following section, architecture DSLs can
specify architectures unambiguously while emphasizing these fundamentals instead of
technologies.

\sect{Architecture DSLs}

\subsection{Conceptual Architecture and DSLs}

An Architecture DSL (ADSL) is a language that expresses a system's architecture
directly. "Directly" means that the language's abstract syntax contains
constructs for all the ingredients of the conceptual architecture. The language
can hence be used to describe a system on architectural level without using
low-level implementation code, but still in an unambiguous way. Code generation
is used to generate representations of the application architecture in the
implementation language(s), automating the technology mapping\footnote{Of
course, the decisions about the mapping have to be made manually.}. Finally, the
programming model is defined with regards to the generated code plus possibly additional frameworks\footnote{Architecture DSLs are typically
\emph{incomplete}. Only the architecturally relevant structures and behaviors
are expressed with the DSL. The application logic is implemented in a GPL.}.

We want to (re)emphasize an important point: we do not advocate the definition
of a generic, reusable language such as the various ADLs, or UML (see below).
Based on our experience, the approach works best if you define the ADSL in real
time as you understand, define and evolve the conceptual architecture of a
system. The process of defining the language actually helps the
architecture/development team to better understand, clarify and refine the
architectural abstractions as the language serves as a (formalized) ubiquitous
language that lets you reason and discuss about the architecture.


\subsection{An Example ADSL}

This section contains an example of an Architecture DSL taken from a real
system in the domain of airport management systems\footnote{I was helping that
customer build an architecture DSL for their architecture. They hired me
because they needed to get a grips of their architecture independent of specific
technologies, since the system was supposed to last for 20 years.}.

The customer decided they wanted to build a new airport management system.
Airlines use systems like these to track and publish information about whether
airplanes have landed at airports, whether they are late, and to track the
technical status of the aircraft. The system also populates the online-tracking
system on the Web and information monitors at airports. This system is in many
ways a typical distributed system: there is a central data center to do some of
the heavy number crunching, but there are additional machines distributed over
relatively large areas. Consequently you cannot simply shut down the whole
system, which leads to a requirement to be able to work with different versions
of parts of the system at the same time. Different parts of the system will be
built with different technologies: Java, C++, C\#. This is not an untypical
requirement for large distributed systems either. Often you use Java technology
for the backend, and .NET technology for a Windows front end. They had decided
that the backbone of the system would be a messaging infrastructure and they
were evaluating different messaging tools for performance and throughput.

While the customer knew many of the requirements and had made specific decisions
about certain architectural aspects, they didn't have a well-defined conceptual
architecture. And it showed: when the team were discussing about their system,
they stumbled into disagreements about architectural concepts all the time
because they had no \emph{language} for the architecture.

To solve this issue, an architecture DSL was developed. We started with the
notion of a component. At that point the notion of components is defined
relatively loosely, simply as the smallest architecturally relevant building
block, a piece of encapsulated application functionality\footnote{In many cases
it is a good idea to start with the notion of a component, although components
may look different in different system. Since components are so important, we
discuss them in \sect{comps}.}. We also assume that components can be
instantiated, making components the architectural equivalent to classes in
object-oriented programming. To enable components to interact with each other,
we also introduce the notion of interfaces, as well as ports, which are named
communication endpoints typed with an interface. Ports have a direction
(provides, requires) as well as a cardinality. Based on this initial version of
the ADSL, we could write the following example code:

\begin{lstlisting}[language=archdsl]
component DelayCalculator {
  provides aircraft: IAircraftStatus 
  provides managementConsole: IManagementConsole 
  requires screens[0..n]: IInfoScreen
}

component Manager {
  requires backend[1]: IManagementConsole
}

component InfoScreen {
  provides default: IInfoScreen 
}

component AircraftModule {
  requires calculator[1]: IAircraftStatus
}
\end{lstlisting}


\noindent It is important to not just state which interfaces a component
\emph{provides}, but also which interfaces it \emph{requires} because we want to
be able to understand (and later: analyze with a tool) component dependencies.
This is important for any system, but especially important for the versioning
requirement. 

We then looked at instantiation. There are many aircraft, each running an
\ic{AircraftModule}, and there are even more \ic{InfoScreen}s. So we need to express
instances of components. Note that these are logical instances. Decisions about
pooling and redundant physical instances had not been made yet. We also
introduce connectors to define actual communication paths between components
(and their ports).

\begin{lstlisting}[language=archdsl]
instance dc: DelayCalculator
instance screen1: InfoScreen
instance screen2: InfoScreen
connect dc.screens to (screen1.default, screen2.default)
\end{lstlisting}


\noindent At some point it became clear that in order to not get lost in all the
components, instances and connectors, we need to introduce some kind of
namespace. It became equally clear that we'd need to distribute things to
different files:

\begin{lstlisting}[language=archdsl]
namespace com.mycompany {

  namespace datacenter {
  
    component DelayCalculator {
      provides aircraft: IAircraftStatus 
      provides managementConsole: IManagementConsole 
      requires screens[0..n]: IInfoScreen
    } 
    
    component Manager {
      requires backend[1]: IManagementConsole
    }
    
  }
  
  namespace mobile {
  
    component InfoScreen {
      provides default: IInfoScreen 
    }
    
    component AircraftModule {
      requires calculator[1]: IAircraftStatus
    }
    
  }
} 
\end{lstlisting}


\noindent It is also a good idea to keep component and interface definition
(essentially: type definitions) separate from system definitions (connected
instances), so we introduced the concept of compositions, which make a group of
instances and connectors identifiable by a name:

\begin{lstlisting}[language=archdsl]
namespace com.mycompany.test {

  composition testSystem {
    instance dc: DelayCalculator
    instance screen1: InfoScreen
    instance screen2: InfoScreen
    connect dc.screens to (screen1.default, screen2.default)
  }
} 
\end{lstlisting}


\noindent Of course in a real system, the \ic{DelayCalculator} would have to
dynamically discover all the available \ic{InfoScreen}s at runtime. There is not
much point in manually describing those connections. So, we specify a query that
is executed at runtime against some kind of naming/trader/lookup/registry
infrastructure\footnote{Note how the specific realiziation depends on the
technology; we just express that we have to be able to run the queries
specified in the model against the implementation.}. It is re-executed
every 60 seconds to find the \ic{InfoScreen}s that had just come online.

\begin{lstlisting}[language=archdsl]
namespace com.mycompany.production {

  instance dc: DelayCalculator

  // InfoScreen instances are created and 
  // started in other configurations 
  dynamic connect dc.screens query {
    type = IInfoScreen
    status = active
  }
} 
\end{lstlisting}


\noindent A similar approach can be used to address load balancing or fault
tolerance. A static connector can point to a primary as well as a backup
instance. Or a dynamic query can be re-executed when the currently used instance
becomes unavailable. To support registration of instances with the naming or
registry service, we add additional syntax to their definition. A registered
instance automatically registers itself with the registry, using its name (qualified
through the namespace) and all provided interfaces. Additional parameters can be
specified, the following example registers a primary and a backup instance for
the \ic{DelayCalculator}:


\begin{lstlisting}[language=archdsl]
namespace com.mycompany.datacenter {

  registered instance dc1: DelayCalculator {
    registration parameters {role = primary}
  }
  
  registered instance dc2: DelayCalculator {
    registration parameters {role = backup}
  }
} 
\end{lstlisting}


\noindent So far we didn't really define what an interface is. We knew that we'd
like to build the system based on a messaging infrastructure. Here's our first
idea: an interface is a collection of messages, where each message has a name
and a list of typed parameter\footnote{This also requires the ability to define
data structures, but in the interest of brevity, we won't show that.}. After
discussing this notion of interfaces for a while, we noticed that it was too
simplistic. We needed to be able to define the direction of a message: does it
flow in or out of the port? More generally, which kinds of message interaction
patterns are there? We identified several, here are examples of \ic{oneway} and
\ic{request-reply}:



\begin{lstlisting}[language=archdsl]
interface IAircraftStatus {

  oneway message reportPosition(aircraft: ID, pos: Position )

  request-reply message reportProblem {
    request (aircraft: ID, problem: Problem, comment: String)
    reply (repairProcedure: ID) 
  }
} 
\end{lstlisting}


\noindent We talked a long time about various message interaction patterns.
After a while it turned out that one of the core use cases for messages is to
push updates of various data structures out to various interested parties. For
example, if a flight is delayed because of a technical problem with an aircraft,
then this information has to be pushed out to all the \ic{InfoScreen}s in the system.
We prototyped several of the messages necessary for "broadcasting" complete
updates, incremental updates and removal of data items. And then it hit
us: we were working with the wrong abstraction! While messaging is a suitable
\emph{transport} abstraction for these things, architecturally we're really talking
about replicated data structures. It basically works the same way for all of
those structures:

\begin{itemize}
	\item You define a data structure (such as \ic{FlightInfo}).
 	\item The system then keeps track of a collection of such data structures.
	\item This collection is updated by a few components and typically read by many
	other components.
	\item The update strategies from publisher to receiver always include full
	update of all items in the collection, incremental updates of just one or a few
	items and removal of items.
\end{itemize}

\noindent Once we understood that in addition to messaging, there's this
additional core abstraction in the system, we added this to our Architecture DSL
and were able to write something like the following. We define data structures
and replicated items. Components can then publish or consume those replicated
data structures. We state that the publisher publishes the replicated data
whenever something changes in the local data structure. However, the
\ic{InfoScreen} only needs an update every 60 seconds (as well as a full load of
data when it is started up).


\begin{lstlisting}[language=archdsl]
struct FlightInfo {
  from: Airport
  to: Airport
  scheduled: Time
  expected: Time
}

replicated singleton flights {
  flights: FlightInfo[]
}

component DelayCalculator {
  publishes flights { publication = onchange }
}

component InfoScreen {
  consumes flights { update 60 }
}
\end{lstlisting}

\noindent This is much more concise compared to a description based on messages.
We can automatically derive the kinds of messages needed for full update, incremental
update and removal and create these messages in the model using a model
transformation. The description reflects much more clearly the actual
architectural intent: it expresses better what we want to do (replicate data)
compared to a lower level description of how we want to do it (sending around
update messages). 

While replication is a core concept for data, there's of course still a need for
messages, not just as an implementation detail, but also as a way to express
your architectural intent. It is useful to add more semantics to an interface,
for example, defining valid sequencing of messages. A well-known way to do that
is to use protocol state machines. Here is an example that expresses that you
can only report positions and problems once the aircraft is registered. In other
words, the first thing an aircraft has to do is register itself.

\begin{lstlisting}[language=archdsl]
interface IAircraftStatus {

  oneway message registerAircraft(aircraft: ID! ) 
  
  oneway message unregisterAircraft(aircraft: ID! ) 
  
  oneway message reportPosition(aircraft: ID!, pos: Position! ) 
  
  request-reply message reportProblem {
    request (aircraft: ID!, problem: Problem!, comment: String!)
    reply (repairProcedure: !ID) 
  }
  
  protocol initial = new {
    state new {
      registerAircraft => registered
    }
    state registered { 
      unregisterAircraft => new
      reportPosition
      reportProblem
    }
  }
} 
\end{lstlisting}

\noindent Initially, the protocol state machine is in the \ic{new} state where
the only valid message is \ic{registerAircraft}. If this is received, we
transition into the \ic{registered} state. In \ic{registered}, you can either
\ic{unregisterAircraft} and go back to \ic{new}, or receive a \ic{reportProblem}
or \ic{reportPosition} message in which case you'll remain in the
\ic{registered} state. 

We mentioned above that the system is distributed geographically. This means it
is not feasible to update all parts of the systems (e.g.,~all \ic{InfoScreen}s or
all \ic{AircraftModule}s) at the same time. As a consequence, there might be
several versions of the same component running in the system. To make this
feasible, many non-trivial things need to be put in place in the runtime system.
But the basic requirement is this: you have to be able to mark up versions of
components, and you have to be able to check them for compatibility with old
versions. The following piece of code expresses that the \ic{DelayCalculatorV2} is a
new implementation of \ic{DelayCalculator}. \ic{newImplOf} means that no externally
visible aspects change which is why no ports and other externally-exposed
details of the component are declared. For all intents and purposes, it's the
same thing --- just maybe a couple of bugs are fixed.

\begin{lstlisting}[language=archdsl]
component DelayCalculator {
  publishes flights { publication = onchange }
}
newImplOf component DelayCalculator: DelayCalculatorV2
\end{lstlisting}


\noindent To evolve the externally visible signature of a component, one can
write this: 

\begin{lstlisting}[language=archdsl]
component DelayCalculator {
  publishes flights { publication = onchange }
}

newVersionOf component DelayCalculator: DelayCalculatorV3 {
  publishes flights { publication = onchange }
  provides somethingElse: ISomething
}
\end{lstlisting}

\noindent The keyword \ic{newVersionOf} allows to add additional provided ports
(such as the \ic{somethingElse} port) and to remove required ports. You cannot
add additional required ports or remove any of the provided ports since that
would destroy the "plug-in compatibility". Constraints make sure that these
rules are enforced on model level. 

Using the approach shown here, we were able to quickly get a grip towards the
overall architecture of the system. All of the above was actually done in the
first day of the workshop. We defined the grammar, some important constraints,
and a basic editor (without many bells and whistles). We were able to separate
what we wanted the system to do from how it would achieve it: all the technology
discussions were now merely an implementation detail of the conceptual
descriptions given here\footnote{I don't want to give the impression that
technology decisions are unimportant. However, they should be an explicit second
step, and not mixed with the concepts. This is particularly important in light
of the fact that the system should live for > 20 years where technologies will
change more than once.}. We also achieved a clear and unambiguous definition of
what the different architectural concepts mean. The generally nebulous concept
of \emph{component} has a formal, well-defined meaning in the context of this
system. 

In this project, as well as in many other ones, we have used textual DSLs. We
have argued in this book why textual DSLs are superior in many cases, and these
arguments apply here as well. However, we did use visualization to show the
relationships between the building blocks, and to communicate the architecture
to stakeholders who were not willing to dive into the textual models. Figure
\ref{aal-vis} shows an example, created with Graphviz.

\begin{figure}[h]
\begin{center}
  \includegraphics[scale=0.55]{figures-sweng/arch/aal-vis.png}
  \caption[labelInTOC]{TODO}
  \label{aal-vis}
\end{center}
\end{figure}


\subsection{Architecture DSL Concepts}


\paragraph{What we did in a nutshell} The approach recommends the definition of
a formal language for your project's or system's conceptual architecture. You
develop the language as the understanding of your architecture grows. The
language therefore always resembles the complete understanding about your
architecture in a clear and unambiguous way. 

\paragraph{Component Implementation} By default, architecture DSLs are
incomplete, component implementation code is written manually against the
generated API code, using well-known composition techniques such as inheritance,
delegation or partial classes (cf. \todo{ref}).

However, there are other alternatives for component implementation that do not
use a GPL, but instead use formalisms that are specific to certain classes of
behavior: state machines, business rules or workflows. You can also define and
use a domain-specific language for certain classes of functionality in a
specific business domain\footnote{Be aware that the discussion in this section
is only really relevant for application-specific behavior, not for all
implementation code. Huge amounts of implementation code are related to the
technical infrastructure (e.g.,~remoting, persistence, workflow) of an
application. It can be derived from the architectural models, and generated
automatically. }.


\paragraph{Standards, ADLs and UML} Describing architecture with formal
languages is not a new idea. Various communities recommend using Architecture
Description Languages (ADLs) or the Unified Modeling Language (UML).
However, all of those approaches advocate using existing, \emph{generic} languages for
specifying architecture, although some of them, including the UML, can be
customized to some degree.

Unfortunately, efforts like that completely miss the point. We have not
experienced much benefit in shoehorning your architecture description into the
(typically very limited as well as too generic) constructs provided by
predefined languages --- one of the core activities of the approach explained is
this chapter is the process of actually building \emph{your own language} to capture
your system's conceptual architecture.


\paragraph{Code Generation} It should have become clear from the chapter that
the primary benefit of developing the architecture DSL (and using it) is just
that: understanding concepts by removing any ambiguity and defining them
formally. It helps you understand your system and get rid of unwanted technology
interference. But of course, now that we have a formal model of the conceptual
architecture (the language) and also a formal description of system(s) we are
building --- i.e., the or models defined using the language --- we
might as well use it to do more good:

\begin{itemize}
  \item
    We generate an API against which the implementation is coded. That API
    can be non-trivial, taking into account the various messaging paradigms,
    replicated state, etc. The generated API allows developers to code the
    implementation in a way that does not depend on any technological decisions: 
    the generated API hides those from the component implementation code. We call
    this generated API and the set of idioms to use it the programming model.
  \item
    Remember that we expect some kind of component container or middleware
    platform to run the components, so we also generate the code that is
    necessary to run the components (including their
    technology-neutral implementation) on the implementation technology of
    choice. We call this layer of code the technology mapping code (or glue
    code). It typically also contains the configuration files for
    the various platforms involved\footnote{As a side effect, the generators capture best
    practices in working with the technologies you've decided to use.}.
\end{itemize}

\noindent It is of course completely feasible to generate APIs for several
target languages (supporting component implementation in various languages) and/or
generating glue code for several target platforms (supporting the execution of
the same component on different middleware platforms). This nicely supports
potential multi-platform requirements, and also provide a way to scale or evolve
the infrastructure over time.

Another point worth making is that you typically generate in several phases: a
first phase uses type definitions (components, data structures, interfaces) to
generate the API code so you can write the component implementation code. A
second phase generates the glue code and the system configuration code. As a
consequence, it is often sensible to separate type definitions from system
definitions into several different viewpoints: they are used at different times
in the overall process, and also often created, modified and processed by
different people. This shows that language (and model) modularization is useful.

In summary, the generated code supports an efficient and technology independent
implementation and hides much of the underlying technological complexity, making
development more efficient and less error-prone.

\paragraph{What needs to be documented?} I advertise the above approach as a way
to formally describe a system's conceptual and application architecture. So,
this means it serves as some kind of documentation, right? Right, but it does
not mean that you don't have to document anything else. The following things
still need to be documented:

\begin{description}

  \item[Rationales/Architectural Decisions] The DSLs describe \emph{what} your
architecture looks like, but it does not explain \emph{why}. You still need to
document the rationales for architectural and technological decisions. Note that
the grammar is a really good baseline for such a documentation. Each of the
constructs in your architecture DSL grammar is the result of architectural
decisions. So, if you explain for each grammar element why it is there (and why
other alternatives have not been chosen) you are well on your way to documenting
the important architectural decisions. A similar approach can be used for the
application architecture, i.e.~the programs written with the DSL.

  \item[User Guides] A language grammar can serve as a well-defined and formal
way of capturing an architecture, but it is not a good teaching tool. So you
need to create tutorials for your users (i.e., the application programmers) on
how to use the architecture. This includes what and how to model (using your
DSL) and also how to generate code and how to use the programming model (how to
fill in the implementation code into the generated skeletons).
\end{description}

\noindent There are more aspects of an architecture that might be worth
documenting, but the above two are the most important ones.


\subsection{Embedding Business Logic via DSLs}

Architecture DSLs as introduced above focus on the description of software
architecture. As the section on component implementation explains, we do not
concern ourselves much with the question of how the components are implemented,
i.e.\ how business logic is expressed.

Of course, business logic is essential for building the actual software system.
As we outline above, one can either implement the application logic with
manually written code, or one can use a DSL for that. If application domain DSLs
are used together with architecture DSLs, then the code generator for the
application domain DSL has to act as the "implementor" of the components (or
whatever other architectural abstractions are defined in the architecture DSL).
The code generated from the business logic DSL must fit into the code skeletons
generated from the architecture DSL. The code composition techniques discussed
for incomplete DSLs in \todo{ref} can be used here.


\sect{Component Models}
\label{comps}

There are many (more or less formal) definitions of what a components is. They
range from a building block of software systems to something with explicitly
defined context dependencies to something that contains business logic and is
run inside a container.

Our understanding (notice we are not saying we have a real definition) is that a
component is the smallest architectural building block. When defining a system's
architecture, you don't look inside components. Components have to specify all
their architecturally relevant properties declaratively (aka in meta data, or
models). As a consequence, components become analyzable and composable by tools.
Typically they run inside a container that serves as a framework to act on the
runtime-relevant parts of the meta data. The component boundary is the level at
which the container can provide technical services such as as logging,
monitoring, or failover.

We don't have any specific requirements towards what meta data a component
actually contains (and hence, which properties are described). We think that the
concrete notion of components has to be defined for each
(system/platform/product line) architecture separately: this is exactly what we
do with the language approach introduced above.

From our experience in software projects, we find that we almost always start by
modeling the component structure of the system to be built. To do that, we start
by defining what a component actually is --- that is, by defining a meta model
for component-based development. Independent of the domain in which the
development project exists, these meta models are quite similar across
application domains. We therefore show parts of these meta models here to give
you a head start when defining your own component architecture.

\FloatBarrier 
\subsection{Three Typical Viewpoints}

It is useful to look at a component-based system from several viewpoints
(\todo{ref}). Three viewpoints form the backbone of the description. The
\emph{Type} viewpoint describes component types, interfaces, and data
structures\footnote{Referring back to the terminology introduced in \todo{ref},
this viewpoint is \emph{independent}. It is also \emph{sufficient} for
generating all the code that is needed for developers to implement the
application logic.}. A component provides a number of interfaces and references
a number of required interfaces. An interface owns a number of operations, each
with a return type, parameters, and exceptions. \fig{viewpoints_type} shows
this.

\begin{figure}[h!]
\begin{center}
  \includegraphics[scale=0.30]{figures-sweng/arch/viewpoints_type.png}
  \caption[labelInTOC]{The types viewpoint describes interfaces, data types and
  components. These are referred to as types because they can be instantiated
  (in the composition viewpoint) to make up the actual application.}
  \label{viewpoints_type}
\end{center}
\end{figure}


\noindent To describe the data structures with which the components work
(\fig{viewpoints_data}), we start out with the abstract concept \ic{Type}. We
use primitive types as well as complex types. A \ic{ComplexType} has a number of
named and typed attributes. There are two kinds of complex types. Data transfer
objects are simple (C-style) \ic{struct}s that are used to exchange data among
components. Entities have a unique ID and can be persisted (this is not visible
from the meta model). Entities can reference each other and thus build more
complex data graphs. Each reference specifies whether it is navigable in only
one or in both directions. A reference also specifies the cardinalities of the
entities at the respective ends, and whether the reference has containment
semantics.

\begin{figure}[h!]
\begin{center}
  \includegraphics[scale=0.30]{figures-sweng/arch/viewpoints_data.png}
  \caption[labelInTOC]{The structure of data types of course depends a lot on
  the application. A good starting point for data definitions is the well-known
  entity relationship model that is essentially represented by this meta model.}
  \label{viewpoints_data}
\end{center}
\end{figure}

\FloatBarrier


\noindent The \emph{Composition} viewpoint, illustrated in
\fig{viewpoints_comp}, describes component instances and how they are connected. Using the \emph{Type}
and \emph{Composition} viewpoints, we can define logical models of
applications\sidenote[][-10mm]{The Composition viewpoint is \emph{dependent}, it
depends on the \emph{Type} viewpoint. It is also sufficient for generating stub
implementation of the system for unit testing and for doing dependency analyses
and other checks for completeness and consistency.}. A \ic{Configuration}
consists of a number of \ic{ComponentInstance}s, each referencing their type
(from the \emph{Type} viewpoint). An instance has a number of wires (or
connectors): a \ic{Wire} can be seen as an instance of a
\ic{ComponentInterfaceRe- quirement}. Note the constraints defined in the meta
model:


\begin{itemize}
  \item For each \ic{ComponentInterfaceRequirement} defined in the instance's type,
  we need to supply a wire.
  \item The type of the component instance at the target end of a wire needs to
  provide the interface to which the wire's component interface requirement
  points.
\end{itemize}

\begin{figure}[h!]
\begin{center}
  \includegraphics[scale=0.30]{figures-sweng/arch/viewpoints_comp.png}
  \caption[labelInTOC]{The \emph{Composition} viewpoint describes the composition of a
  logical system from the component types defined in the \emph{Types}
  viewpoint.}
  \label{viewpoints_comp}
\end{center}
\end{figure}



\noindent The \emph{System} viewpoint describes the system infrastructure onto
which the logical system defined with the two previous viewpoints is deployed
(\fig{viewpoints_system}), as well as the mapping of the Composition viewpoint
onto this execution infrastructure\sidenote[][-15mm]{In some cases it may make
sense to separate the infrastructure definition from the mapping to the Composition
viewpoint (for example, if the infrastructure is configured by some operations
department).}.

\begin{figure}
\begin{center}
  \includegraphics[scale=0.30]{figures-sweng/arch/viewpoints_system.png}
  \caption[labelInTOC]{The \emph{System} viewpoint maps the logical system
  defined in the \emph{Composition} viewpoint to a specific hardware and
  systems software configuration.}
  \label{viewpoints_system}
\end{center}
\end{figure}

\noindent A system consists of a number of nodes, each one hosting containers. A
container hosts a number of component instances. Note that a container also defines its
kind --- representing technologies like OSGi, JEE, Eclipse or Spring. Based on
this data, together with the data in the Composition viewpoint, you can generate
the necessary "glue" code to run the components in that kind of container,
including container and remote communication configuration code as well as
scripts to package and deploy the artifacts for each container.

\vspace{5mm}
\noindent You may have observed that the dependencies among the viewpoints are
well-structured. Since you want to be able to define several compositions using
the same components and interfaces, and since you want to be able to run the
same compositions on several infrastructures, dependencies are only legal in the
directions shown in figure \ref{viewpoints_dependencies}.

\begin{figure}[h!]
\begin{center}
  \includegraphics[scale=0.30]{figures-sweng/arch/viewpoints_dependencies.png}
  \caption[labelInTOC]{Viewpoint dependencies are set up so that the same
  components (\emph{Type} viewpoint) can be assembled into several logical
  applications (\emph{Composition} viewpoint), and each of those can be mapped
  to several execution infrastructures (\emph{System} viewpoint).}
  \label{viewpoints_dependencies}
\end{center}
\end{figure}

\subsection{Aspect Models}

The three viewpoints described above are a good starting point for modeling and
building component-based systems. However, in many cases these three models are
not enough. Additional aspects of the system have to be described using specific
aspect models that are arranged "around" the three core viewpoint models. The
following aspects are typically handled in separate aspect models:

\begin{itemize}
  \item Persistence
  \vspace{-2mm}
  \item Authorization and Authentication (for enterprise systems)
  \vspace{-2mm}
  \item Forms, layout, page flow (for Web applications)
  \vspace{-2mm}
  \item Timing, scheduling and other quality of service aspects (especially in embedded systems)
  \vspace{-2mm}
  \item Packaging and deployment
  \vspace{-2mm}
  \item Diagnostics and monitoring
\end{itemize}

\noindent The idea of aspect models is that the information is not added to the
three core viewpoints, but rather is described using a separate model with a suitable
concrete syntax. Again, the meta model dependencies are important: the aspects
may depend on the core viewpoint models and maybe even on one another, but the
core viewpoints must not depend on any of the aspect models. Figure
\ref{viewpoints_persistence} illustrates a simplified persistence aspect 
meta model.

\begin{figure}[h]
\begin{center}
  \includegraphics[scale=0.30]{figures-sweng/arch/viewpoints_persistence.png}
  \caption[labelInTOC]{An example meta model for a persistence aspect. It maps
  data defined in the \emph{Type} viewpoint to tables and columns.}
  \label{viewpoints_persistence}
\end{center}
\end{figure}



\subsection{Variations}

\FloatBarrier
The meta models we describe above cannot be used in exactly this way in every
project. Also, in many cases the notion of what constitutes a \ic{Component} needs to
be extended. So there are many variations of these meta models. In this section
we discuss a few of them\footnote{Consider them as an inspiration for your own
case. In the end, the actual system architecture drives these meta models.}.

\paragraph{No Interfaces} Operations could be added directly to the components.
As a consequence, of course, you cannot reuse the interface's "contracts"
separately, independently of the supplier or consumer components.

\paragraph{Component Kinds} Often you'll need different kinds of components,
such as domain components, data access (DAO) components, process components, or
business rules components. Depending on this component classification you can
define the valid dependency structures between components. You will typically
also use different ways of implementing component functionality, depending on
the component kinds.

\paragraph{Layers} Another way of managing dependencies is to mark each
component with a layer tag, such as domain, service, GUI, or facade, and define
constraints on how components in these layers may depend on each other.

\paragraph{Hierarchical Components} Hierarchical components, as illustrated in
figure \ref{hierarchical}, are a very powerful tool. Here a component is
structured internally as a composition of other component instances. This way, a
recursive and hierarchical decomposition of a system is supported. Ports define
how components may be connected: a port has an optional protocol definition that
allows for port compatibility checks that go beyond simple interface equality.
While this approach is powerful, it is also non-trivial, since it blurs the
formerly clear distinction between Type and Composition viewpoints.

\begin{figure}[h]
\begin{center}
  \includegraphics[scale=0.35]{figures-sweng/arch/hierarchical.png}
  \caption[labelInTOC]{Hierarchical components support the recursive
  hierarchical decomposition of systems. In particular, a
  \icsn{HierarchicalComponent} consists internally of connected instances of
  other components.}
  \label{hierarchical}
\end{center}
\end{figure}

\paragraph{Configuration Parameters} A component might have a number of
configuration parameters --- comparable to command line arguments in console
programs --- that help configure the behavior of components. The parameters and
their types are defined in the type model, and values for the parameters can be
specified later, for example in the models for the Composition or the System
viewpoints.

\paragraph{Component Characteristics} You might want to express whether a
components is stateless or stateful, whether they are thread-safe or not, and
what their lifecycle should look like (for example, whether they are passive or
active, whether they want to be notified of lifecycle events such as activation,
and so on).

\paragraph{Asynchronicity} It is not always enough to use simple synchronous
communication. Instead, one of the various asynchronous communication paradigms,
such as those described in \todo{ref my book}, might be applicable. Because
using these paradigms affects the APIs of the components, the pattern to be used
has to be marked up in the model for the \emph{Type} viewpoint, as shown in
\fig{async}. It is not enough to define it in the Composition
viewpoint\footnote{If your application uses messaging interfaces instead of
the RPC-style interfaces discussed in this section, then an API can be
designed that remains independent of the communication paradigm.}.

\begin{figure}[h]
\begin{center}
  \includegraphics[scale=0.30]{figures-sweng/arch/async.png}
  \caption[labelInTOC]{A \icsn{ComponentInterface- Requirement} may describe which
  communication paradigm should be applied.}
  \label{async}
\end{center}
\end{figure}

\paragraph{Events} In addition to the communication through interfaces, you
might need (asynchronous) events using a static or dynamic publisher/subscriber
infrastructure. The "direction of flow" of these events is the opposite of the
dependencies discussed above.

\paragraph{Dyanmic Connection} The Composition viewpoint connects component
instances statically. This is not always feasible. If dynamic wiring is
necessary, the best way is to embed the information that determines which
instance to connect to at runtime into the static wiring model. So, instead of
specifying in the model that instance \ic{A} must be wired to instance \ic{B},
the model only specifies that \ic{A} needs to connect to a component with the
following properties: it needs to provide a certain interface, and for example
offer a certain reliability. At runtime, the wire is "deferenced" to a suitable
instance using an instance repository.

\paragraph{Structuring} Finally, it is often necessary to provide additional
means of structuring complex systems. The terms \emph{business component} or
\emph{subsystem} are often used. Such a higher-level structure consists of a set
of components (and related artifacts such as interfaces and data types).
Optionally, constraints define which kinds of components may be contained in a
specific kind of higher-level structure. For example, you might want to define
that a business component always consists of exactly one facade component and
any number of domain components. 



