\newpage


\part{DSLs in Software Engineering}
 
 
\noindent This part of the book looks at how DSLs can be used in various aspects
of software engineering. In particular, we look at requirements engineering,
software architecture, product line engineering and in the implementation phase
for technical and business DSLs. 

Note that this part of the book is not as coherent as the others. While the
other two parts of the book have been written in one piece, from scratch, this
part is assembled from various articles and papers, and also written partially
by other people. In spite of this, I think the part adds value.

 


\chapter{DSLs and Requirements}


\chapterabstract{This chapter looks at the role of DSLs in requirements
engineering. In particular it explores the use of DSLs to specify requirements
formally, at ways of representing requirements as models and at traceability
between implementation artifacts and requirements.}





\section{What is Requirements Engineering}

Wikipedia defines a requirements as follows:
\textit{a requirement is a singular documented need of what a particular product
or service should be or perform.}
Wiktionary says:
A requirement \textit{specifies a verifiable constraint on an implementation
that it shall undeniably meet or (a) be deemed unacceptable, or (b) result in
implementation failure, or (c) result in system failure.}
In our own words we would probably define a requirement as a statement about
\textit{what a system should do, and with which quality attributes, without
presupposing a specific implementation.} Requirements are supposed to tell the
programmers what the system they are about to implement, should do. They are a
means of communicating from humans (people who know what the system should do)
to other humans (those that have to implement it). Of course, as well all know,
there are a number of challenges in this:

\begin{itemize}
  \item Those who implement the system may have a different background than
  those who write them, making misunderstandings between the two groups likely. 
  \item Those who write the requirements may not actually really know what they
  want the system to do, at least initially. Requirements change over the course
  of a project, particularly as people start to "play" with early versions of
  the system.
  \item Usually requirements are written in plain English (or whatever language
  you prefer). Writing things down precisely and completely in a non-formal
  language is next to impossible\footnote{Writing \emph{any} large prose text
  document consistently and free from bugs is hard. I am sure you will find
  problems in this book :-)}.
\end{itemize}

\noindent As we say above, traditional requirements documents are a means to
communicate from people to people. However, in the end this is not really true. In an ideal
world, the requirements (in the brain of the person who writes them down) should
be communicated directly to the computer, without the intermediate programmer,
to avoid the misunderstandings mentioned above. If we look at the problem in
this way, requirements now become formal, computer-understandable.
 
Wikipedia has a nice list of characteristics that requirements should posses.
Here is a slightly adapted version of this list:
%
\begin{description}

\item[Complete] The requirement is fully stated in one place with no missing
information. This makes the requirement easy to consume because readers do not
have to build the complete picture from scattered information.

\item[Consistent] The requirement does not contradict any other requirement and
is fully consistent with all authoritative external documentation\footnote{This
is extremely hard to achieve with prose text, because there is no "compiler"
that finds inconsistencies.}.

\item[Cohesive \& Atomic] The requirement is atomic, i.e., it does not contain
conjunctions. e.g.,~"The postal code field must validate American and Canadian
postal codes" should be written as two separate requirements: (1) "The postal
code field must validate American postal codes" and (2) "The postal code field
must validate Canadian postal codes". This ensures that traceability from
implementation artifacts back to the requirements is relatively simple.

\item[Current] The requirement has not been made obsolete by the passage of
time. Outdated requirements should be removed or marked as outdated.

\item[Feasible] The requirement can be implemented within the constraints of the
project\footnote{Of course as the person who writes the requirements you may not
be able to judge, since you may not know the project constraints, the effort to
implement the requirement or whether the implementation technology is able to
address it. This is one reason why interaction with the impementors is
critical.}.

\item[Unambiguous] The requirement is concisely stated without recourse to
technical jargon, acronyms (unless defined elsewhere in the requirements
document), or other esoteric verbiage. It expresses objective facts, not
subjective opinions. It is subject to one and only one interpretation. Vague
subjects, adjectives, prepositions, verbs and subjective phrases are avoided.
Negative statements and compound statements are prohibited. All of those are
intended to make the prose language as precise as possible to avoid
misunderstandings.

\item[Mandatory] The requirement represents a stakeholder-defined characteristic
the absence of which will result in a deficiency that cannot be ameliorated. An
optional requirement is a contradiction in terms.

\item[Verifiable] The implementation of the requirement can be determined
through one of four possible methods: inspection, demonstration, test or
analysis. Otherwise it is hard to tell if a system actually fulfills a
requirement or not.

\end{description}

\noindent If requirements are written as pure prose text, then making sure all
these characteristics are met boils down mostly to a manual review process. Of
course, this is tedious and error prone and requirements end up in the sorry
state we all know.

To get one step better, you can use controlled natural
language\footnote{\icsn{http://en.wikipedia.org/wiki/Con- trolled\_natural\_language}}:
words like "must", "may", or "should" have a well defined meaning and are used
consciously. Using tables and, to some extent, state machines, is also a good
way to make some of the data a bit more unambiguous. To manage large sets of
requirements, tools should be used to support uniquely identifying and naming of
requirements, as well as the expression of relationships and hierarchies among
requirements\footnote{Example tools include DOORS, Requisite Pro or the Eclipse
Requirements Framework (RMF).} However, the requirements themselves are still
expressed as plain text, so the fundamental problems mentioned above are not
improved significantly.

In this chapter we will give you some ideas and examples on how this situation
can be improved with DSLs.


\section{Requirements versus Design versus Implementation}

Traditionally, we try to establish a clear line between requirements,
architecture and design, and implementation. For example, a requirement may
state that the system be 99.99\% reliable. The design may use hot-standby and
failover to continue service if a component breaks. The implementation would
then select a specific standby/failover technology to realize the design. We
make this distinction because we want to establish different roles in the
software engineering process. For example, product management writes the
requirements, a systems architect comes up with the architecture and design, and
then a programmer writes the actual code and chooses the technologies. Different
organizations may even be involved: the OEM writes the requirements, a systems
integrator does the architecture, and some outsourcing company does the coding.
In such a scenario it is important to draw precise boundaries between the
activities. However, in some sense the boundaries are arbitrary. We could just
as well state the following:

\noindent \emph{Requirement} The system shall be 99.99\% reliable by using
hot-standby and failover to continue service if something breaks.

\noindent \emph{Desgin} We use two application servers running on two hosts,
using XYZ messaging queue as a replication engine for the hot-standby. We use a watchdog
for detecting if the primary machine breaks.

\noindent \emph{Implementation} \ldots all the code that is necessary to
implement the design above.

From software development we know that it is very hard to get requirements
right. In the real world, you have to elaborate on the requirements
incrementally: you write some requirements, then you write a prototype and check
if the requirements make sense, then you refine the requirements, write a (maybe
more detailed) prototype, and so on. In systems engineering this approach is
also very well established. For example, when satellites are built, the
scientists come up with initial scientific requirements, for example, regarding
the resolution a satellite-based radar antenna looking at the earth should have.
Let's look at some of the consequences:

\begin{itemize}
  \item A given resolution requires a specific size of the antenna, and a
  specific amount of energy being sent out. (Actually, the two influence each
  other as well).
  \item A bigger antenna results in a heavier satellite, and more radar energy
  requires more solar panel area - increasing the size and weight even further.
  \item At some point, the size and weight of the satellite cannot be further
  increased, because a given launch vehicle reaches its limits - a different
  launch vehicle might be required.
  \item A bigger launch vehicle might be much more expensive, or you might have
  to change the launch provider. For example, you might have to use a Soyuz
  instead of an Ariane.
  \item A Soyus launched at Baikonur cannot reach the same orbits as an Ariane
  launched from Courou. As a consequence, the satellite might be "further
  away" from the area you want to inspect with your radar, neglecting the
  advantages gained by the bigger antenna.
\end{itemize}

\noindent ... and this has just looked at size and weight! Similar problems
exist with heat management, pointing accuracy or propulsion. As you can see, a change in a
requirement can lead to non-trivial consequences you will only detect if you
think about the \emph{implementation} of the requirement. A strictly sequential
approach (first write all the requirements, then think about the implementation)
will not work. So what do the systems engineers do? They come up with a model of
the satellite. Using mathematic formulas, they describe how the different
properties discussed above relate. These might be approximations or based on
past experience - after all, the real physics can be quite complex. And then
they run a so-called trade-off analysis. In other words, they change the input
values until a workable compromise is reached. Usually this is a manual process,
but sometimes parts of it can be automated.

This example illustrates three things. First, requirements elicitation is
incremental. Second, models can be a big help to precisely specify requirements
and then "play" with them. And third, the boundary between requirements and
design is blurred, and the two influence each other (\fig{reqAndDesign}).

\begin{figure}[h]
\begin{center}
  \includegraphics[scale=0.5]{figures-sweng/req/reqAndDesign.png}
  \caption[labelInTOC]{Requirements and Design influence each other and are
  thus best done iteratively, and in parallel}
  \label{reqAndDesign} 
\end{center} 
\end{figure} 
  

\section{Using DSLs for Requirements Engineering}

So here is the approach for using DSLs we suggest: identify a couple of core
areas of the to-be-built system that lend themselves to specification with a
formal language. Then develop a DSL to express these areas and use them to
describe the system. The rest of the system -- i.e.\ the areas for which a
DSL-based description makes no sense -- is described textually, with the usual
tools\footnote{We will discuss the integration between the textual requirements and the
DSL-based requirements below.}. 

Once a suitable DSL has been found and implemented, those people who have the
requirements in mind can directly express them -- the lossy human-to-human
communication is no longer a problem. Various constraint checks, tests and
simulations can be used to have the requirements owners "play" with the
requirements models to see if they really express what they had in mind.



Of course there is one significant caveat: we first have to build this DSL. So
how do we go about that? We could have somebody write prose requirements and
hand them over to the DSL developer \ldots back to square one!

There is a much better approach, though. Since today's language workbenches
support extremely rapid prototyping, you can actually build the DSLs
interactively with the requirements owner. Since you are not capturing the
specific requirements but rather try to describe how specific requirements are
described, you are performing a domain analysis: you try to understand the
degrees of freedom in the domain to be able to represent the domain with the
DSL. This is similar to what has been done with "analysis models" (back in the
day \ldots). However, instead of drawing UML analysis diagrams, you capture the
domain into a language definition, which makes it executable in the sense that
you can always turn around and have the requirements owner try to express
specific requirements with the DSL you're building, verifying the suitability of
the DSL. Here is the process we use:

\begin{enumerate}
  \item Have the requirements owner explain some particular aspect of the
  domain.
  \vspace{-2mm}
  \item Try to understand that aspect and change your DSL so it can express that
  aspect. 
  \vspace{-2mm}
  \item Have the requirements owner try to express a couple of specific, but
  representative, requirements with the DSL.
  \vspace{-2mm}
  \item You'll run into problems, some things cannot be expressed with the DSL.
  \vspace{-2mm}
  \item Go back to 1 and reiterate. A complete iteration should take no more
  than 60 minutes.
  \vspace{-2mm}
  \item After half a day, stop working with the requirements owner and clean
  up/refactor the DSL.
  \vspace{-2mm}
  \item Start another of the language design sessions with the requirements
  owner and iterate -- over time, you should get closer to \emph{the} DSL for
  the domain.
\end{enumerate}

\noindent Once that once DSL is finished the requirements owners are able to
express domain requirements without involvement of the software developers. 

Note how this approach to requirements engineering is very close to regular DSL
usage. We identify an aspect of the domain that lends itself to formalization,
iteratively build a language, and then let the domain experts -- who are the
requirements owners for many of the business requirements -- express the system
directly. The \emph{classical} requirements document is gone. In many ways the
refrigerator and pension plan examples from Part I of this book are examples of
this approach.

Using DSLs to specify (some parts of the) requirements formally helps achieve
some of the desirable characteristics for requirements discussed above. 
The following lists only those characteristics for which DSLs make a difference.

\begin{description}
	\item[Consistent] Consistency is enforced by the language. If the DSL is crafted
	correctly, no inconsistent requirements can be expressed.
	\item[Feasible] Specific requirements are checked for feasibility by being
	expressible with the DSL -- they are within the scope of what the DSL, hence,
	the domain for which we write the requirements -- is intended.
	\item[Unambiguous] A description of requirements -- or application
	functionality in general -- with a DSL always unambiguous, provided the DSL
	has well-defined semantics.
	\item[Verifiable] Constraints, tests, verification or simulation can be used to
	verify that the requirements regarding various properties. Inspection and review
	is simplified, because DSL programs are less verbose than implementation code,
	and clearer than prose.
\end{description}





\section{Integration with Plain Text Requirements}

You will not be able to describe all requirements of a systems using the
approach described above. There will always be aspects that cannot be
formalized, or that are so specific, that the effort of building a DSL does not
pay off. You have to find some way of integrating plain text requirements with
DSL code. Here are some approaches of how this can be done.


\subsection{Embedding DSL Code in a Requirements Tool}

One approach is to mix prose requirements with formalized, DSL-based
requirements. 

As part of the VERDE\footnote{\icsn{http://www.itea-verde.org/}} and
ProR\footnote{\icsn{http://www.pror.org/}} research projects, Eclipse-based tooling for
requirements engineering is developed. This includes a "classical" requirements
engineering tool in which textual requirements are classified, structured and
put into relationships with each other. The requirements structure is
represented as an EMF model to make integration with other model-based artifacts
simple. qIn addition to plain text, requirements can have parameters with
well-defined types. The types of these parameters can be primitive (string,
int), but they can also be any other Ecore meta class, so any additional model
structure can be embedded into a requirement. An integration with Xtext is
provided, which provides textual concrete syntax for these data structures. In
other words, it is possible to associate DSL programs with requirements
(\fig{dslEmbeddedInReqTool}). 

\begin{figure}[h]
\begin{center}
  \includegraphics[width=11cm]{figures-sweng/req/dslEmbeddedInReqTool.png}
  \caption[labelInTOC]{An Xtext DSL embedded in a requirements engineering tool
  based on the Eclipse Requirements Modeling Framework (RMF).}
  \label{dslEmbeddedInReqTool}
\end{center}
\end{figure}

\noindent We have built a similar solution for MPS in the mbeddr
project\footnote{\icsn{http://mbeddr.com}}. The solution supports collecting trees of
requirements, where each requirement has an ID, a kind and a short summary.
\fig{requirements1} shows an example. In addition, the one-line summary can be
expanded to reveal additional details (\fig{requirements2}). There users can
enter a detailed prose description as well as additional constraints among requirements (\ic{requires
also}, \ic{conflicts with}.) In the \ic{Additional Specifications} section, 
users can enter arbitrary DSL programs: since MPS supports language modularization
an composition (\sect{mpsmodular}), embedding arbitrary languages with arbitrary
syntax into the requirements language is no problem. 

\begin{figure}[h]
\begin{center}
  \includegraphics[width=11cm]{figures-sweng/req/requirements1.png}
  \caption[labelInTOC]{The requirements language supports creating trees of
  requirements. Each requirement has an ID, a kind and short text. In addition,
  a detailed description and constraints among requirements can be added
  (\fig{requirements2}).}
  \label{requirements1}
\end{center}
\end{figure}

It is possible to associate a
certain additional specification with a particular requirements kind. So,
for example, it is possible to specify that a requirement of kind \ic{timing}
must contain an instance of \ic{TimingSpecification} in the \ic{Additional
Specifications} section. 

\begin{figure}[h]
\begin{center}
  \includegraphics[width=11cm]{figures-sweng/req/requirements2.png}
  \caption[labelInTOC]{The detail view of the requirements language. In the
  \icsn{Additional Specifications} section users can enter arbitrary programs
  written in arbitrary DSLs. Constraints can be used to make sure that certain
  additional specifications are \emph{always} added to requirements of a
  particular kind.}
  \label{requirements2}
\end{center}
\end{figure}


% \subsection{Integrating Plain Text and Models}
% 
% If DSLs are used to describe requirements, these can obviously annotated with
% comments, providing some form of integration with non-formal requirements.
% However, this is a bad solution for various reasons. In most cases it is better
% to keep the text and the models separate, and then refer from one to the using
% actual links (not just text references).
% 
% Using the Xdoc extension to Xtext % TODO
% 
% 
% In MPS, one can use the generic documentation language and embed references
% % TODO


\section{Requirements Traceability}

Requirements traceability establishes links, or traces, between implementation
(or design or test) artifacts and requirements. This way, each (part of) an
artifact can be traced back to the requirements that drive this artifact.
Once such pointers are available, various analyses become possible. For example,
it is easy to find out if each requirement has been implemented (or tested) and
we know which implementation artifacts may have to change if a requirement
changes. Traces are typically typed (as in \ic{implements}, \ic{tests} or
\ic{refines}), so various different relationships can be established.

\noindent Requirements traceability has two challenges. The first one is social,
the second one is technical. The social problem is that, while traces are easy to analyze
once they are available, they still have to be established manually. This
requires discipline by the people, typically developers, whose job it is to
establish the traces. 

The technical problem addresses how to actually establish the pointers.
In a world where requirements as well as design, implementation and test
artifacts are all model-based, establishing these pointers becomes trivial. In
mixed environments with many different tools built on many different
foundations, this can become arbitrarily complicated.




\subsection{Traceability Framework for Eclipse}

The VERDE project mentioned above also develops a traceability framework based
on Eclipse. Various types of traceability links can be defined after which they
can be used to establish links between arbitrary EMF based models. In addition
to the generic EMF-based version, tool adapters can also be plugged in. These
provide specific support for links from/into a number of specific tools or
formats, for example plain text files, non-EMF UML tools or AUTOSAR models.

The links are kept external to the actual models, so no modifications to
existing meta models or languages are required. This is also the reason why
non-EMF artifacts can be integrated, albeit requiring the special tool adapter.


\begin{figure*}[h]
\begin{center}
  \includegraphics[scale=0.45]{figures-sweng/req/trace.png}
\caption{\emph{Left:} A C function with an attached requirement trace. Traces
can be attached to arbitrary program nodes, supporting tracing on arbitrary levels of
detail. \emph{Right, Top:} The requirements can be color coded to reflect whether
they are traced at all (grey), implemented (blue) and tested (green). Untraced
requirements are red. \emph{Right, Bottom:} The Find Usages dialog shows the different kinds of
traces as separate categories. Programs can also be shown without the traces
using conditional projection. We discuss this mechanism in the section on
product line variability (\sect{var}).}
\label{trace}
\end{center}
\end{figure*}
 

\subsection{Traceability in MPS}

As part of mbeddr, we have implemented a generic tracing framework base on MPS'
language annotations (discussed in \sect{mpsannot}). Arbitrary models --
independent of the language used to create them -- can be annotated with traceability
links, as shown in the left part of figure \ref{trace}.

A context menu action adds a new trace to any model element:
\ic{Ctrl-Space} allows the selection of one or more requirements at which to
point. Each trace has a \ic{kind}. The traced requirements are color coded to
reflect their trace status (\fig{trace}, top right). Finally the \ic{Find
Usages} functionality of MPS has been customized to show traces directly
(\fig{trace}, bottom right).


