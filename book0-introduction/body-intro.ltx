\part{Introduction}



\chapter{About this Book}

\chapterabstract{This book is about creating domain-specific languages. It 
covers three main aspects: DSL design, DSL implementation and software
engineering with DSLs, focusing mainly on textual languages. The book will make
use of modern language workbenches. It is not a tutorial for any specific tool,
but of course I will provide examples and some level of detail for mainly MPS
and Xtext, and to a lesser degree, some others. The goal of the book is to
provide a thorough overview of modern DSL engineering. The book tries to be
objective, but it is majorly based on my own experience and opinions.}


\section{Thank you!}

Before I do anything else, I want to thank my reviewers. This book has profited
tremendously from the feedback they sent me. It is a lot of work to read a book
like this concentrated enough to give meaningful feedback. All of my reviewers
did that. So, thank you very much! Here is the list, in alphabetical order:
Achim Demelt \todo{}, Alexander Shatalin, Bernd Kolb, Bran Selic, Christa
Schwanninger, Dan Ratiu, Iris Groher, Jean Bezivin, Jos Warmer, Laurence Tratt,
Mats Helander, Michael Kircher, Nora Ludewig and Vaclav Pech.
 
A special thank you goes to my girlfriend Nora Ludewig. She didn't just
volunteer to provide feedback on the book, she also had to endure all kinds of
other discussions around the topic all the time. Thanks!


\section{Why this book}

First of all, there is currently no book available that explicitly covers DSLs
developed with modern language workbenches, with an emphasis on textual
languages. I feel that this way of developing DSLs is very productive and very
useful, so I decided I'd need to provide a book to fill this gap. I wanted to
make sure the book contains a lot of detail on how to design and build good
DSLs, so it can act as a primer for DSL language engineering, for students as
well as practitioners. However, I also want the book to clearly show the
benefits of DSLs - not by pointing out general truths about the approach, but
instead by providing a couple of good examples of where and how DSLs are used
successfully. This is why the book has the three parts mentioned above.

Even though I have written a book on Model-Driven Software Development (MDSD)
before \todo{cite}, I feel that it is time for a complete rewrite\sidenote[]{I
have learned a lot in the meantime, my viewpoints have evolved and the tools
that are available today have evolved significantly. The latter is a reflection
of the fact that the whole MDD community has evolved. Ten years ago, UML was the
mainstay for MDD, and the relationship to DSLs was not clear. Today, DSLs are
the basis for most interesting and innovative aspects of MDSD.}. So if you are
among the people who have read the "old" MDSD book, you really should continue
reading. This one is very different, but in many ways a natural evolution of the
old one. It may gloss over certain details present in the older book, but it
will expand greatly on others.


\section{Who should Read This Book}
Everybody who has read my original book on Model-Driven Software Development
should read this book. This book can be seen as an update to the old one, even
though it is a complete rewrite.

On a more serious note, this book is intended for developers and architects who
want to implement their own DSLs. I expect solid knowledge in object oriented
programming as well as basic knowledge about functional programming and
(classical) modeling. It also helps if readers have heard the word
\emph{grammar} and \emph{parser} before, although I don't expect any significant
experience with these techniques.

In the MDSD book, there was a chapter of process and organizational aspects.
Except for maybe ten pages of process-related topics, this book does not contain
any of this. Two reasons: one, these things haven't changed much since the old
book, and you can read them there. Second, I feel these aspects were the weakest
part of the old book, because it is very hard to discuss process and
organzational aspects in a general way, independent of a particular context. Any
working software development process will work with DSLs. Any strategy to
introduce promising new techniques into an organization applies to introducing
DSLs. The few \emph{specific} aspects are covered in the aforementioned ten
pages at the end of the design chapter.


\section{How to read this Book}

The rest of this first part is a brief introduction to DSLs. It defines
terminology, looks at the benefits and challenges of developing and using DSLs,
and introduces the notion of modular languages, which plays an important role
throughout the book. This first part is written in a relatively personal, some
may say, biased style. It presents DSLs based on my experience. It is not a
scientific treatment.

Part II is about DSL design. It is a systematic exploration of eight design
dimensions relevant to DSL design: expressivity, coverage, semantics, separation
of concerns, completeness, large-scale model structure, language modularization
and syntax. It uses a set of four five case studies to illustrate the concepts.
It does not at all deal with implementation issues --- we address this in part
III.

Part III covers DSL implementation concerns. It looks at syntax definition,
constraints and type systems, scoping, transformation and interpretation,
debugging and IDE issues. It uses examples implemented with three different
tools. Part III is not intended as a tutorial for any one of them, but should
provide a solid foundation for understanding the technical challenges when
implementing DSLs.

Part IV looks at using DSLs in for various tasks in software engineering, among
them requirements engineering, architecture, implementation and, a specifically
relevant topic, product line engineering. Part IV consists of a set of fairly
independent chapters, each illustrating one of the software engineering
challenges.

\vspace{7mm}
\noindent I have had a lot of trouble deciding whether DSL design or DSL
implementation should go first. The two parts are relatively independent. As a
consequence of the fact that the design part comes first, there are some
references back to design concerns from within the implementation part. But
still, I guess the two parts can be read in any order, depending on what you are
more interested in.

The chapters in Part IV are independent from each other and can be read in any
sequence.

Finally, I think you should at least skim the rest of Part I. If you are already
versed in DSLs, you may want to skip some sections or just skim over them. But I
think it is important to understand where I am coming from to be able to make
sense of some of the later chapters.


\section{Tools}

You could argue that this whole business about DSLs is nothing new. You could
always build custom languages using parser generators such as lex/yacc, ANTLR or
JavaCC. And of course you are right. Martin Fowler's DSL book\todo{cite}
emphasizes this aspect.

However, I feel that language workbenches, which are tools to efficiently
create, integrate and use sets of DSLs in powerful IDEs, make a qualitative
difference. Developers, as well as the domain experts that use the DSL are used
to powerful, feature-rich IDEs and tools in general. If you want to establish
the use of DSLs and you propose to your users to use \ic{vi} or \texttt{notepad.exe},
you won't get very far.

Also, the effort to develop (groups of) DSLs and their IDEs has been
significantly reduced by the maturation of language workbenches. This is why in
this book I focus on DSL engineering with language workbenches, i.e. I focus
on IDE development just as much as I focus on language development.

\newthought{This is not a tool-tutorial book.} However, I will of course show
how to work with different tools, but this should be understood more as
representative examples of different tooling approaches. I tried to use diverse
tools for the examples, but for the most part I stuck to tools I happen to
know (well) and that have serious traction in the real-world or the potential to
do so: SDF/Stratego/Spoofax, Eclipse Modeling + Xtext, JetBrains MPS and, to
some extent, the Intentional Domain Workbench. Here is a brief overview over the
tools:



\subsection{Eclipse Modeling + Xtext}
\marginnote{http://eclipse.org/Xtext}
The Eclipse Modeling project is an ecosystem or frameworks and tools for
modeling, DSLs and all that's needed or useful around it. It would easily merit
its own book (or set of books), so I won't cover it extensively. I restrict
myself to Xtext, the framework for building textual DSLs, Xpand, a code
generation engine, as well as EMF/Ecore, the underlying meta meta model used to
represent model data. Xtext may not be as advanced as SDF/Stratego, but the
tooling is very mature and has a huge user community. Also, the surrounding
ecosystem provides a huge number of add-ons that support the construction of
sophisticated DSL environments. I will briefly look at some of these tools,
graphical editing frameworks among them.


\subsection{JetBrains MPS}
\marginnote{http://jetbrains.com/mps}
The Meta Programming System (MPS) is a projectional language workbench, which
means that there is no grammar and parser involved, rather, editor gestures
directly change the underlying AST which is projected in a way that looks like
text. As a consequence, MPS supports mixed notations (textual, symbolic,
tabular, graphical) and a wide range of language composition features.


\subsection{SDF/Stratego/Spoofax}
\marginnote{http://strategoxt.org/Spoofax}
These tools are developed at the university of Delft in Eelco Visser's group.
SDF is a formalism for defining grammars and parsers for context free grammars.
Stratego is a term rewriting system used for AST transformations and code
generation. Spoofax is an Eclipse-based IDE that provides a nice environment for
working with SDF and Stratego. This tooling has a number of advanced features
regarding language modularization and composition.


\subsection{Intentional Domain Workbench}
\marginnote{http://intentsoft.com}
A few examples will be based on the Intentional Domain Workbench. This is a
commercial product that also uses the projectional approach to editing. The IDW
has been used to build a couple of very interesting systems that can serve well
to illustrate the power of DSLs.


\vspace{7mm}
\noindent Way more tools exist. If you are interested, I suggest you take a
look at the Language Workbench
Competition\marginnote{http://languageworkbenches.net} where a number of
language workbenches (13 at the time of writing of this book) all implement the
same examples. This provides a good way to compare the various tools.

\section{Case Studies and Examples}

\todo{There still seem to be German examples in the screenshot --- change!}

I strove to make this book as accessible and practically relevant as possible,
so I provide a lot of examples. \marginnote{I decided against a single big,
running example because (a) it becomes increasingly complex to follow along and
(b) fails to illustrate different approaches to the same problem. However, we
use a set of case studies to illustrate many issues, especially in the part on
DSL design} Throughout the book I use relatively simple examples, described in
detail, to introduce principles. I use more sophisticated and elaborate
examples, described in less detail, to showcase the power of DSLs. These
examples are introduced below. These are mostly taken from real projects, some
of them anonymized or stripped of all too project-specific idiosyncrasies.


\subsection{Component Architecture}

This language is an architecture DSL used to define the software architecture of
a complex, distributed, component-based system in the transportation domain.
Among other architectural abstractions, the DSL supports the definition of
components and interfaces (\fig{compArch1}) as well as the definition of 
systems, which are connected instances of components (\fig{compArch1}). 
Code generators generate code that acts as the basis for the implementation
of the system, as well as all the code necessary to work with the
distribution middleware. It is used by software developers and architects and
implemented with Eclipse Xtext.

\begin{figure}[h]
  \rule{1\textwidth}{0.7pt}
  \vspace{-0.5cm}
  \includegraphics[width=8cm]{figures-intro/compArch1.png}
  \caption[][0.3cm]{Components and interfaces}
  \label{compArch1} 
  \rule{1\textwidth}{0.7pt}
\end{figure}
 
\begin{figure}[h]
  \rule{1\textwidth}{0.7pt}
  \vspace{-0.5cm}
  \includegraphics[width=7cm]{figures-intro/compArch2.png}
  \caption[][0.3cm]{Component instances and connectors}
  \label{compArch2} 
  \rule{1\textwidth}{0.7pt}
\end{figure}


\subsection{Refrigerator Configuration}


This case study describes a set of DSLs for cooling algorithms in refrigerators.
Three languages are used. The first one describes the logical hardware structure
of refrigerators (\fig{cooling1}). The second one describes cooling algorithms
in the refrigerators using a state-based, asynchronous language
(\fig{cooling2}). Cooling programs refer to hardware features and they can
access the properties of hardware elements from expressions and commands. The
third one is used to test cooling programs (\fig{cooling3}). These DSLs are used
by thermodynamists and are implemented with Eclipse Xtext.

\begin{figure}[h]
  \rule{1\textwidth}{0.7pt}
  \vspace{-0.5cm}
  \includegraphics[width=6cm]{figures-intro/cooling1.png}
  \caption[][0.3cm]{Hardware structure definition in the refrigerator
  case study}
  \label{cooling1} 
  \vspace{0.2cm}

  \rule{1\textwidth}{0.7pt}
\end{figure}


\begin{figure}[h]
  \rule{1\textwidth}{0.7pt}
  \vspace{-0.5cm}
  \includegraphics[width=12cm]{figures-intro/cooling2.png}
  \caption[][0.3cm]{A simple cooling algorithm.}
  \label{cooling2} 
  \rule{1\textwidth}{0.7pt}
\end{figure}

\begin{figure}[h]
  \rule{1\textwidth}{0.7pt}
  \vspace{-0.5cm}
  \includegraphics[width=6cm]{figures-intro/cooling3.png}
  \caption[][0.3cm]{A test script to test cooling programs}
  \label{cooling3} 
  \vspace{0.2cm}

  \rule{1\textwidth}{0.7pt}
\end{figure}



\subsection{Extended C}

This case study (detailed in\cite{Voelter10}) covers a set of extensions to the
C programming language tailored to embedded programming, developed as part of
mbeddr.com \todo{cite}. Extensions include state machines, physical quantities,
tasks, interfaces and components. Higher level DSLs are added for specific
purposes. An example used in a showcase application is the control of a Lego
Mindstorms robot. ANSI C is generated and subsequently compiled with GCC. 
This DSL is intended to be used by embedded software developers and it is 
implemented with MPS.

\begin{figure*}[h]
  \rule{1\textwidth}{0.7pt}
  \vspace{-0.5cm}
  \includegraphics[width=18cm]{figures-intro/extendedC-2.png}
  \caption[-5mm]{Example Code written using the Extended C
  language. It contains C functions, constants, as well as a task and a state
  machine.}
  \label{extendedC} 
  \rule{1\textwidth}{0.7pt}
\end{figure*}

\subsection{Pension Plans}

The pension DSL supports mathematical abstractions and notations to allow
insurance mathematicians to express their domain knowledge directly
(\fig{pension1}) as well as higher level pension rules and unit tests in the
table notation (\fig{pension2}). This DSL is used to efficiently describe
families of pension plans for a large insurance company. A complete Java
implementation of the calculation engine is generated. It is intended to be used
by insurance mathematicians and pension experts. It has been built by Capgemini
with the Intentional Domain Workbench.


\subsection{WebDSL}
 
WebDSL is a language for web programming\cite[1cm]{Visser07} that integrates
languages the different concerns of web programming, including persistent data
modeling (entity), user interface templates (define), access
control\cite{GroenewegenV08}, data
validation\cite{GroenewegenVisser-SOSYM-2011}, search, and more. The language
enforces inter-concern consistency checking, providing early detection of
failures\cite{HemelGKV11}. The fragment in \fig{webdsl} shqows a data model,
user interface templates, and access control rules for posts in a blogging
application. WebDSL is implemented with the Spoofax Language
Workbench\cite{KatsV10a} and is used in the researchr
digital library (\url{http://researchr.org}).   
 







\chapter{Setting the Stage}

\chapterabstract{Domain-Specific Languages (DSLs) are becoming more
and more important in software engineering. Tools are becoming  better as well, so
DSLs can be developed with less effort. In this chapter I first explain the
difference between DSLs and general-purpose languages, as well as the
relationship between them. I then look at the relationship to model-driven
development and develop a vision for modular programming languages which I
consider the pinnacle of DSLs. I discuss the benefits of DSLs, some of the
challenges for adopting DSLs and describe a few application areas. Finally, I
define a couple of important terms that will be used throughout the book.}


\section{Very Brief Introduction to the Terminology}

While we explain many of the important terms in the book, here are a few
essential ones. You should at least roughly understand those right now.

I use the term \emph{programming language} to refer to general purpose languages
(GPLs) such as Java, C++, Lisp or Haskell. While DSLs could be called
programming languages as well (although they are not \emph{general purpose}
programming languages) I don't do this in this book.


I use the terms model, program and code interchangeably because I think that any
distinction is more or less artificial. Code can be written in a GPL or in a
DSL. Sometimes DSL code and program code are mixed, so separating the two makes
no sense. If the distinction is important, I say "DSL program" or "GPL code". If
I use model and program or code in the same sentence, the model usually refers
to the more abstract representation. An example would be: "The program generated
from the model is \ldots".

If you know about DSLs, you will know that there are two main schools:
\emph{internal} and \emph{external} DSLs. In this book I only address external
DSLs. See \sect{Differentiation} for details.


I distinguish between the execution engine and the target platform. The
\emph{target platform} is what your DSL program has to run on in the end and is
assumed to be something we cannot change as part of the DSL development process.
The \emph{execution engine} can be changed, and bridges the gap between the DSL
and the platform. It may be an interpreter or a generator. An \emph{interpreter}
is a program running on the target platform that loads, and then acts on a DSL
program. A \emph{generator} (aka compiler) takes the DSL program and transforms
it into an artifact (often GPL souce code) that can run directly on the target
platform.\footnote{In an example from enterprise systems, the platform could be
JEE and the execution engine could be an enterprise bean that runs an
interpreter for our DSL. In embedded software, the platform could be a real-time
operating system, and the execution engine could be a code generator that maps
our DSL to the APIs provided by the RTOS.}.

I use the term \emph{processor} to refer to any program that processes models
expressed with a DSL. It may be the a constraint checker, a type inference
engine, a code generator, a model transformation, an interpreter, or a
sophisticated analysis tool.

A language, domain-specific or not, consist of the following ingredients. The
\emph{concrete syntax} defines the notation with which users can express
programs. It may be textual, graphical, tabular, or a mix of those. The
\emph{abstract syntax} is a data structure that can hold the semantically
relevant information expressed by a program. It is typically a tree of a graph.
It does not contain any details about the notation --- for example, in textual
languages, it does not contain keywords, symbols or whitespace. The \emph{static
semantics} of a language are the set of constraints and/or type system rules to
which programs have to conform, in addition to being structurally correct (with
regards to a the concrete and abstract syntax). \emph{Execution Semantics}
refers to the meaning of a program once it is executed. It is realized using the
\emph{execution engine}. If I use the term semantics without any qualification,
I refer to the execution semantics, not the static semantics.

Sometimes it is useful to distinguish between what I call technical DSLs and
application domain DSLs (sometimes also called business DSLs, vertical DSLs, or
"fachliche DSLs" in German). The distinction is not always clear and not always
necessary. But generally I consider technical DSLs to be used by programmers and
application domain DSLs to be used by non-programmers (i.e. domain experts).

The field discussed in this book has many names. These include Model-Driven
Development, Domain-Specific Modeling, Generative Software Development,
Language-Oriented Programming, Model-Integrated Computing, Model-Based
Engineering, Language Engineering, Grammarware, and, if you want to stretch it a
bit, Model-Driven Architecture and End-User Programming. Now, I don't claim that
all of these are the same and I am very aware of the differences. However, they
all have a common core which is designing languages for a specialized/limited
domain including their execution environments and IDEs. With this book, I aim to
cover this core.



\section{From General Purpose Languages to DSLs}

General Purpose Programming Languages (GPLs) are means for
programmers to instruct computers. All of them are Turing complete, which means
that they can be used to implement anything that is computable with a Turing
machine. It also means that anything expressible with one Turing complete
programming language can also be expressed with any other Turing complete
programming language. In that sense, all programming languages are exchangeable.

So then, why is there more than one? Why don't we program everything in Java or
Pascal or Ruby or Python? Why doesn't an embedded systems developer use Ruby,
and why doesn't a Web developer use C?

Of course there is the execution strategy. C code is compiled down to efficient
native code, whereas Ruby is run by a virtual machine (a mix
between an interpreter and a compiler). But in principle, you could compile Ruby to native
code, and you could interpret C. 

The real reason why these languages are used for what they are used for is that
their features are tailored to the tasks that are relevant in the respective
usage areas. In C you can directly influence memory layout (important to
communicate with low-level, memory mapped devices), you can use pointers
(resulting in potentially very efficient data structures) and the preprocessor
can be used as a (very limited) way of expressing abstractions with zero runtime
overhead. In Ruby, closures can be used to implement "postponed" behavior
(very useful for asynchronous web applications), you have powerful string
manipulation features (to handle input received from a website) and the
meta programming facility supports the definition of abstractions that are very
suitable for Web applications (Rails is \emph{the} example for that).


By now it should be clear that even within general-purpose programming we use
different languages that provide different features tailored to the specific
tasks at hand\footnote{We do this is real live as well! I am sure you have heard
about the eskimos who have 13 different words for snow, because this is relevant
in their "domain".}. The more specific the tasks get, the more reason there is
for specialized languages. Consider relational algebra: relational databases use
tables, rows, columns and joins as their core abstractions. A specialized
language, SQL, which takes these features into account has been created. Or
consider reactive, distributed, concurrent systems: Erlang is specifically made
for this environment.


So, if we want to "program" for even more specialized environments, it is
relatively obvious that specialized languages are useful. A Domain-Specific
Language is simply a language that is optimized for a given class of problems,
called a \emph{domain}. It is based on abstractions that are closely aligned
with the domain for which the language is built\marginnote{SQL has tables, rows
and columns, Erlang has lightweight tasks, message passing and pattern
matching.}. Specialized languages also come with a syntax suitable to
conveniently expressing these abstractions. In many cases these are textual
notations, but tables, symbols (as in mathematics) or graphics might also be
useful. Assuming the semantics of these abstractions is well defined, this
makes a good starting point for
effectively expressing programs for a specialized domain.

\parhead{Executing the Language} Engineering a DSL (or any language) doesn't
stop there, because the language has to be "brought to life" as well ---
programs written in the language have to be executed somehow. There are two main
approaches for that: translation (a.k.a. generation or compilation) and
interpretation. The former translates a DSL program to a language for which an
execution engine on a given target platform already exists. In the latter case,
you build a new execution engine (on top of your desired target platforms) which
loads the program and executes it directly.

If there is a big gap between the language abstractions and the relevant
concepts of target platform (i.e., the platform the interpreter or generated
code runs on), execution can become inefficient. E.g., if you try to store and
query graph data in a relational database, this will be very inefficient because
many joins are necessary. Another example is trying to run Erlang on a system
which only provides heavy-weight processes --- having thousands of processes as
Erlang requires, is not going to be efficient. So, when defining a language for
a given domain, you should be aware of the intricacies of the target platform
and the interplay between execution and language design\footnote{This may sound
counter-intuitive. Isn't a DSL supposed to abstract away from just these details
of execution? Yes, but: it has to be possible to implement a reasonably
efficient execution engine. DSL design is a compromise between approriate domain
abstractions and the ability to get to an efficient execution. A good DSL allows
the DSL \emph{user} to ignore execution concerns, but allows the DSL
\emph{implementor} to implement a reasonable execution engine}.


\parhead{Languages vs. Libraries and Frameworks} By now you should believe to a
certain extent that specific problems can be more efficiently solved by using
the right abstractions. But why do we need full blown languages? Aren't objects,
functions, APIs and frameworks good enough? What does the \emph{language} add to
the picture?

Languages (and the programs you write with them), are the cleanest form of
abstraction --- essentially, you are adding a notation to a conceptual model of
the domain. You get rid of all the unneeded clutter that an API --- or
anything else embedded in or expressed with a general-purpose language ---
requires. You can define a notation that fits the abstractions well and makes
interacting with programs easy and efficient. DSLs may be so limited that they
only allow the creation of correct programs (correct-by-construction). You can
provide non-trivial static analyses and checks and provide an IDE that provides
services such as code completion, syntax highlighting, error markers,
refactoring and debugging. This goes far beyond what can be done with the
facilities provided by general-purpose languages\marginnote{In the end, this is
what allows DSLs to be used by non-programmers, one of the value propositions of
DSLs: they get a clean, custom, productive environment that allows them to work
with languages whose abstractions and notations are aligned with the domain they
work in.}.

So then how are DSLs different from general purpose programming languages, and
what do they have in common? This boundary isn't as clear as it could be. Obviously the
core abstractions are aligned with whatever domain the DSL is built for, and the
notations are suitable as well. Also, in many cases, DSLs are much smaller and
simpler\footnote{Small and simple can mean that the language has fewer concepts,
that the type system is less sophisticated or that the expressive power is
limited} than GPLs (although there are some pretty sophisticated DSLs). I don't
go as far as saying that DSLs are always declarative (it is not completely clear
what this means anyway), or that they may never be Turing complete. But if your
DSL approaches what Java can do, you might consider just using
Java\marginnote{\ldots or, if your tooling allows it, extending Java with
domain-specific concepts}. DSLs often start simple, based on an initially
limited understanding of the domain, but then grow more and more sophisticated
over time, a phenomenon Hudak notes in his '96 paper \todo{}.

So, I guess we agree that Java is not a DSL. But what about Mathematica, SQL,
State Charts or HTML? Are these DSLs? This is not so easy to answer. They are,
of course, DSLs in the sense that they are languages that are optimized for (and
limited to) a special domain or problem. However:

\begin{itemize}
  \item These languages are really really big and complicated.
  While I don't claim that good DSLs are always simple, it is really rare
  that you'll build something comparable to SQL in sophistication or size.
  \item An underlying assumption of many (process) recommendations in this book
  is that, as the developer of a DSL, you know the
  users and can communicate with them. For example, you can make them remove
  deprecated language constructs from their models, or you inspect and analyze
  the models to learn how to improve the language. This is not true for
  languages that are used by (more or less) the whole world, such as the 
  ones mentioned above.
\end{itemize}

\marginnote{You may know the saying in artificial intelligence (AI) that
"everything that works in practice isn't called AI anymore". Ira Baxter suggests
that this is also true for DSLs: as soon as a DSL is really successful (like the
ones mentioned above), we don't call them DSLs anymore. So maybe we can agree
that those well-known, widely used and big languages are in fact DSLs, but
because they are so big and widespread, not all of the advice given in this
book may apply.}
 



Domain-specificity is not black-and-white, but rather gradual:
a language is \emph{more} or \emph{less} domain specific. The following
table lists a set of language characteristics. While DSLs and general purpose
languages (GPLs) can have characteristics from both the second and the third
columns, DSLs are more likely to pick characteristics from the right column.
This makes designing DSLs a more tractable problem than designing general
purpose languages\marginnote[-2cm]{There are many connections to general
purpose languages. DSL programs may be translated into GPL code. DSL code may be
embedded in GPL programs. And DSL designers can learn a lot from GPLs.}
 
\begin{figure*}[h] 
\footnotesize
  \begin{tabular}{lll} \toprule
    \textbf{Domain} & large and complex & smaller and well-defined \\
    \textbf{Designed by} & guru or committee & a few engineers and domain
         experts \\ 
    \textbf{Language Size} & large & small \\ 
    \textbf{Turing-completeness} & always & often not \\ 
    \textbf{User Community} & large, anonymous and widespread & small,
         accessible and local  \\ 
    \textbf{User-Defined Abstractions} & sophisticated & limited \\ 
    \textbf{Lifespan} & years to decades & months to years (driven by context) 
    \\  
    \textbf{Evolution} & slow, often standardized & fast-paced  \\
    \textbf{Deprecation/Incompatible Changes} & almost impossible & feasible 
        \\ 
    \bottomrule
  \end{tabular}
\caption[][6mm]{Domain-specific languages versus programming languages. DSLs
tend to pick more characteristics from the third column, GPLs tend to pick more
from the second. 
\laurie{This table is great. Actually, it's so great that it renders a lot 
of the text that comes before it slightly superfluous! Can it be moved earlier in the book?}}
\label{fig:}
\end{figure*}

\section{Modeling and Model-Driven Development}

The approach described above of defining and using DSLs is a form of
model-driven development (MDD): we create formal, tool-processable
representations of certain aspects of software systems\footnote{One can also do
MDD without DSLs by, for example, generating code from general purpose modeling
languages such as UML.}. We then use interpretation or code generation to
transform those representations into executable code expressed in programming
languages and the associated XML/HTML/whatever files. With today's tools it is
technically relatively simple to define arbitrary abstractions to represent some
aspect of a software system in a meaningful way\footnote{Designing a \emph{good}
language is another matter --- I provide some input on designing DSLs in the
Design part of this book.}. It is also relatively simple to build code
generators that generate the executable artifacts (as long as you don't need
sophisticated optimizations, which can be challenging). Ddepending on the
particular DSL tool used, it is also possible to define suitable notations that
make the abstractions accessible to non-programmers (for example opticians or
thermodynamics engineers).

However, there are also limitations to the approach. The biggest one is that
modeling and programming often does not go together very well: 
modeling languages, environments and tools are distinct from programming
languages, environments and tools. The level of distinctness varies, but in many
cases it is big enough to cause integration issues that can make adoption of MDD
challenging. Let me provide some specific examples. Industry has settled on a
limited number of meta meta models, EMF/EMOF being the most widespread one.
Consequently, it is possible to navigate, query and constrain arbitrary models
with a common API. However, programming language IDEs are typically \emph{not}
built on top of EMF, but come with their own API for representing and accessing
the syntax tree. Thus, interoperability between models and source code is
challenging --- you can't treat source code the same way as models. A similar
problem exists regarding IDE support for model-code integrated systems: you
cannot mix (DSL) models and (GPL) programs while retaining reasonable IDE
support. Again, this is because the technology stacks used by the two are
different\footnote{Of course, an integration can be created as Xtext/Xtend/Java
shows. However, this is a \emph{special} integration with Java. Interoperability
with, say, C code, would require a new and different integration
infrastructure.}. These problems often results in an artificial separation of
models and code, where code generators create skeletons into which source code
is inserted, or the arcane practice of pasting C snippets into 5-in sized text
boxes in graphical state machine tools (and getting errors reported only once
the resulting, integrated C code is compiled).


Above we have discussed the difference between DSLs and GPLs. Now that we talk
about modeling, I have to explain what I mean by modeling. There are two ways
modeling can be used: descriptive and prescriptive. A \emph{descriptive} model
represents and existing system. It abstracts away certain aspect, and
emphasizes others. It is usually used for discussion, communication and
analysis. A \emph{prescriptive} model is one that can be used to (automatically)
construct the target system. It must be much more rigorous, formal, complete and
consistent. In the context of this chapter, and of the book in general, we
always mean prescriptive models when we use the term model\footnote{Some
people say that models are always descriptive, and once you become
prescriptive, you enter the realm of programming. That's fine with me. As I
said, I don't distinguish between programming and modeling, just between more
or less abstract languages and models.}.


So what really is the difference between programming and (prescriptive) modeling
today? The table contains some (general and broad) statements:


\begin{figure*}[h]
\footnotesize
  \begin{tabular}{lll} \toprule
	\textbf{Aspect} & \textbf{Modeling} & \textbf{Programming}\\
	\midrule
	Define your own notation and language & Easy & Sometimes Possible to some
	Extent \\ 
	Syntactically integrate several languages & possible, depends on tool & hard\\
	Graphical Notations & possible, depends on tool & usually only visualizations\\
	Customize Generator/Compiler & Easy & Sometimes possible based on open compilers\\
	Navigate/Query & Easy & Sometimes possible, depends on IDE and APIs\\
	Constraints & Easy & Sometimes possible with Findbugs etc.\\
	Sophisticated Mature IDE & Sometimes & Standard\\
	Debugger & Rarely & Almost always\\
	Versioning/Diff/Merge & Depends on tooling & Standard\\
    \bottomrule
  \end{tabular}
\caption[][6mm]{Comparing Modeling and Programming}
\label{fig:}
\end{figure*}

So one can and should ask: why is there a difference? I guess the primary
reason is history, the two worlds have different origins and have evolved in
different directions.

Programming languages have traditionally been using textual concrete syntax,
i.e. the program is represented as a stream of characters. Modeling languages
traditionally used graphical notations\footnote{There are several scenarios in
which graphical concrete syntax makes sense (I discuss this later in the book).
But there are also many cases where a good textual syntax, plus maybe a
visualization, would be much more productive.}. Of course
there are textual domain specific languages (and mostly failed graphical general purpose
programming languages), but the use of textual syntax for domain specific
modeling has only recently become more prominent. Programming languages have
traditionally used storage based on concrete syntax, together with parsers that
transform a character stream to an abstract syntax tree for further processing.
Modeling languages have traditionally used editors that directly manipulate the
abstract syntax, using projection to render the concrete syntax in the form of
diagrams. Modeling tools have also provided the ability to define views, i.e.
the ability to show the same model elements in different contexts, often using
different notations. This has never really been a priority for programming
languages beyond outline views, inheritance graphs or call graphs.

I want to make the point that there should be no difference\footnote{This is my
personal opinion. While I know enough people who share it, I also know people
who disagree}. Programming and (prescriptive) modeling should be based on the
same fundamental approach, enabling meaningful integration. No programmer really
wants to model, they want to program, but:

\begin{description}
  \item[at different levels of abstraction:] some things may have to be
  described in detail, low level, algorithmically (a sorting algorithm), other
  aspects may be described in more high-level terms (declarative UIs)
  \item[from different viewpoints:] seaprate aspects of the system should be
  described with languages suitable to these aspects (data structures,
  persitence mapping, process, UI)
  \item[with different degrees of domain-specificity:] some aspects of systems
  are generic enough so they can be described with reusable, generic languages
  (components, database mapping). Other aspects require their own dedicated,
  maybe even project-specific DSLs (pension calculation rules).
  \item[with suitable notations,] so all stakeholders can contribute directly to
  "their" aspects of the overall system (a tabular notation for testing pension
  rules)
  \item[with suitable degrees of expressiveness:] aspects may be described
  imperatively, with functions, or other turing-complete formalisms (a routing
  algorithm), and other aspects may be described in a declarative way (UI
  structures)
  \item[and always integrated and tool processable,] so all aspects
  \emph{directly} lead to executable code through a number of transformations or
  other means of execution.
\end{description}

This vision, or goal, leads to the need for modular languages, as explained in
the next section.


\section{Modular Languages}

I distinguish between the size of a language and its scope. Language size simply
refers to the number of language concepts in that language. Language scope
describes the area of applicability for the language, i.e. the size of the
domain. The same domain can be covered with big and small languages. A big
language makes use of linguistic abstraction, whereas a small language allows
the user to define their own in-language abstractions. We discuss the tradeoffs
between big and small languages in detail as part of the DSL design chapter on
Expressivity \todo{}, but here is a short overview, based on examples from the
domain of general purpose programming (i.e. GPLs).

\begin{marginfigure}
  \includegraphics[width=4cm]{figures-intro/bigLang.jpg}
  \caption{A Big Language: Many specific language concepts}
  \label{bigLang} 
\end{marginfigure}
Examples of big languages include Cobol (a relatively 
old language intended for use by business users) or ABAP (SAP's language for 
programming the R/3 system). Big languages (\fig{bigLang}) have a relatively
large set of very specific language concepts. These languages are, the
proponents say, easy to learn, since "there's a keyword for everything". Tool
support is easy to build. Interesting constraint checks and meaningful error
messages are relatively simple to implement. However, expressing more
sophisticated algorithms can be clumsy, because it is hard to write compact, 
dense code. 

\begin{marginfigure}
  \includegraphics[width=4cm]{figures-intro/smallLang.jpg}
  \caption{A Small Language: Few, but powerful language concepts}
  \label{smallLang} 
\end{marginfigure}
Let us now take a look at small languages. Lisp or Smalltalk are examples of
small languages in the domain of general purpose programming. They have 
few, but very powerful language concepts that are highly composable. Users can 
define their own abstractions. Proponents of this kind of language also say 
that those are easy to learn, because "you only have to learn three concepts". 
But it requires experience to build more complex systems from these basic
building blocks, and code can be challenging to read because of its high density. 
Tool support is harder to build because much more sophisticated analysis of the 
code is necessary to reverse engineer its domain semantics.


\begin{marginfigure}
  \includegraphics[width=5cm]{figures-intro/modLang.jpg}
  \caption{A Modular Language: A small core, and a library of
  reusable language modules}
  \label{modLang} 
\end{marginfigure}


Let us look at a third option, modular languages. They are, in some sense, the
synthesis of the previous two. A modular language is made of a minimal language
core, plus a library of language modules that can be imported for use in a given
program. The core is typically a small language (in the way defined above) and
can be used to solve any problem at a low level, just as in C, Smalltalk or
Lisp. The extensions then add first class support for concepts that are
interesting the target domain. Because the extensions are first class concepts,
interesting analyses can be performed and writing generators (transforming to
the minimal core) is relatively straight forward. New, custom modules can be
built and used at any time. A language module is like a framework or
library, but it comes with its own syntax, editor, type system, and IDE tooling.
Once a language module is imported, it behaves as an integral part of the
composed language, i.e. it is integrated with other modules by referencing
symbols or by being syntactically embedded in code expressed with another
module. Integration on the level of the type system, the semantics and the IDE
is also provided. An extension module may even be embeddable in
\emph{different} core languages. 


This idea isn't new. Charles Simonyi\cite{SimonyiCC06} and Sergey
Dmitriev\cite{lopnextprogrammingparadigm} have written about it, so has Guy
Steele in the context of Lisp\cite{Steele99}. The idea also relates very much to
the notion of language workbenches as defined by Martin Fowler. \cite{Fowler2011}
defines language workbenches as tools where: 

\vspace{5pt}
\noindent
\textbf{Users can freely define languages that are fully integrated with each
other.} This is the central idea for language workbenches, but also for 
modular languages since you can easily argue that each language module is 
what Martin Fowler calls a language. "Full integration" can refer
to referencing as well as embedding, and includes type systems and semantics.

\vspace{5pt}
\noindent \textbf{The primary source of information is a persistent abstract
representation \emph{and} Language users manipulate a DSL through a projectional
editor.} This implies that projectional editing be used\footnote{Projectional
editing means that users don't write text that is subsequently parsed. Instead,
user interactions with the concrete syntax directly change the underlying
abstract syntax. We'll discuss this technology much more extensively later in
this book}. I don't agree. Storing programs in their abstract representation and
then using projection to arrive at an editable representation is very useful,
and maybe even the best approach to achieve modular languages. However, in the
end I don't care, as long as languages are modular. If this is possible with a
different approach, such as scannerless parsers\footnote{Scannerless parsers
do not distinguish between recognizing tokens and parsing the structure of the
tokens, thereby avoiding certain problems with grammar composability. We'll
discuss this further in the book as well}, that is fine with me.

\vspace{5pt}
\noindent \textbf{Language designers define a DSL in three main parts: schema,
editor(s), and generator(s).} I agree that ideally a language should be defined
"meta model first", i.e., you first define a schema, and then the editor or
grammar, based on the schema (MPS does it this way). However, it is also okay
for me to start with the grammar, and have the meta model derived (the typical
workflow with Xtext, although it can do both). From the language user's point of
view, it does not make a big difference in most cases.


\vspace{5pt}
\noindent \textbf{A language workbench can persist incomplete or contradictory
information.} I agree. This is trivial if the models are stored in a concrete
textual syntax, it is not so trivial if a persistent representation based on the
abstract syntax is used.

\vspace{5pt}
\noindent Let me add two additional requirements. For all the languages built with the
workbench, I want to get tool support: syntax highlighting, code completion, any
number of static analyses (including type checking in case of a statically typed
language) and ideally also a debugger. A central idea of language workbenches is
that language definition always includes IDE definition. The two should be
integrated.

A final requirement is that I want to be able to program
complete systems within the language workbench. This means that together with
DSL, general-purpose languages must also be available in the environment based
on the same language definition/editing/processing infrastructure. Depending on
the target domains, this language could be Java or C\#, but it could also be C
for the embedded community. Starting with an existing general-purpose language
also makes the adoption of the approach simpler: incremental language extensions
can be developed as the need arises.

\parhead{Syntax} Generally I expect the syntax of DSLs to be textual. Decades of
experience show that textual syntax, together with good tool support, is
adequate for large and complex software systems\footnote{As I said, this is not
true for all formalisms. Expressing hierarchical state charts textually can be a
challenge. However, textual syntax is a good default that can be used unless
otherwise indicated}. This becomes even more true if you consider that
programmers will have to write less code, since the abstractions available in
the languages will be much more closely aligned with the domain than is the case
for traditional languages \laurie{huh?}. Programmers can always define a
language module that fits a domain. However, there are worthwhile additions. For
example, semi-graphical syntax would be useful, i.e. the ability to use
graphical symbols as part of a fundamentally text-oriented editor: mathematical
symbols, fraction bars, subscript/superscript, or even tables\footnote{Tabular
syntax is what made Excel popular!}, can make programs represent certain domains
much more clearly.


However, the need to see graphical notations to gain an overview over complex
structures does not necessarily mean that the program has to be \emph{edited} in
a graphical form. Custom visualizations are important as well. Visualizations
are graphical representations of some interesting aspect of the program that is
read-only, automatically layouted and provides drill-down back to the program (you can
double-click on, say, a state in the diagram, and the text editor selects that
particular state in the program text). 


Finally, actual graphical editing is useful for certain cases. Examples
include data structure relationships, state machine diagrams or data flow
systems. The textual and graphical notations must be integrated, though: you
will want to embed the expression language module into the state machine diagram
to be able to express guard conditions.



\parhead{Language Libraries} The importance of being able to build your own
languages varies depending on the concern at hand. Assume that you work for an
insurance company and you want to build a domain specific language that supports
your company's specific way of defining insurance contracts. It is essential
that the language is exactly aligned with your business, so you have to define
the language yourself. There are other similar examples: building DSLs to
describe radio astronomy observations for a given telescope, a language to
describe cooling algorithms for refrigerators, or a language for describing
telecom billing rules (all of these are actual projects I have worked on).

However, for a large range of technical or architectural concerns, the
abstractions are well known. They could be made available for reuse (and
adaptation) in a library of language modules. Examples include

\begin{itemize}
	\item Hierarchical components, ports, component instances, and connectors. 
	\item Data structure definition \grave{a} la relational model or hierarchical
	data \grave{a} la XML and XML schema, including specifications for persisting that data
	\item Definition of rich contracts, i.e. interfaces, pre- and post conditions,
	protocol state machines, and the like 
	\item Various communication paradigms such as message passing, synchronous and
	asynchronous remote procedure calls, and service invocations
	\item Abstractions for concurrency based on transactional memory or actors
\end{itemize}

This sounds like a lot of stuff to put into a programming language. But
remember: it will not all be in one language. Each of those concerns will be a
separate language module that will  be used in a program only if needed.

It is certainly not possible to define all these language modules in isolation.
Modules have to be designed to work with each other, and a clear dependency
structure has to be defined. Interfaces on language level support "plugging in"
new language constructs. A minimal core language supporting primitive types,
expression, functions and maybe OO, will likely act as the focal point around
which additional language modules are organized. Some of the tools outlined in
the next section support this approach.

Many of these architectural concerns interact with frameworks, platforms and
middleware. It is crucial that the abstractions in the language remain
independent of specific technology solutions. In addition, when interfacing with
a specific technology, additional (hopefully declarative) specifications might
be necessary: such a technology mapping should be a separate model that
references the core program. The language modules define a language for
specifying persistence, distribution, or contract definition. Technology
suppliers can support customized generators that map programs to the APIs
defined by their technology, taking into account possible additional
specifications that configure the mapping. This is a little bit like service
provider interfaces (SPIs) in Java enterprise technology.

\begin{figure*}[h]
  \includegraphics[width=18cm]{figures-intro/exampleModLang.jpg}
  \caption{A program written in a modularly extended C}
  \label{exampleModLang} 
\end{figure*}

\parhead{A Vision of Programming} For me, this is the vision of programming I am
working towards. The distinction between modeling and programming is gone.
People can develop code using a language directly suitable to the task. They can
also build languages, if that makes sense. These languages will be relatively
small, since they only address one aspect of a system. They are not
general-purpose. They are DSLs.

Tools for this approach exist\marginnote{MPS is one of them, which is why I
focus a lot on MPS in this book. Intentional's Domain Workbench is another one.
Various Eclipse-based solutions are getting there as well}. Of course they can
become even better, for example, regarding development of debuggers or regarding
integration of graphical and textual languages, but we are clearly getting
there.


\section{Benefits of using DSLs}

Using DSLs can reap a multitude of benefits. There are also some challenges you
have to master, I outline these in the next section. But let's look at the
upside first.

\subsection{Automation & Productivity}
The most obvious benefit of using DSLs is that --- once you've got a language
and an execution engine --- your work in the particular aspect of software
development covered by the DSL becomes much more efficient, simply because you
don't have to do the grunt work manually\sidenote{Presumably, the amount of DSL
code you have to write is much less than what you'd have to write if you used
the target platform directly. If that were not the case, using DSLs in that
context makes no sense.}. This is most obvious if you generate a whole truck
load of code from a relatively small DSL program. There are many studies that
show that just the amount of code one has to write (and read!) introduces
complexity, independent of what the code expresses, and how. The ability to
reduce that amount while retaining the same semantic content, is a huge
advantage.

You could argue that a good library or framework will do the job as well. True,
libraries, frameworks and DSL all encapsulate knowledge and functionality,
making it easily reusable. However, DSLs provide a number of additional
benefits, as we will see in the next couple of items.


\subsection{Quality}
\marginnote{The appraoch can also yield better performance if the execution
engine contains the necessary optimizations. However, implementing these is a
lot of work, so most DSLs do not lead to significant gains in performance.}
Using DSLs can increase the quality of the created product: fewer bugs, better
architectural conformance, increased maintainability. This is the result of the
removal of (unnecessary) degrees of freedom for programmers, the avoidance of
duplication in code (if the DSL is engineered in the right way) and the
automation of repetitive work (by the execution engine)\footnote{This is also
known as correct-by-construction: the language only allows the construction of
correct programs.}. As the next item shows, more meaningful validation and
verification can be performed on the level of DSL programs, increasing the
quality further.


\subsection{Analysis and Checks}
Because DSLs capture their respective concern in a way that is uncluttered from
the implementation, it is more semantically rich. Analyses are much easier to
implement and error messages can use more meaningful wording, because it happens
on the domain level. As mentioned above, some DSLs are built specifically to
enable non-trivial, formal (mathematical) analyses\footnote{Manual review
also becomes more efficient, because the domain specific aspects are uncluttered, and domain
experts can be involved more directly}. 


\subsection{Data Longevity}
If done right, models are independent of specific realization techniques. They
are expressed at a level of abstraction that is meaningful to the domain ---
this is why we can analyze and generate based on these models. This also means
that models can be transformed into other representations, if the need arises,
for example, because you are migrating to a new DSL technology. While the
investments into DSLs are specific to a particular tool (and lost if you change
it), the models should largely be migratable.


\subsection{Thinking and Communication Tool}
If you have a way of expressing domain concerns in a language that is closely
aligned with the domain, your thinking becomes clearer because the code you
write is not cluttered by implementation details. In other words: using DSLs
allows you to separate essential from incidental complexity, moving the latter
to the execution engine. This also makes team communication and reviews simpler.

But not just using the DSL is useful; also, the act of building the language can
help you sharpen your understanding of whatever you build the language for.
\marginnote{Building a language requires formalization and decision making: you
can't create a DSL if you don't really know what you're talking about.} In some
sense, a language definition is an "executable analysis model" - remember the
days when "analysts" created "analysis models"? I have had several occasions
where customers said after a three-day DSL prototyping workshop that they had
learned a lot about their own domain, and that even if they never used the DSL,
this alone would be worth the effort spent on building the DSL. In effect, a DSL
is a formalization of the ubiquitous language in the sense of Eric Evans'
Domain Driven Design.\todo{cite}

\subsection{Domain Expert Involvement}
DSLs whose domain, abstractions and notations are closely aligned with how
domain experts (i.e., non-programmers) express themselves, allow for very good
integration between the techies and the domain people: they can easily read, and
often write the program code, since it is not cluttered with implementation
details irrelevant to them. \marginnote{Of course, the domain (and the people
working in it) must be suitable for formalization, but once you start looking,
it is amazing how many domains fall into this category. Insurance contracts,
hearing aids and refrigerators are just some examples where you maybe didn't
think this is true.} And even when domain experts aren't willing to write DSL
code, developers can at least pair with them when writing code, or use the DSL
code to get domain experts involved in meaningful validation and reviews.
(Fowler uses the term "business-readable DSLs" in this case.) At the very least
you can generate visualizations, reports or even interactive simulators that are
suitable for use by domain experts. 


\subsection{Productive Tooling}
In contrast to libraries, frameworks, and internal DSLs, external DSLs can come
with tools, i.e. IDEs that are aware of the language. This can result in a much
improved user experience. Static Analyses, code completion, visualizations,
debuggers, simulators and all kinds of other niceties can be provided. These
features improve developer productivity and also make it easier for new team
members to become productive.



\subsection{No Overhead}
If you are generating source code from your DSL program (as opposed to
interpreting it) you can use nice, domain-specific abstractions without paying
any runtime overhead, because the generator, just like a compiler, can remove
the abstractions and generate efficient code. This is very useful in cases where
performance, throughput or resource efficiency is a concern (i.e. in embedded
systems, but also in The Cloud where you run many, many processes in server
farms, and energy consumption is an issue these days).



\subsection{Platform isolation}
In some cases, using DSLs can abstract from the underlying technology
platform\footnote{Remember OMG's MDA? They introduced the whole model-driven
concept as a means to primarily abstract from platforms (probably a consequence
of their historical focus on interoperability). In my experience, this can be
one driver, but it is typically not the only one, and often it's even just a
minor side benefit. There are cases, though, where DSLs are used mainly to
achieve platform independence: cross-platform mobile development comes to
mind.}. Using DSLs and an execution engine makes the application logic expressed
in the DSL code independent of the target platform\footnote{this is not
necessarily true for architecture DSLs and utility DSLs whose abstractions may
be tied relatively closely to the concepts provided by the target platform.}. It
is absolutely feasible to change the execution engine and the target platform
"underneath" a DSL to execute the code on a new platform. Portability is
enhanced, as is maintainability, because DSLs support separation of concerns -
the concerns expressed in the DSL (e.g., the application logic) is separated
from implementation details and target platform specific.



\vspace{7mm}
\noindent Often, no single one of the advantages would drive you to use a
DSL. But in many cases you can benefit in multiple ways, so the sum of the
benefits is worthwhile the (undoubtably necessary) investment into the approach.


\section{Challenges}

There ain't no such thing as a free lunch. This is also
true for DSLs. Let us look at the price you have to pay to get all these nice
benefits mentioned above.

\todo{Hudak's '96 paper has a wonderful graph showing the start-up costs
(c1 and c2) of conventional / DSL approaches. I think his thoughts could
usefully feed into this section.}

\subsection{Effort of Building the DSLs}
Before a DSL can be used, it has to be built. If it has been built already, then
using the DSL is obviously useful. If the DSL has to be developed as part of a
project, the effort for building it has to be factored into the overall cost-benefit
analysis. For technical DSLs\footnote{Technical DSLs are those that address
aspects of software engineering such as components, state machines or
persistence mappings, not application domain DSLs for a technical domain (such
as automotive software or machine control)}, there is a huge potential for reuse
(e.g., a large class of web or mobile applications can be described with the
same DSL), so here the investment is easily justified. On the other side,
application domain-specific DSLs (e.g., mortgage contracts specifications) are
often very narrow in focus, so the investment of building them is harder to
justify at first glance. But these DSLs are often tied to the core know-how of a
business and provide a way for describing this knowledge in a formal,
uncluttered, portable and maintainable way and that should also be a priority
for any business that wants to remain relevant. In both cases, modern tools
reduce the effort of building DSLs considerably, making it a feasible approach
in more and more projects. \marginnote[-4\baselineskip]{I hope that this book
helps you master the learning curve with some of these tools. But in the end,
you (or somebody else) have to make the decision when and how to use DSLs.
Experience helps here.}

\subsection{Language Engineering Skills}
Building DSLs is not rocket science. But to do it well requires experience and
skill --- it is likely that your first DSL will not be great. Also, the whole
language/compiler thing has a bad reputation that mainly stems from "ancient
times" where tools like lex/yacc, ANTLR, C and Java were the only ingredients
you would use for language engineering. Modern language workbenches have changed
this situation radically, but of course there is still a learning curve. In
addition, the definition of good languages --- independent of tooling and
technicalities --- is not made simpler by better tools: how do you
find out which abstractions need to go into the languages? How do you create
"elegant" languages? I will elaborate on this later in the book, but there is a
significant element of experience and practice you need to build up over time.

\subsection{Process Issues}
Using DSLs inevitably leads to work share: some people build the languages,
others use them. Sometimes the languages have been built already when you start
a development project, sometimes they are built as part of the project.
Especially in the latter case it is important that you establish some kind of
process of how language users interact with language developers and how they
interact with domain experts (in case they are not the language users
themselves). Just like any other situation where one group of people creates
something which another group of people relies on, this can be a
challenge\sidenote[][-3\baselineskip]{This is not much different for languages
than for any other shared artifact (frameworks, libraries, tools in general),
but it also isn't any simpler and needs to be addressed.}

\subsection{Maintenance}
A related issue is language evolution and maintenance. Again, just like any
other asset you develop for use in related contexts, you have to plan ahead
(people, cost, time, skills) for the maintenance phase. A language that is not
actively maintained will get outdated over time and become a liability.
Especially during the phase where you introduce DSLs into an organization, a
rapid evolution based on the requirements of users is critical to build trust in
the approach\sidenote[][-1\baselineskip]{While this is an important aspect, once
again, it is not worse for DSLs than it is for any other shared, reused asset.}.


\subsection{DSL Hell} Once development of DSLs is easy, there is a danger that
developers create new DSLs instead searching for and learning existing DSLs.
This may end up in a large set of half-baked DSLs, each covering related
domains, possibly with overlap, but still incompatible. The same problem can
arise with libraries, frameworks or tools. They are all addressed by governance
and effective communication in the team. It also helps if DSLs are incrementally
extensible, so an existing language can be extended instead of creating a
completely new language.


\subsection{Investment Prison} The more you invest into reusable artifacts
(not just DSLs), the more productive you become. However, you may also get
locked into a particular way of doing things. Radically changing your business
model may seem unattractive, once you've become very efficient at the current
one. It becomes expensive to "move outside the box"\footnote{With the advent of
the digital age, we all know many businesses that went bankrupt because they had
sticked too long to a dying business model. Maybe they just couldn't see that
things will change, but maybe it way because they were so efficient at what they
were doing, they couldn't invest into new stuff for fear of canibalizing their
mainstream business.}. To avoid this, keep an open mind and be willing to throw
things away and come up with more appropriate solutions. 


\subsubsection{Tool Lockin} Many of the DSL tools are open source. So you don't
get locked into a vendor. However, today there is no interoperability between
DSL tools, all investments regarding the DSLs and its processors are specific to
a single tool. 


\subsection{Cultural Challenges}
Statements like "Language Engineering is complicated", "developers want to
program, not model", "domain experts aren't programmers" and "if we model, we
use the UML standard" are often overheard prejudices that hinder the adoption of
DSLs. I hope to provide the factual and technical arguments for fighting these
in this book. But there may still remain an element of cultural bias. You may
have to do some selling and convincing that is relatively independent of the
actual technical arguments. Problems like this always arise if you want to
introduce something new into an organization, especially if it changes
significantly what people do, how they do it or how they interact. A lot has
been written about introducing new ideas into organizations, and I recommend
reading this book \todo{Linda's Book} if you're the person who is driving the
introduction of DSLs into your organization.


\vspace{7mm}
\noindent Of course there are other things that can go wrong: your DSL or
generator might be buggy and you build buggy systems with it. You might have the
DSL developed by external parties, giving away core domain knowhow. The guy who
built the DSL may leave the company. However, these things are not specific to
DSLs, they can happen with anything. So we don't address these as challenges in
the context of DSLs specifically.



\newthought{So, is it worth it?} Should you use DSLs? Presumably the only
realistic answer is: it depends. With this book I aim to give you as much help
as possible. The better you understand the topic, the easier it is to make an
informed decision. In the end, you have to decide for yourself or maybe ask
people for help who have done it before. Let us look at when you should
\emph{not} use DSLs.

If you don't understand the domain you want to write a DSL for or if you
don't have the means to learn about it (e.g., access to somebody who knows the
domain), you're in trouble. You will identify the wrong abstractions, miss the
expectations of your future users and generally have to iterate a lot to get it
right\sidenote{If everyone is aware of this, then you might still want to
try to build a language as a means of building the understanding about the domain. But
this is risky, and should be handled with care.} Another sign of problems is
this: if you build your DSL iteratively and over time, the changes requested by
the domain experts don't become fewer (and concerning more and more detailed
points), then you know you are in trouble because it seems there is no common
understanding about the domain. It is hard to write a DSL for a set of
stakeholders who can't agree on what the domain is about. 

Another problem is an unknown target platform. If you don't know how to
implement something on the target platform in the first place, you'll have a
hard time to implement an execution engine (generator or interpreter). You might
want to consider writing (or inspecting) a couple of representative example
applications manually to understand the patterns that go into the execution
engine.

DSLs and the respective tooling are sophisticated software programs
themselves. They need to be designed, tested, deployed, documented. So a certain
level of general software development experience is a prerequisite. A related
topic is the maturity of the development process. The fact that you introduce
additional dependencies in the form of a supplier-consumer relationship into
your development team requires that you know how to track issues, handle version
management, do testing and quality assurance and document things in a way
accessible to the target audience. So, if your development team lacks this
maturity, you might want to consider to first introduce those concerns into the
team before you start using DSLs in a strategic way --- the occasional utility
DSL is the obvious exception.


\section{Applications of DSLs}

So far we have covered some of the basics of DSLs, as well as the benefits and
challenges. This section addresses in which aspects of software engineering DSLs
have been used successfully. Part IV of the book provides extensive treatment
for most of these.


\subsection{Utility DSLs}
One use of DSLs is simply as utilities for developers. A developer, or a small
team of developers, creates a small DSL that automates a specific, usually
well-bounded aspect of software development. The overall development process is
not based on DSLs, it's a few developers being creative and simplifying their
own lives\sidenote{Often, these DSL serve as a "nice front end" to an existing
library or framework, or automates a particularly annoying or intricate aspect
of software development in a given domain.}.

Examples include the generation of array-based implementations for state
machines, any number of interface/contract definitions out of which various
derived artifacts (classes, WSDL, factories) are generated, or tools that set up
project and code skeletons for given frameworks (as exemplified in Rails' and
Roo's scaffolding).

\subsection{Architecture DSLs}	

\marginnote{This is one of the most interesting use cases of DSLs and I have
seen (and contributed to the creation of) many instances. This is why a later
section focusses on architecture DSLs extensively} A somewhat more large-scale
use is to use DSLs to describe the architecture (components, interfaces,
messages, dependencies, processes, shared resources) of a (larger) software
system or platform. In contrast to using existing architecture modeling
languages (such as UML or the various ADLs), an the abstractions in an
architecture DSL can be tailored specifically to the abstractions relevant to
the particular architecture. Much more meaningful analyses and generators are
possible this way. Architecture DSLs are usually developed during the
architecture exploration phase of a project and make sure that the system
architecture is consistently implemented by a potentially large development
team. From the architecture models expressed in the DSL code skeletons are
generated into which manually written application code is inserted. The
generated code usually handles the integration with the runtime infrastructure.
Often, these DSLs also capture non-functional constraints such as timing or
resource consumption.

For example, In AUTOSAR, the architecture is specified in models and then the
complete communication middleware for a distributed component infrastructure is
generated. Examples in embedded systems in general abound: I have used this
approach for a component architecture in software-defined radio, as
well as for factory automation systems, where the distributed components had to
"speak" an intricate protocol whose handlers could be generated from a concise
specification. Finally, the approach can also be used well in enterprise systems
that are based on a multi-tier, database-based distributed server architecture.
Middleware integration, server configuration and build scripts can often be
generated from relatively concise models.


\subsection{Full Technical DSLs}
For certain domains, DSLs can be created that don't just embody the
architectural structure of the systems, but their complete application logic as well, so that
100\% of the code can be generated. DSLs like these often consist of
several language modules that play together to describe all aspects of the
underlying system. I emphasize the word "technical", since these DSLs are
used by developers, in contrast to the next category.

Examples include DSLs for (certain kinds of) Web applications, DSLs for mobile
phone apps as well as the proverbial wrist watch (you know what I am talking
about if you know the Finnish company Metacase :-)).

\subsection{Application Domain DSLs}
In this case, the DSLs describe the core business logic of an application system
independent of its technical implementation. These DSLs are intended to be
used by domain experts, usually non-programmers. This leads to more stringent
requirements regarding notation, ease of use and tool support, and usually more
effort in building the language, since a "messy" application domain first has
to be understood, structured and possibly "re-taught" to the domain experts.
In contrast, technical DSLs are often much easier to define, since they are
guided very much by existing formal artifacts (architectures, frameworks,
middleware infrastructures).

Examples include DSLs for describing mortgage contracts, a DSL for describing
the cooling algorithms in refrigerators, a DSL for configuring hearing aids, or
DSLs for insurance mathematics.
  
  
\subsection{DSLs in Requirements Engineering}
A related topic to application domain DSLs is the use of DSLs in the context of
requirements engineering. Here, the focus of the languages is not so much on
automatic code generation but rather on a precise and checkable complete
description of requirements. Traceability into other artifacts is important.
Often, the DSLs need to be embedded or otherwise connected to prose text, to
integrate them with "classical" requirements approaches.

Examples include a DSL for helping with the trade analysis for satellite
construction or pseudo-structured natural language DSLs that imply some formal
meaning into domain entities and terms such as \emph{should} or \emph{must}. The
latter kind of DSLs, also called \emph{Controlled Natural Language}, is quite
different from the kinds of DSLs we cover in this book. I will not cover it any
further.

\subsection{DSLs used for Analysis}
Another category of DSL use is as the basis for analysis, checking and proofs.
Of course, checking plays a role in all use cases for DSLs - you want to make
sure that the models you release for downstream use are "correct" in a sense
that goes beyond what the language syntax already commands. But in some cases,
DSLs are used to express concerns in a formalism that lends itself to formal
analysis or model checking (concurrency, resource allocation, etc.). While code
generation is often a part of it, code generation is not the driver why this
type of DSLs is used. This is especially relevant in complex technical systems,
or in systems engineering, where we look beyond only software and consider a
system as a whole (including mechanical, electric/electronic or fluid-dynamic
aspects). Sophisticated mathematical formalisms are used here - I will cover
this aspect only briefly in this book.

Examples include systems to find counterexamples, allocate resources or optimize
resource consumption, or to come up with optimal scheduling algorithms.

\subsection{DSLs used in Product Line Engineering} At its core, PLE is mainly
about expressing, managing and then later binding variability between a set of
related products. Depending on the kind of variability, DSLs are a very good way
of capturing the variability, and later, in the DSL code, of describing a
particular variant. Often, but not always, these DSLs are used more for
configuration than for "creatively constructing" a solution to a problem.

Examples include the specification of refrigerator models as the composition of
the functional layout of a refrigerator and a cooling algorithm, injected with
specific parameter values.











\section{Differentiation from other Works and Approaches}
\label{Differentiation}

\subsection{Internal vs. External DSLs}

\todo{Add controlled natutral language here?}

\laurie{IMHO, this is a very important section. Most developers use `DSL' 
for `internal DSL', not really understanding the difference. I think it 
needs to be teased out (particularly w.r.t. fluent interfaces). 
My PhD student's paper \texttt{http://tratt.net/laurie/research/publications/html/vasudevan\_tratt\_\_comparative\_study\_of\_dsl\_tools/} 
gives one angle on this.}

Internal DSLs are DSLs that are embedded into general-purpose languages.
Usually, the host languages are dynamically typed and the implementation of the
DSL is based on meta programming (Scala is an exception here). I distinguish
internal DSLs in this sense from language embedding (as covered later in the
book) because I feel that one main ingredient is missing: IDE support. In
classical internal DSLs, the IDE is not aware of the grammar, constraints or
other properties of the embedded DSL (beyond what the type system can offer,
which isn't much in the case of dynamically typed languages). Since I consider
IDE integration an important ingredient to DSL adoption, I decided not to cover
internal DSLs in this book\footnote{In addition, I don't have enough
real-world experience with internal DSLs to be able to talk about them in a
book}.

\todo{Point at good books to read on this topic}

\begin{figure*}[h]
  \includegraphics[width=18cm]{figures-intro/pension-1.png}
  \caption{Example Code written using the Pension Plans
  language (yes, the prose is Dutch, but it is not important here to be able
  to understand it.)}
  \label{pension1} 
\end{figure*} 


\subsection{UML}

So what about the Unified Modeling Language - UML? \marginnote{When I wrote my
"old" book on MDSD, the UML played an important role. At the time, I really did
use UML a lot for projects involving models and code generation. Over the
years, the importance of UML has diminished significantly (in spite of the OMG's
efforts in popularizing both UML and MDA) mainly because of the advent of modern
language workbenches.} I decided not to cover or use UML in this book. I focus
on mostly textual DSLs and related topics. UML does show up peripherally in a
couple of places, but if you are interested in UML-based MDSD, then this book is
not for you. For completeness, let us briefly put UML into the context of DSLs.


UML is a general-purpose modeling language. Like Java or Ruby, it is not
specific to any domain (unless you consider software development in general to
be a domain, which renders the whole DSL discussion useless), so UML itself
does not count as a DSL. UML can be seen as an integrated \emph{collection} of
DSLs that describe various aspects of software systems: class structure, state
based behavior, deployment, etc. However, these DSLs still address the overall
domain of \emph{software}. However, UML provides profiles, which are a (bad!)
way to define variants of UML language concepts and to effectively add new ones.
It depends on the tool you choose how well this actually works and how far you
can adapt the UML syntax as part of profile definition. In practice, only a very
small part of the core UML is used (and you have to make sure your users don't
use the other part) with the majority of concepts coming from the profiles. It
is my experience that because of that, it is much more productive, and often
even less work, to build DSLs with "real" language engineering environments as
opposed to UML profiles.

\begin{figure*}[h]
  \includegraphics[width=18cm]{figures-intro/pension-2.png}
  \caption{Example Code written using the Pension Plans
  language}
  \label{pensions2} 
\end{figure*}


This is one reason why I decided not to cover it. Also, the fact that this book
has an emphasis on textual languages and UML is graphical, obviously also drove
my decision to not cover it in any detail.

So is UML used in an MDD context? Sure. People build profiles and use UML-based
DSLs, especially in large organizations where the perceived need for
standardization is paramount\sidenote[][-1cm]{It's interesting to see that even
these sectors increasingly embrace DSLs. I did a couple of projects in the
aerospace/defense sector where I replaced general-purpose, UML-based modeling
with very specific and much more productive DSLs. It is also interesting to see
how sectors define their own standard languages - I hesitate to call them DSLs,
somehow. For example, the automotive industry is in the process of standardizing
on AUTOSAR.}. As a cross-organizational example of an OMG-related standard:
SysML is widely used in the aerospace/defense sector and has a lot of traction
and applicability there. However, for most programmers, textual DSLs and the
accompanying tools are just much more usable and pragmatic.


\begin{figure*}[h]
  \rule{1\textwidth}{0.7pt}
  \vspace{-0.5cm}
  \includegraphics[width=18cm]{figures-intro/webdsl.jpg}
  \caption[-5mm]{Example Code written in WebDSL}
  \label{webdsl} 
  \rule{1\textwidth}{0.7pt}
\end{figure*}



\subsection{Graphical vs. Textual}

This is something of a religious war, akin to the statically-typed versus
dynamically-typed languages debate elsewhere. Of course, there is a use for both
flavors of notation, and in many cases, a mix is the best approach. In a number
of cases, the distinction is even hard to make: tables or mathematical and
chemical notations are both textual and graphical in nature\footnote{The ideal
tool environment will allow you to use and mix all of them and we will see in
the book how close existing tools come to this ideal situation.}.

However, this book does have a bias towards textual notations, for
several reasons. I feel that the textual format is more generally useful,
scales better and that the necessary tools take (far) less effort to build. In
the vast majority of cases, starting with textual languages is a good idea -
graphical visualizations or editors can be built on top of the meta model later,
if a real need has been established.

This book focusses mostly on textual languages; I discuss other forms of
notations only peripherally.

\todo{Point at good books to read on this topic (DSM Book)}





